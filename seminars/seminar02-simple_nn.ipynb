{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uLgXXT-GITz7"
      },
      "source": [
        "# Семинар 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2wOZrxsoITz9"
      },
      "source": [
        "## План ноутбука\n",
        "\n",
        "1. Высокоуровневое API для обучение нейросетей в `PyTorch`\n",
        "2. Обучение первой нейросети в `PyTorch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QG2RRPzQITz-"
      },
      "source": [
        "## Высокоуровневое API для обучение нейросетей в `PyTorch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6pIYm0RnITz-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sv4WdmWSIm47",
        "outputId": "beb3d23b-098a-426e-9af4-c25c136828f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ry8lraUMIT0A"
      },
      "source": [
        "### Создание объекта нейросети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1blv1TNWIT0C"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(700, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(200, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ez2XNkG_IT0D",
        "outputId": "0ca9136f-fadf-48ab-cff0-a46fd6ef369b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=500, out_features=200, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wgAbnF6xIT0E",
        "outputId": "12ece7c7-2201-400c-9343-d78536960826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReLU()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "net[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8F_2FhYUIT0E",
        "outputId": "156648bf-4078-4492-cb65-8d189177a405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1412,  0.0074, -0.0167,  0.0939, -0.0294,  0.0939, -0.0387, -0.1157,\n",
              "         -0.1341, -0.0507]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x = torch.rand(1, 700)\n",
        "\n",
        "net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rSAJrDCyIT0F"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "net = nn.Sequential(\n",
        "    OrderedDict(\n",
        "        [\n",
        "            ('linear1', nn.Linear(700, 500)),\n",
        "            ('relu1', nn.ReLU()),\n",
        "            ('linear2', nn.Linear(500, 200)),\n",
        "            ('relu2', nn.ReLU()),\n",
        "            ('linear3', nn.Linear(200, 10))\n",
        "        ]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qGXJfFBEIT0F",
        "outputId": "b16815d7-be23-42c0-e9aa-1de34ccd88d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (linear2): Linear(in_features=500, out_features=200, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (linear3): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MD71MrHKIT0F",
        "outputId": "82cf1adb-adee-4ecd-f55e-d75d8b0f75b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=700, out_features=500, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "net.linear1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Cca8oS1pIT0G",
        "outputId": "28c63703-96b2-4473-e81f-5dbffabde5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "input_tensor = torch.rand(6, 700)\n",
        "\n",
        "net(input_tensor).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ChmFtJRIIT0G"
      },
      "outputs": [],
      "source": [
        "# необходимо отнаследоваться от nn.Module и определить методы __init__ и forward\n",
        "\n",
        "class CustomTaskNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(700, 500)\n",
        "        self.linear2 = nn.Linear(500, 500)\n",
        "        self.linear3 = nn.Linear(500, 10)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.activation(self.linear1(x))\n",
        "        output = self.activation(self.linear2(output))\n",
        "        output = self.linear3(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w_ckhOSzIT0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e665f8c4-a776-46ac-a745-41d135d46b1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTaskNetwork(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "net = CustomTaskNetwork()\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ZJJ3IEMFPM",
        "outputId": "864fb30e-4f42-45c8-db54-8e0675008966"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear1.weight',\n",
              "              tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
              "                      [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
              "                      [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
              "                      ...,\n",
              "                      [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
              "                      [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
              "                      [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]])),\n",
              "             ('linear1.bias',\n",
              "              tensor([-2.1088e-02,  1.0055e-02, -7.7552e-03, -1.9122e-02, -3.3471e-02,\n",
              "                      -2.0890e-02,  1.7957e-02,  2.6099e-02,  3.0136e-02, -3.0112e-02,\n",
              "                       2.7849e-02, -1.2145e-02, -2.8552e-02,  1.0605e-02, -7.8391e-03,\n",
              "                      -2.5345e-02,  6.5207e-03,  3.5297e-02,  1.6740e-02,  6.9777e-03,\n",
              "                      -3.3125e-02,  1.8327e-02,  1.6675e-02,  1.7545e-02,  7.4183e-03,\n",
              "                      -3.3241e-02,  6.3233e-03, -1.6696e-02, -1.5523e-02, -2.8453e-02,\n",
              "                       6.5478e-03,  2.4674e-02, -3.0306e-02, -1.9385e-02,  1.4468e-02,\n",
              "                      -2.1729e-03, -8.4098e-03, -3.4562e-02, -3.6783e-02,  2.9103e-02,\n",
              "                      -1.9729e-02, -2.3040e-02,  2.1877e-02,  6.0152e-03,  1.1391e-02,\n",
              "                      -6.1097e-03,  3.3665e-02, -8.8738e-03,  2.9855e-02, -3.3741e-02,\n",
              "                      -1.2577e-02,  3.6876e-02,  8.4248e-03,  2.4642e-02,  1.0302e-02,\n",
              "                      -6.1079e-05,  7.1781e-03, -8.0475e-03,  3.1832e-02,  2.9259e-02,\n",
              "                      -1.5856e-03,  1.4783e-02,  1.7176e-02,  1.3105e-02, -6.7287e-03,\n",
              "                       7.3206e-03,  2.7062e-02, -1.4028e-02,  2.2943e-02,  2.3746e-02,\n",
              "                      -3.6304e-02,  3.6079e-02, -2.3212e-02, -3.6907e-02,  2.5203e-02,\n",
              "                      -1.2118e-02,  2.9581e-02,  2.1207e-02, -1.2558e-02,  1.9321e-02,\n",
              "                      -8.6805e-03,  2.7435e-02, -2.9800e-02, -7.4419e-03,  3.1814e-02,\n",
              "                      -2.1617e-02,  4.0231e-03,  1.6897e-03, -2.7224e-02,  2.2252e-02,\n",
              "                      -7.8276e-03, -5.8323e-03,  2.1604e-02,  2.0243e-02, -3.0634e-02,\n",
              "                      -2.7636e-02,  2.7618e-02, -3.7075e-02,  2.7422e-02,  3.3624e-02,\n",
              "                       2.0136e-02, -1.3579e-02, -2.2899e-02, -1.4406e-02,  2.4088e-02,\n",
              "                      -9.2240e-03,  2.6004e-02,  4.2309e-03, -2.8261e-03, -3.2937e-02,\n",
              "                       3.1131e-02,  2.3983e-02,  2.5834e-02, -2.6628e-02, -2.7433e-03,\n",
              "                       1.2604e-02, -2.5830e-02,  7.5568e-03,  1.7652e-02,  2.4667e-02,\n",
              "                      -1.8043e-02,  3.3015e-02,  2.3048e-02, -2.3558e-02,  3.4824e-02,\n",
              "                      -2.8269e-02, -3.1550e-02, -2.7370e-02, -2.6664e-02,  7.4422e-03,\n",
              "                      -2.6541e-03,  3.2709e-02, -1.3939e-02, -2.2142e-03,  3.4098e-02,\n",
              "                      -2.3110e-02, -1.9643e-02,  2.7051e-02,  5.9541e-03,  1.0441e-02,\n",
              "                      -3.7375e-02,  1.6852e-02, -1.5934e-03,  3.5533e-02,  1.0102e-02,\n",
              "                       3.3332e-02,  1.0482e-02, -1.4666e-03, -9.0070e-04, -2.3667e-02,\n",
              "                       9.0613e-03,  3.0280e-02, -2.8597e-02, -4.7025e-03, -3.0936e-02,\n",
              "                       3.3503e-02,  7.9252e-03,  3.6596e-02,  2.0123e-02, -1.7245e-02,\n",
              "                       3.3844e-02,  3.7385e-03,  3.1676e-02, -3.1413e-03,  3.0088e-02,\n",
              "                       2.7965e-02,  9.2660e-03, -1.5061e-02,  2.0272e-02,  1.7319e-02,\n",
              "                       1.1421e-02,  1.6356e-02, -2.4352e-02,  2.3212e-02, -1.2722e-02,\n",
              "                      -9.1015e-03, -3.1929e-02, -1.6754e-03, -1.4019e-02,  3.1846e-02,\n",
              "                      -9.5939e-03,  2.3547e-02,  2.9385e-02,  2.3610e-02, -2.9643e-02,\n",
              "                      -3.4354e-02,  1.0636e-02,  3.2803e-02, -3.7144e-02,  1.3430e-02,\n",
              "                       4.3989e-03,  1.3182e-02, -3.5367e-02, -1.0653e-02, -2.4406e-02,\n",
              "                      -2.6916e-02,  1.7391e-02,  4.7808e-04,  2.8604e-02,  3.6015e-02,\n",
              "                       1.8232e-02, -3.7585e-02,  3.0150e-02,  1.7946e-02,  7.0479e-04,\n",
              "                       8.1254e-03, -1.2554e-03,  3.6734e-02,  1.0598e-02, -2.4759e-02,\n",
              "                      -2.6136e-02, -2.6340e-02,  2.1876e-02,  1.2150e-02,  1.5493e-02,\n",
              "                      -3.3803e-03,  2.9934e-02, -2.7638e-02,  2.2518e-02, -1.3672e-02,\n",
              "                       1.8667e-02,  3.6630e-02,  3.4238e-02, -1.9072e-02, -2.3200e-02,\n",
              "                       2.3868e-02, -4.1296e-03,  3.5641e-03, -1.7887e-02, -2.8080e-02,\n",
              "                       2.5498e-02,  2.9298e-02,  2.2406e-02, -2.5950e-03,  2.8695e-02,\n",
              "                       3.1996e-03,  3.5602e-02, -2.1324e-02, -1.2049e-02,  3.8762e-03,\n",
              "                       1.8266e-03, -3.7611e-02,  3.0309e-02, -2.4930e-02,  2.9155e-02,\n",
              "                      -3.2713e-02,  1.3671e-02, -1.9708e-02, -6.1535e-03, -1.0558e-02,\n",
              "                      -1.5693e-02, -3.4235e-02, -3.5057e-02,  1.6365e-02,  2.7775e-02,\n",
              "                      -3.3592e-02,  4.2016e-03,  9.7943e-03,  1.4701e-02, -2.3763e-02,\n",
              "                      -2.8359e-02, -2.5611e-02, -9.1226e-03,  4.2522e-03,  3.1462e-02,\n",
              "                      -2.0447e-02, -1.0213e-02, -1.2950e-02,  1.5270e-02, -1.2357e-02,\n",
              "                      -2.4148e-02, -1.3724e-02, -3.7999e-03,  1.8555e-02, -1.9261e-02,\n",
              "                      -2.4181e-02, -2.7522e-02, -2.5183e-02,  2.8741e-02,  2.1401e-02,\n",
              "                      -3.3081e-02,  2.3929e-02,  1.3709e-02, -3.1708e-02,  7.9679e-04,\n",
              "                       2.9082e-02,  3.7677e-02,  1.6617e-02, -3.7382e-02, -3.3329e-02,\n",
              "                      -1.0952e-02, -6.0063e-03,  2.9784e-02, -1.5767e-02,  7.5520e-03,\n",
              "                      -3.4725e-02, -1.1838e-02, -2.2909e-03, -1.1572e-02,  1.8612e-02,\n",
              "                      -7.8427e-03, -1.4418e-02,  3.5646e-02,  2.8472e-02, -2.9033e-03,\n",
              "                       3.7322e-02, -2.1974e-02, -1.8507e-03, -4.0348e-03, -1.5332e-02,\n",
              "                      -2.6000e-02, -1.8626e-02, -1.7881e-02, -2.8806e-02, -4.8746e-03,\n",
              "                       5.2117e-04, -3.5524e-02,  3.5276e-02,  1.9274e-02, -1.4597e-02,\n",
              "                       3.7489e-02,  2.4153e-02, -5.2726e-03,  3.5320e-02,  1.3490e-02,\n",
              "                      -2.2662e-02, -2.7852e-02, -1.0120e-02,  8.4886e-03, -3.0992e-02,\n",
              "                      -2.0506e-02,  7.5290e-04, -1.5898e-02,  1.6921e-02,  2.0459e-03,\n",
              "                      -1.7894e-02,  2.9129e-02, -5.4935e-03, -2.9863e-02,  1.9031e-03,\n",
              "                      -3.3494e-02,  2.4294e-02, -3.7473e-02, -1.8028e-03,  2.4746e-02,\n",
              "                       6.6127e-03,  2.1944e-02, -1.3487e-02,  2.9026e-02, -2.1637e-02,\n",
              "                      -2.6116e-02, -1.6284e-05, -7.8429e-03, -2.5580e-02, -3.3264e-02,\n",
              "                       2.3889e-02, -2.2489e-02,  3.3062e-02,  2.7630e-02, -2.4447e-02,\n",
              "                       1.5234e-02,  6.6940e-03,  3.6024e-02,  2.6909e-02, -2.7675e-02,\n",
              "                       5.4294e-03,  5.2006e-03,  2.9157e-02,  3.4057e-02,  6.1873e-04,\n",
              "                       1.3365e-02, -3.5609e-02, -1.8890e-02,  1.7682e-02, -5.2733e-03,\n",
              "                      -1.7077e-02, -2.4927e-02,  9.5001e-03,  1.3495e-02, -1.3850e-04,\n",
              "                      -3.6141e-02,  1.7146e-02, -3.0712e-02, -1.6967e-03, -1.8722e-02,\n",
              "                      -3.5153e-05,  1.5529e-02,  1.9934e-02, -2.4996e-02, -1.5817e-02,\n",
              "                       2.5603e-02, -5.3140e-03, -1.9459e-02, -9.2029e-03, -2.6543e-02,\n",
              "                       2.1321e-03,  2.9912e-02, -1.5243e-02, -7.7429e-03,  5.0050e-03,\n",
              "                       3.0519e-02, -7.3945e-03, -3.1097e-03, -1.3865e-02,  9.9026e-03,\n",
              "                      -3.2466e-02, -3.7627e-02, -1.3422e-02, -1.0427e-02,  2.1377e-03,\n",
              "                      -6.0688e-03,  2.8623e-02, -9.8816e-03, -1.5493e-02, -3.3663e-02,\n",
              "                      -1.2207e-02,  2.0714e-02,  7.5187e-03,  3.7671e-02,  3.1614e-04,\n",
              "                      -2.4504e-02, -3.7076e-02,  2.8945e-02, -2.3758e-02, -1.3764e-02,\n",
              "                       1.8083e-02,  2.4609e-02,  1.6331e-02,  1.9995e-02,  2.4576e-02,\n",
              "                       3.0222e-02, -4.0500e-03, -3.3403e-03, -1.6479e-02, -2.8774e-03,\n",
              "                       3.4440e-03, -6.8797e-03, -2.2185e-02,  3.1309e-02, -1.9372e-03,\n",
              "                      -2.4458e-02,  2.3783e-02,  2.2976e-02,  3.0641e-02, -1.9648e-02,\n",
              "                       2.1407e-03, -3.6643e-02, -2.4720e-02,  1.6860e-02, -2.2766e-02,\n",
              "                       1.4337e-02,  2.0908e-02,  1.5782e-02, -5.3099e-03,  9.5026e-03,\n",
              "                       3.2643e-02, -3.3406e-02, -1.7788e-02, -9.5856e-03, -1.9034e-03,\n",
              "                       2.6211e-02,  9.1809e-03,  8.5669e-03,  6.3824e-03, -6.7577e-03,\n",
              "                      -1.9724e-02, -1.6573e-02, -2.1311e-02,  2.8633e-02, -3.2395e-02,\n",
              "                       1.2633e-02, -1.5238e-02, -3.7148e-02,  5.4258e-03,  2.6598e-02,\n",
              "                      -3.4482e-02, -1.2404e-02,  1.3461e-02, -2.9659e-02,  1.5229e-02,\n",
              "                      -3.2967e-02, -3.2873e-03, -1.5344e-03,  3.0648e-02, -1.8912e-03,\n",
              "                       2.7574e-02,  2.2823e-02, -3.5906e-02, -5.1922e-03,  4.7518e-03,\n",
              "                      -7.5980e-03, -2.3305e-02,  1.6202e-02,  1.0993e-02,  1.2283e-02,\n",
              "                      -3.3819e-02, -5.9721e-03, -3.4620e-02,  2.0248e-02,  2.4543e-02])),\n",
              "             ('linear2.weight',\n",
              "              tensor([[-0.0402,  0.0283,  0.0263,  ...,  0.0190,  0.0062,  0.0207],\n",
              "                      [-0.0305,  0.0241, -0.0027,  ..., -0.0121,  0.0265, -0.0412],\n",
              "                      [ 0.0403,  0.0433, -0.0336,  ..., -0.0290,  0.0308,  0.0265],\n",
              "                      ...,\n",
              "                      [ 0.0118,  0.0286,  0.0321,  ...,  0.0309,  0.0178,  0.0350],\n",
              "                      [ 0.0219, -0.0409, -0.0249,  ..., -0.0075,  0.0112, -0.0412],\n",
              "                      [ 0.0391, -0.0251,  0.0126,  ..., -0.0289, -0.0140, -0.0266]])),\n",
              "             ('linear2.bias',\n",
              "              tensor([ 0.0034,  0.0428,  0.0163,  0.0247, -0.0372, -0.0156,  0.0023, -0.0048,\n",
              "                      -0.0259, -0.0240,  0.0109, -0.0052,  0.0053,  0.0254, -0.0429,  0.0255,\n",
              "                       0.0243, -0.0398, -0.0186,  0.0082,  0.0180,  0.0305, -0.0264, -0.0196,\n",
              "                       0.0145, -0.0173,  0.0378, -0.0424,  0.0216,  0.0083,  0.0173, -0.0260,\n",
              "                       0.0337,  0.0125, -0.0428, -0.0404,  0.0376, -0.0266, -0.0347,  0.0442,\n",
              "                      -0.0190, -0.0107, -0.0166, -0.0098,  0.0203, -0.0052, -0.0018,  0.0077,\n",
              "                       0.0134,  0.0328,  0.0032,  0.0238,  0.0382,  0.0102,  0.0097,  0.0187,\n",
              "                      -0.0257,  0.0304,  0.0388,  0.0267,  0.0269, -0.0171,  0.0414, -0.0082,\n",
              "                       0.0382,  0.0187,  0.0323,  0.0177, -0.0297,  0.0250,  0.0203,  0.0364,\n",
              "                       0.0275,  0.0013, -0.0099, -0.0447, -0.0296,  0.0409, -0.0354, -0.0015,\n",
              "                       0.0303, -0.0412,  0.0224,  0.0069, -0.0403,  0.0318,  0.0177,  0.0124,\n",
              "                      -0.0088, -0.0355,  0.0077, -0.0172,  0.0275,  0.0071, -0.0163, -0.0335,\n",
              "                      -0.0002, -0.0293,  0.0159, -0.0047,  0.0270, -0.0281, -0.0201,  0.0257,\n",
              "                      -0.0154,  0.0325, -0.0231,  0.0191,  0.0312, -0.0139, -0.0380, -0.0226,\n",
              "                      -0.0215, -0.0265,  0.0192,  0.0076,  0.0357,  0.0052, -0.0176, -0.0216,\n",
              "                       0.0255,  0.0401,  0.0425,  0.0320, -0.0433, -0.0057,  0.0347, -0.0163,\n",
              "                      -0.0105,  0.0146, -0.0071, -0.0056, -0.0186, -0.0376,  0.0144, -0.0251,\n",
              "                      -0.0066,  0.0323, -0.0032, -0.0388, -0.0142, -0.0332,  0.0375,  0.0266,\n",
              "                       0.0164, -0.0254, -0.0027,  0.0132, -0.0322,  0.0228, -0.0124, -0.0140,\n",
              "                       0.0079,  0.0076, -0.0159,  0.0333, -0.0412,  0.0066, -0.0095, -0.0001,\n",
              "                      -0.0306,  0.0094, -0.0402,  0.0313,  0.0328, -0.0134, -0.0336, -0.0189,\n",
              "                      -0.0128, -0.0377, -0.0234,  0.0050, -0.0004,  0.0179,  0.0183,  0.0401,\n",
              "                      -0.0184,  0.0123,  0.0027,  0.0301,  0.0408,  0.0343,  0.0263,  0.0422,\n",
              "                       0.0231,  0.0026, -0.0023, -0.0075,  0.0187,  0.0014, -0.0090, -0.0163,\n",
              "                      -0.0328, -0.0188,  0.0005, -0.0049, -0.0378, -0.0005, -0.0088, -0.0380,\n",
              "                      -0.0235,  0.0329,  0.0130, -0.0275, -0.0137, -0.0309,  0.0368, -0.0369,\n",
              "                      -0.0247, -0.0003,  0.0401,  0.0368, -0.0339, -0.0029, -0.0118,  0.0232,\n",
              "                       0.0173, -0.0110,  0.0205,  0.0209, -0.0284, -0.0289,  0.0430,  0.0308,\n",
              "                      -0.0020,  0.0035, -0.0219,  0.0291, -0.0140,  0.0424, -0.0437,  0.0114,\n",
              "                       0.0133,  0.0420,  0.0039,  0.0360,  0.0274, -0.0182, -0.0238, -0.0114,\n",
              "                       0.0217,  0.0340,  0.0350,  0.0208, -0.0355,  0.0403, -0.0026,  0.0167,\n",
              "                      -0.0211,  0.0303, -0.0166, -0.0219, -0.0043,  0.0292,  0.0298, -0.0430,\n",
              "                       0.0053,  0.0332, -0.0226,  0.0320,  0.0116, -0.0146,  0.0235, -0.0323,\n",
              "                      -0.0343,  0.0267,  0.0183, -0.0350,  0.0055,  0.0326,  0.0191, -0.0109,\n",
              "                      -0.0311,  0.0128, -0.0161,  0.0077, -0.0094,  0.0183,  0.0277, -0.0069,\n",
              "                      -0.0343,  0.0024, -0.0315,  0.0268,  0.0201,  0.0077, -0.0255, -0.0027,\n",
              "                      -0.0027, -0.0297,  0.0177, -0.0031,  0.0281, -0.0095, -0.0157, -0.0318,\n",
              "                       0.0219, -0.0220,  0.0027, -0.0091,  0.0198,  0.0192, -0.0345, -0.0232,\n",
              "                      -0.0309,  0.0443,  0.0163,  0.0328, -0.0377,  0.0066, -0.0173, -0.0147,\n",
              "                       0.0334,  0.0035,  0.0246,  0.0019,  0.0070,  0.0273, -0.0067, -0.0068,\n",
              "                      -0.0083, -0.0153,  0.0023, -0.0366, -0.0041,  0.0238,  0.0346,  0.0154,\n",
              "                      -0.0263, -0.0352,  0.0359,  0.0183,  0.0060, -0.0109,  0.0295, -0.0166,\n",
              "                      -0.0255, -0.0009,  0.0141,  0.0207, -0.0369,  0.0431, -0.0343, -0.0059,\n",
              "                       0.0005, -0.0426, -0.0205,  0.0071,  0.0189,  0.0141,  0.0193, -0.0289,\n",
              "                       0.0420, -0.0094,  0.0227, -0.0156,  0.0172, -0.0100, -0.0446,  0.0222,\n",
              "                       0.0106, -0.0234, -0.0366, -0.0316, -0.0368, -0.0150,  0.0055, -0.0385,\n",
              "                       0.0074, -0.0224,  0.0145, -0.0356,  0.0046, -0.0014,  0.0252, -0.0010,\n",
              "                       0.0193, -0.0380,  0.0412, -0.0083, -0.0372, -0.0382,  0.0230,  0.0130,\n",
              "                       0.0241, -0.0325, -0.0090,  0.0145,  0.0231,  0.0293, -0.0098, -0.0035,\n",
              "                       0.0172,  0.0435,  0.0426, -0.0172,  0.0042, -0.0352, -0.0437,  0.0295,\n",
              "                      -0.0196,  0.0346, -0.0368, -0.0039, -0.0299, -0.0319,  0.0338,  0.0254,\n",
              "                       0.0175, -0.0219,  0.0353, -0.0334, -0.0119,  0.0362,  0.0377, -0.0135,\n",
              "                      -0.0042,  0.0070,  0.0133,  0.0143, -0.0163,  0.0049,  0.0337,  0.0231,\n",
              "                      -0.0323,  0.0243,  0.0404, -0.0274,  0.0171,  0.0389,  0.0006, -0.0441,\n",
              "                      -0.0015, -0.0445,  0.0340,  0.0421,  0.0114, -0.0243, -0.0092, -0.0402,\n",
              "                       0.0016,  0.0049,  0.0011, -0.0377,  0.0003,  0.0236, -0.0369,  0.0330,\n",
              "                      -0.0005,  0.0161, -0.0268, -0.0152,  0.0424,  0.0336, -0.0438, -0.0328,\n",
              "                      -0.0392, -0.0430,  0.0233, -0.0151,  0.0340, -0.0388,  0.0149, -0.0097,\n",
              "                      -0.0181,  0.0034,  0.0190, -0.0280, -0.0114, -0.0167,  0.0292,  0.0191,\n",
              "                       0.0217, -0.0078, -0.0175,  0.0302,  0.0136, -0.0443,  0.0172, -0.0002,\n",
              "                       0.0037, -0.0260, -0.0222,  0.0424,  0.0394,  0.0116,  0.0409, -0.0421,\n",
              "                       0.0146, -0.0284, -0.0217, -0.0313, -0.0356, -0.0395, -0.0080, -0.0419,\n",
              "                       0.0215, -0.0424, -0.0353, -0.0124])),\n",
              "             ('linear3.weight',\n",
              "              tensor([[ 0.0313, -0.0056,  0.0156,  ..., -0.0097,  0.0022, -0.0443],\n",
              "                      [-0.0181,  0.0347, -0.0230,  ..., -0.0166,  0.0020, -0.0419],\n",
              "                      [-0.0376,  0.0236, -0.0180,  ...,  0.0371, -0.0164,  0.0314],\n",
              "                      ...,\n",
              "                      [ 0.0395, -0.0152,  0.0260,  ...,  0.0249,  0.0231, -0.0141],\n",
              "                      [ 0.0130, -0.0265, -0.0054,  ..., -0.0264, -0.0314,  0.0319],\n",
              "                      [-0.0426, -0.0290, -0.0283,  ..., -0.0154, -0.0330,  0.0123]])),\n",
              "             ('linear3.bias',\n",
              "              tensor([ 0.0406, -0.0222, -0.0079,  0.0007,  0.0099, -0.0348, -0.0156, -0.0126,\n",
              "                       0.0221,  0.0215]))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"model.pt\")"
      ],
      "metadata": {
        "id": "zniRL0ykMCYk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kRWndYr7IT0H",
        "outputId": "109c4233-f662-4201-ebc3-95f897cee4f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-daa6e0a94d49>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(\"model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "net.load_state_dict(torch.load(\"model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uVXw-XiAIT0H",
        "outputId": "751392d6-0167-4ef4-eb00-d0ae7574b080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "net(input_tensor).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cI-APVdDIT0H",
        "outputId": "c659835f-1083-4b90-c853-509f8c6b2ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTaskNetwork(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# net.to(torch.device('cuda:0'))\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FVU8ZIERIT0I",
        "outputId": "19a04e64-b16b-491c-a524-eb0b2b2544b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "net.linear1.weight.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HHq8QP5VIT0I",
        "outputId": "86f09c9a-8a21-4a9d-b42f-5548f9c7a7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ec5a8680da8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-a79b60dd2c25>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "net(input_tensor).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Geeqfm7xIT0I",
        "outputId": "6e9650ff-db91-4291-c2a9-a276b39997b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "net(input_tensor.cuda()).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wPmMmKxnIT0J",
        "outputId": "ceec55ce-d71b-4c3b-fd03-deb55b03005a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTaskNetwork(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "net.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hIlDUG7eIT0J",
        "outputId": "e8ff9082-2333-4ba8-d6fe-914fcc0a71c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTaskNetwork(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-lyyknMeIT0J",
        "outputId": "5dfd592d-1e59-43f3-93d5-dc417730f41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "net.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d3G6JYzDIT0J",
        "outputId": "873c9832-9c7a-4a64-b6d1-0beec29697e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTaskNetwork(\n",
              "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
              "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WML1JOeGIT0K",
        "outputId": "b585b449-b39c-495d-9166-ef80171f6076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "net.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fTei3n4cIT0K",
        "outputId": "e225e50f-7d63-488b-9460-3ed5e4903bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
              "        [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
              "        [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
              "        ...,\n",
              "        [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
              "        [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
              "        [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "net.linear1.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "id": "xVtBTxzZIT0K",
        "outputId": "f502a875-366c-4a81-fc2b-0735e175ea15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
              "         [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
              "         [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
              "         ...,\n",
              "         [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
              "         [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
              "         [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-2.1088e-02,  1.0055e-02, -7.7552e-03, -1.9122e-02, -3.3471e-02,\n",
              "         -2.0890e-02,  1.7957e-02,  2.6099e-02,  3.0136e-02, -3.0112e-02,\n",
              "          2.7849e-02, -1.2145e-02, -2.8552e-02,  1.0605e-02, -7.8391e-03,\n",
              "         -2.5345e-02,  6.5207e-03,  3.5297e-02,  1.6740e-02,  6.9777e-03,\n",
              "         -3.3125e-02,  1.8327e-02,  1.6675e-02,  1.7545e-02,  7.4183e-03,\n",
              "         -3.3241e-02,  6.3233e-03, -1.6696e-02, -1.5523e-02, -2.8453e-02,\n",
              "          6.5478e-03,  2.4674e-02, -3.0306e-02, -1.9385e-02,  1.4468e-02,\n",
              "         -2.1729e-03, -8.4098e-03, -3.4562e-02, -3.6783e-02,  2.9103e-02,\n",
              "         -1.9729e-02, -2.3040e-02,  2.1877e-02,  6.0152e-03,  1.1391e-02,\n",
              "         -6.1097e-03,  3.3665e-02, -8.8738e-03,  2.9855e-02, -3.3741e-02,\n",
              "         -1.2577e-02,  3.6876e-02,  8.4248e-03,  2.4642e-02,  1.0302e-02,\n",
              "         -6.1079e-05,  7.1781e-03, -8.0475e-03,  3.1832e-02,  2.9259e-02,\n",
              "         -1.5856e-03,  1.4783e-02,  1.7176e-02,  1.3105e-02, -6.7287e-03,\n",
              "          7.3206e-03,  2.7062e-02, -1.4028e-02,  2.2943e-02,  2.3746e-02,\n",
              "         -3.6304e-02,  3.6079e-02, -2.3212e-02, -3.6907e-02,  2.5203e-02,\n",
              "         -1.2118e-02,  2.9581e-02,  2.1207e-02, -1.2558e-02,  1.9321e-02,\n",
              "         -8.6805e-03,  2.7435e-02, -2.9800e-02, -7.4419e-03,  3.1814e-02,\n",
              "         -2.1617e-02,  4.0231e-03,  1.6897e-03, -2.7224e-02,  2.2252e-02,\n",
              "         -7.8276e-03, -5.8323e-03,  2.1604e-02,  2.0243e-02, -3.0634e-02,\n",
              "         -2.7636e-02,  2.7618e-02, -3.7075e-02,  2.7422e-02,  3.3624e-02,\n",
              "          2.0136e-02, -1.3579e-02, -2.2899e-02, -1.4406e-02,  2.4088e-02,\n",
              "         -9.2240e-03,  2.6004e-02,  4.2309e-03, -2.8261e-03, -3.2937e-02,\n",
              "          3.1131e-02,  2.3983e-02,  2.5834e-02, -2.6628e-02, -2.7433e-03,\n",
              "          1.2604e-02, -2.5830e-02,  7.5568e-03,  1.7652e-02,  2.4667e-02,\n",
              "         -1.8043e-02,  3.3015e-02,  2.3048e-02, -2.3558e-02,  3.4824e-02,\n",
              "         -2.8269e-02, -3.1550e-02, -2.7370e-02, -2.6664e-02,  7.4422e-03,\n",
              "         -2.6541e-03,  3.2709e-02, -1.3939e-02, -2.2142e-03,  3.4098e-02,\n",
              "         -2.3110e-02, -1.9643e-02,  2.7051e-02,  5.9541e-03,  1.0441e-02,\n",
              "         -3.7375e-02,  1.6852e-02, -1.5934e-03,  3.5533e-02,  1.0102e-02,\n",
              "          3.3332e-02,  1.0482e-02, -1.4666e-03, -9.0070e-04, -2.3667e-02,\n",
              "          9.0613e-03,  3.0280e-02, -2.8597e-02, -4.7025e-03, -3.0936e-02,\n",
              "          3.3503e-02,  7.9252e-03,  3.6596e-02,  2.0123e-02, -1.7245e-02,\n",
              "          3.3844e-02,  3.7385e-03,  3.1676e-02, -3.1413e-03,  3.0088e-02,\n",
              "          2.7965e-02,  9.2660e-03, -1.5061e-02,  2.0272e-02,  1.7319e-02,\n",
              "          1.1421e-02,  1.6356e-02, -2.4352e-02,  2.3212e-02, -1.2722e-02,\n",
              "         -9.1015e-03, -3.1929e-02, -1.6754e-03, -1.4019e-02,  3.1846e-02,\n",
              "         -9.5939e-03,  2.3547e-02,  2.9385e-02,  2.3610e-02, -2.9643e-02,\n",
              "         -3.4354e-02,  1.0636e-02,  3.2803e-02, -3.7144e-02,  1.3430e-02,\n",
              "          4.3989e-03,  1.3182e-02, -3.5367e-02, -1.0653e-02, -2.4406e-02,\n",
              "         -2.6916e-02,  1.7391e-02,  4.7808e-04,  2.8604e-02,  3.6015e-02,\n",
              "          1.8232e-02, -3.7585e-02,  3.0150e-02,  1.7946e-02,  7.0479e-04,\n",
              "          8.1254e-03, -1.2554e-03,  3.6734e-02,  1.0598e-02, -2.4759e-02,\n",
              "         -2.6136e-02, -2.6340e-02,  2.1876e-02,  1.2150e-02,  1.5493e-02,\n",
              "         -3.3803e-03,  2.9934e-02, -2.7638e-02,  2.2518e-02, -1.3672e-02,\n",
              "          1.8667e-02,  3.6630e-02,  3.4238e-02, -1.9072e-02, -2.3200e-02,\n",
              "          2.3868e-02, -4.1296e-03,  3.5641e-03, -1.7887e-02, -2.8080e-02,\n",
              "          2.5498e-02,  2.9298e-02,  2.2406e-02, -2.5950e-03,  2.8695e-02,\n",
              "          3.1996e-03,  3.5602e-02, -2.1324e-02, -1.2049e-02,  3.8762e-03,\n",
              "          1.8266e-03, -3.7611e-02,  3.0309e-02, -2.4930e-02,  2.9155e-02,\n",
              "         -3.2713e-02,  1.3671e-02, -1.9708e-02, -6.1535e-03, -1.0558e-02,\n",
              "         -1.5693e-02, -3.4235e-02, -3.5057e-02,  1.6365e-02,  2.7775e-02,\n",
              "         -3.3592e-02,  4.2016e-03,  9.7943e-03,  1.4701e-02, -2.3763e-02,\n",
              "         -2.8359e-02, -2.5611e-02, -9.1226e-03,  4.2522e-03,  3.1462e-02,\n",
              "         -2.0447e-02, -1.0213e-02, -1.2950e-02,  1.5270e-02, -1.2357e-02,\n",
              "         -2.4148e-02, -1.3724e-02, -3.7999e-03,  1.8555e-02, -1.9261e-02,\n",
              "         -2.4181e-02, -2.7522e-02, -2.5183e-02,  2.8741e-02,  2.1401e-02,\n",
              "         -3.3081e-02,  2.3929e-02,  1.3709e-02, -3.1708e-02,  7.9679e-04,\n",
              "          2.9082e-02,  3.7677e-02,  1.6617e-02, -3.7382e-02, -3.3329e-02,\n",
              "         -1.0952e-02, -6.0063e-03,  2.9784e-02, -1.5767e-02,  7.5520e-03,\n",
              "         -3.4725e-02, -1.1838e-02, -2.2909e-03, -1.1572e-02,  1.8612e-02,\n",
              "         -7.8427e-03, -1.4418e-02,  3.5646e-02,  2.8472e-02, -2.9033e-03,\n",
              "          3.7322e-02, -2.1974e-02, -1.8507e-03, -4.0348e-03, -1.5332e-02,\n",
              "         -2.6000e-02, -1.8626e-02, -1.7881e-02, -2.8806e-02, -4.8746e-03,\n",
              "          5.2117e-04, -3.5524e-02,  3.5276e-02,  1.9274e-02, -1.4597e-02,\n",
              "          3.7489e-02,  2.4153e-02, -5.2726e-03,  3.5320e-02,  1.3490e-02,\n",
              "         -2.2662e-02, -2.7852e-02, -1.0120e-02,  8.4886e-03, -3.0992e-02,\n",
              "         -2.0506e-02,  7.5290e-04, -1.5898e-02,  1.6921e-02,  2.0459e-03,\n",
              "         -1.7894e-02,  2.9129e-02, -5.4935e-03, -2.9863e-02,  1.9031e-03,\n",
              "         -3.3494e-02,  2.4294e-02, -3.7473e-02, -1.8028e-03,  2.4746e-02,\n",
              "          6.6127e-03,  2.1944e-02, -1.3487e-02,  2.9026e-02, -2.1637e-02,\n",
              "         -2.6116e-02, -1.6284e-05, -7.8429e-03, -2.5580e-02, -3.3264e-02,\n",
              "          2.3889e-02, -2.2489e-02,  3.3062e-02,  2.7630e-02, -2.4447e-02,\n",
              "          1.5234e-02,  6.6940e-03,  3.6024e-02,  2.6909e-02, -2.7675e-02,\n",
              "          5.4294e-03,  5.2006e-03,  2.9157e-02,  3.4057e-02,  6.1873e-04,\n",
              "          1.3365e-02, -3.5609e-02, -1.8890e-02,  1.7682e-02, -5.2733e-03,\n",
              "         -1.7077e-02, -2.4927e-02,  9.5001e-03,  1.3495e-02, -1.3850e-04,\n",
              "         -3.6141e-02,  1.7146e-02, -3.0712e-02, -1.6967e-03, -1.8722e-02,\n",
              "         -3.5153e-05,  1.5529e-02,  1.9934e-02, -2.4996e-02, -1.5817e-02,\n",
              "          2.5603e-02, -5.3140e-03, -1.9459e-02, -9.2029e-03, -2.6543e-02,\n",
              "          2.1321e-03,  2.9912e-02, -1.5243e-02, -7.7429e-03,  5.0050e-03,\n",
              "          3.0519e-02, -7.3945e-03, -3.1097e-03, -1.3865e-02,  9.9026e-03,\n",
              "         -3.2466e-02, -3.7627e-02, -1.3422e-02, -1.0427e-02,  2.1377e-03,\n",
              "         -6.0688e-03,  2.8623e-02, -9.8816e-03, -1.5493e-02, -3.3663e-02,\n",
              "         -1.2207e-02,  2.0714e-02,  7.5187e-03,  3.7671e-02,  3.1614e-04,\n",
              "         -2.4504e-02, -3.7076e-02,  2.8945e-02, -2.3758e-02, -1.3764e-02,\n",
              "          1.8083e-02,  2.4609e-02,  1.6331e-02,  1.9995e-02,  2.4576e-02,\n",
              "          3.0222e-02, -4.0500e-03, -3.3403e-03, -1.6479e-02, -2.8774e-03,\n",
              "          3.4440e-03, -6.8797e-03, -2.2185e-02,  3.1309e-02, -1.9372e-03,\n",
              "         -2.4458e-02,  2.3783e-02,  2.2976e-02,  3.0641e-02, -1.9648e-02,\n",
              "          2.1407e-03, -3.6643e-02, -2.4720e-02,  1.6860e-02, -2.2766e-02,\n",
              "          1.4337e-02,  2.0908e-02,  1.5782e-02, -5.3099e-03,  9.5026e-03,\n",
              "          3.2643e-02, -3.3406e-02, -1.7788e-02, -9.5856e-03, -1.9034e-03,\n",
              "          2.6211e-02,  9.1809e-03,  8.5669e-03,  6.3824e-03, -6.7577e-03,\n",
              "         -1.9724e-02, -1.6573e-02, -2.1311e-02,  2.8633e-02, -3.2395e-02,\n",
              "          1.2633e-02, -1.5238e-02, -3.7148e-02,  5.4258e-03,  2.6598e-02,\n",
              "         -3.4482e-02, -1.2404e-02,  1.3461e-02, -2.9659e-02,  1.5229e-02,\n",
              "         -3.2967e-02, -3.2873e-03, -1.5344e-03,  3.0648e-02, -1.8912e-03,\n",
              "          2.7574e-02,  2.2823e-02, -3.5906e-02, -5.1922e-03,  4.7518e-03,\n",
              "         -7.5980e-03, -2.3305e-02,  1.6202e-02,  1.0993e-02,  1.2283e-02,\n",
              "         -3.3819e-02, -5.9721e-03, -3.4620e-02,  2.0248e-02,  2.4543e-02],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0402,  0.0283,  0.0263,  ...,  0.0190,  0.0062,  0.0207],\n",
              "         [-0.0305,  0.0241, -0.0027,  ..., -0.0121,  0.0265, -0.0412],\n",
              "         [ 0.0403,  0.0433, -0.0336,  ..., -0.0290,  0.0308,  0.0265],\n",
              "         ...,\n",
              "         [ 0.0118,  0.0286,  0.0321,  ...,  0.0309,  0.0178,  0.0350],\n",
              "         [ 0.0219, -0.0409, -0.0249,  ..., -0.0075,  0.0112, -0.0412],\n",
              "         [ 0.0391, -0.0251,  0.0126,  ..., -0.0289, -0.0140, -0.0266]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0034,  0.0428,  0.0163,  0.0247, -0.0372, -0.0156,  0.0023, -0.0048,\n",
              "         -0.0259, -0.0240,  0.0109, -0.0052,  0.0053,  0.0254, -0.0429,  0.0255,\n",
              "          0.0243, -0.0398, -0.0186,  0.0082,  0.0180,  0.0305, -0.0264, -0.0196,\n",
              "          0.0145, -0.0173,  0.0378, -0.0424,  0.0216,  0.0083,  0.0173, -0.0260,\n",
              "          0.0337,  0.0125, -0.0428, -0.0404,  0.0376, -0.0266, -0.0347,  0.0442,\n",
              "         -0.0190, -0.0107, -0.0166, -0.0098,  0.0203, -0.0052, -0.0018,  0.0077,\n",
              "          0.0134,  0.0328,  0.0032,  0.0238,  0.0382,  0.0102,  0.0097,  0.0187,\n",
              "         -0.0257,  0.0304,  0.0388,  0.0267,  0.0269, -0.0171,  0.0414, -0.0082,\n",
              "          0.0382,  0.0187,  0.0323,  0.0177, -0.0297,  0.0250,  0.0203,  0.0364,\n",
              "          0.0275,  0.0013, -0.0099, -0.0447, -0.0296,  0.0409, -0.0354, -0.0015,\n",
              "          0.0303, -0.0412,  0.0224,  0.0069, -0.0403,  0.0318,  0.0177,  0.0124,\n",
              "         -0.0088, -0.0355,  0.0077, -0.0172,  0.0275,  0.0071, -0.0163, -0.0335,\n",
              "         -0.0002, -0.0293,  0.0159, -0.0047,  0.0270, -0.0281, -0.0201,  0.0257,\n",
              "         -0.0154,  0.0325, -0.0231,  0.0191,  0.0312, -0.0139, -0.0380, -0.0226,\n",
              "         -0.0215, -0.0265,  0.0192,  0.0076,  0.0357,  0.0052, -0.0176, -0.0216,\n",
              "          0.0255,  0.0401,  0.0425,  0.0320, -0.0433, -0.0057,  0.0347, -0.0163,\n",
              "         -0.0105,  0.0146, -0.0071, -0.0056, -0.0186, -0.0376,  0.0144, -0.0251,\n",
              "         -0.0066,  0.0323, -0.0032, -0.0388, -0.0142, -0.0332,  0.0375,  0.0266,\n",
              "          0.0164, -0.0254, -0.0027,  0.0132, -0.0322,  0.0228, -0.0124, -0.0140,\n",
              "          0.0079,  0.0076, -0.0159,  0.0333, -0.0412,  0.0066, -0.0095, -0.0001,\n",
              "         -0.0306,  0.0094, -0.0402,  0.0313,  0.0328, -0.0134, -0.0336, -0.0189,\n",
              "         -0.0128, -0.0377, -0.0234,  0.0050, -0.0004,  0.0179,  0.0183,  0.0401,\n",
              "         -0.0184,  0.0123,  0.0027,  0.0301,  0.0408,  0.0343,  0.0263,  0.0422,\n",
              "          0.0231,  0.0026, -0.0023, -0.0075,  0.0187,  0.0014, -0.0090, -0.0163,\n",
              "         -0.0328, -0.0188,  0.0005, -0.0049, -0.0378, -0.0005, -0.0088, -0.0380,\n",
              "         -0.0235,  0.0329,  0.0130, -0.0275, -0.0137, -0.0309,  0.0368, -0.0369,\n",
              "         -0.0247, -0.0003,  0.0401,  0.0368, -0.0339, -0.0029, -0.0118,  0.0232,\n",
              "          0.0173, -0.0110,  0.0205,  0.0209, -0.0284, -0.0289,  0.0430,  0.0308,\n",
              "         -0.0020,  0.0035, -0.0219,  0.0291, -0.0140,  0.0424, -0.0437,  0.0114,\n",
              "          0.0133,  0.0420,  0.0039,  0.0360,  0.0274, -0.0182, -0.0238, -0.0114,\n",
              "          0.0217,  0.0340,  0.0350,  0.0208, -0.0355,  0.0403, -0.0026,  0.0167,\n",
              "         -0.0211,  0.0303, -0.0166, -0.0219, -0.0043,  0.0292,  0.0298, -0.0430,\n",
              "          0.0053,  0.0332, -0.0226,  0.0320,  0.0116, -0.0146,  0.0235, -0.0323,\n",
              "         -0.0343,  0.0267,  0.0183, -0.0350,  0.0055,  0.0326,  0.0191, -0.0109,\n",
              "         -0.0311,  0.0128, -0.0161,  0.0077, -0.0094,  0.0183,  0.0277, -0.0069,\n",
              "         -0.0343,  0.0024, -0.0315,  0.0268,  0.0201,  0.0077, -0.0255, -0.0027,\n",
              "         -0.0027, -0.0297,  0.0177, -0.0031,  0.0281, -0.0095, -0.0157, -0.0318,\n",
              "          0.0219, -0.0220,  0.0027, -0.0091,  0.0198,  0.0192, -0.0345, -0.0232,\n",
              "         -0.0309,  0.0443,  0.0163,  0.0328, -0.0377,  0.0066, -0.0173, -0.0147,\n",
              "          0.0334,  0.0035,  0.0246,  0.0019,  0.0070,  0.0273, -0.0067, -0.0068,\n",
              "         -0.0083, -0.0153,  0.0023, -0.0366, -0.0041,  0.0238,  0.0346,  0.0154,\n",
              "         -0.0263, -0.0352,  0.0359,  0.0183,  0.0060, -0.0109,  0.0295, -0.0166,\n",
              "         -0.0255, -0.0009,  0.0141,  0.0207, -0.0369,  0.0431, -0.0343, -0.0059,\n",
              "          0.0005, -0.0426, -0.0205,  0.0071,  0.0189,  0.0141,  0.0193, -0.0289,\n",
              "          0.0420, -0.0094,  0.0227, -0.0156,  0.0172, -0.0100, -0.0446,  0.0222,\n",
              "          0.0106, -0.0234, -0.0366, -0.0316, -0.0368, -0.0150,  0.0055, -0.0385,\n",
              "          0.0074, -0.0224,  0.0145, -0.0356,  0.0046, -0.0014,  0.0252, -0.0010,\n",
              "          0.0193, -0.0380,  0.0412, -0.0083, -0.0372, -0.0382,  0.0230,  0.0130,\n",
              "          0.0241, -0.0325, -0.0090,  0.0145,  0.0231,  0.0293, -0.0098, -0.0035,\n",
              "          0.0172,  0.0435,  0.0426, -0.0172,  0.0042, -0.0352, -0.0437,  0.0295,\n",
              "         -0.0196,  0.0346, -0.0368, -0.0039, -0.0299, -0.0319,  0.0338,  0.0254,\n",
              "          0.0175, -0.0219,  0.0353, -0.0334, -0.0119,  0.0362,  0.0377, -0.0135,\n",
              "         -0.0042,  0.0070,  0.0133,  0.0143, -0.0163,  0.0049,  0.0337,  0.0231,\n",
              "         -0.0323,  0.0243,  0.0404, -0.0274,  0.0171,  0.0389,  0.0006, -0.0441,\n",
              "         -0.0015, -0.0445,  0.0340,  0.0421,  0.0114, -0.0243, -0.0092, -0.0402,\n",
              "          0.0016,  0.0049,  0.0011, -0.0377,  0.0003,  0.0236, -0.0369,  0.0330,\n",
              "         -0.0005,  0.0161, -0.0268, -0.0152,  0.0424,  0.0336, -0.0438, -0.0328,\n",
              "         -0.0392, -0.0430,  0.0233, -0.0151,  0.0340, -0.0388,  0.0149, -0.0097,\n",
              "         -0.0181,  0.0034,  0.0190, -0.0280, -0.0114, -0.0167,  0.0292,  0.0191,\n",
              "          0.0217, -0.0078, -0.0175,  0.0302,  0.0136, -0.0443,  0.0172, -0.0002,\n",
              "          0.0037, -0.0260, -0.0222,  0.0424,  0.0394,  0.0116,  0.0409, -0.0421,\n",
              "          0.0146, -0.0284, -0.0217, -0.0313, -0.0356, -0.0395, -0.0080, -0.0419,\n",
              "          0.0215, -0.0424, -0.0353, -0.0124], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0313, -0.0056,  0.0156,  ..., -0.0097,  0.0022, -0.0443],\n",
              "         [-0.0181,  0.0347, -0.0230,  ..., -0.0166,  0.0020, -0.0419],\n",
              "         [-0.0376,  0.0236, -0.0180,  ...,  0.0371, -0.0164,  0.0314],\n",
              "         ...,\n",
              "         [ 0.0395, -0.0152,  0.0260,  ...,  0.0249,  0.0231, -0.0141],\n",
              "         [ 0.0130, -0.0265, -0.0054,  ..., -0.0264, -0.0314,  0.0319],\n",
              "         [-0.0426, -0.0290, -0.0283,  ..., -0.0154, -0.0330,  0.0123]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0406, -0.0222, -0.0079,  0.0007,  0.0099, -0.0348, -0.0156, -0.0126,\n",
              "          0.0221,  0.0215], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "list(net.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "id": "wHWqnJOQIT0K",
        "outputId": "31212a6b-9445-47ed-b811-fe8a29193431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear1.weight',\n",
              "              tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
              "                      [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
              "                      [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
              "                      ...,\n",
              "                      [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
              "                      [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
              "                      [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]])),\n",
              "             ('linear1.bias',\n",
              "              tensor([-2.1088e-02,  1.0055e-02, -7.7552e-03, -1.9122e-02, -3.3471e-02,\n",
              "                      -2.0890e-02,  1.7957e-02,  2.6099e-02,  3.0136e-02, -3.0112e-02,\n",
              "                       2.7849e-02, -1.2145e-02, -2.8552e-02,  1.0605e-02, -7.8391e-03,\n",
              "                      -2.5345e-02,  6.5207e-03,  3.5297e-02,  1.6740e-02,  6.9777e-03,\n",
              "                      -3.3125e-02,  1.8327e-02,  1.6675e-02,  1.7545e-02,  7.4183e-03,\n",
              "                      -3.3241e-02,  6.3233e-03, -1.6696e-02, -1.5523e-02, -2.8453e-02,\n",
              "                       6.5478e-03,  2.4674e-02, -3.0306e-02, -1.9385e-02,  1.4468e-02,\n",
              "                      -2.1729e-03, -8.4098e-03, -3.4562e-02, -3.6783e-02,  2.9103e-02,\n",
              "                      -1.9729e-02, -2.3040e-02,  2.1877e-02,  6.0152e-03,  1.1391e-02,\n",
              "                      -6.1097e-03,  3.3665e-02, -8.8738e-03,  2.9855e-02, -3.3741e-02,\n",
              "                      -1.2577e-02,  3.6876e-02,  8.4248e-03,  2.4642e-02,  1.0302e-02,\n",
              "                      -6.1079e-05,  7.1781e-03, -8.0475e-03,  3.1832e-02,  2.9259e-02,\n",
              "                      -1.5856e-03,  1.4783e-02,  1.7176e-02,  1.3105e-02, -6.7287e-03,\n",
              "                       7.3206e-03,  2.7062e-02, -1.4028e-02,  2.2943e-02,  2.3746e-02,\n",
              "                      -3.6304e-02,  3.6079e-02, -2.3212e-02, -3.6907e-02,  2.5203e-02,\n",
              "                      -1.2118e-02,  2.9581e-02,  2.1207e-02, -1.2558e-02,  1.9321e-02,\n",
              "                      -8.6805e-03,  2.7435e-02, -2.9800e-02, -7.4419e-03,  3.1814e-02,\n",
              "                      -2.1617e-02,  4.0231e-03,  1.6897e-03, -2.7224e-02,  2.2252e-02,\n",
              "                      -7.8276e-03, -5.8323e-03,  2.1604e-02,  2.0243e-02, -3.0634e-02,\n",
              "                      -2.7636e-02,  2.7618e-02, -3.7075e-02,  2.7422e-02,  3.3624e-02,\n",
              "                       2.0136e-02, -1.3579e-02, -2.2899e-02, -1.4406e-02,  2.4088e-02,\n",
              "                      -9.2240e-03,  2.6004e-02,  4.2309e-03, -2.8261e-03, -3.2937e-02,\n",
              "                       3.1131e-02,  2.3983e-02,  2.5834e-02, -2.6628e-02, -2.7433e-03,\n",
              "                       1.2604e-02, -2.5830e-02,  7.5568e-03,  1.7652e-02,  2.4667e-02,\n",
              "                      -1.8043e-02,  3.3015e-02,  2.3048e-02, -2.3558e-02,  3.4824e-02,\n",
              "                      -2.8269e-02, -3.1550e-02, -2.7370e-02, -2.6664e-02,  7.4422e-03,\n",
              "                      -2.6541e-03,  3.2709e-02, -1.3939e-02, -2.2142e-03,  3.4098e-02,\n",
              "                      -2.3110e-02, -1.9643e-02,  2.7051e-02,  5.9541e-03,  1.0441e-02,\n",
              "                      -3.7375e-02,  1.6852e-02, -1.5934e-03,  3.5533e-02,  1.0102e-02,\n",
              "                       3.3332e-02,  1.0482e-02, -1.4666e-03, -9.0070e-04, -2.3667e-02,\n",
              "                       9.0613e-03,  3.0280e-02, -2.8597e-02, -4.7025e-03, -3.0936e-02,\n",
              "                       3.3503e-02,  7.9252e-03,  3.6596e-02,  2.0123e-02, -1.7245e-02,\n",
              "                       3.3844e-02,  3.7385e-03,  3.1676e-02, -3.1413e-03,  3.0088e-02,\n",
              "                       2.7965e-02,  9.2660e-03, -1.5061e-02,  2.0272e-02,  1.7319e-02,\n",
              "                       1.1421e-02,  1.6356e-02, -2.4352e-02,  2.3212e-02, -1.2722e-02,\n",
              "                      -9.1015e-03, -3.1929e-02, -1.6754e-03, -1.4019e-02,  3.1846e-02,\n",
              "                      -9.5939e-03,  2.3547e-02,  2.9385e-02,  2.3610e-02, -2.9643e-02,\n",
              "                      -3.4354e-02,  1.0636e-02,  3.2803e-02, -3.7144e-02,  1.3430e-02,\n",
              "                       4.3989e-03,  1.3182e-02, -3.5367e-02, -1.0653e-02, -2.4406e-02,\n",
              "                      -2.6916e-02,  1.7391e-02,  4.7808e-04,  2.8604e-02,  3.6015e-02,\n",
              "                       1.8232e-02, -3.7585e-02,  3.0150e-02,  1.7946e-02,  7.0479e-04,\n",
              "                       8.1254e-03, -1.2554e-03,  3.6734e-02,  1.0598e-02, -2.4759e-02,\n",
              "                      -2.6136e-02, -2.6340e-02,  2.1876e-02,  1.2150e-02,  1.5493e-02,\n",
              "                      -3.3803e-03,  2.9934e-02, -2.7638e-02,  2.2518e-02, -1.3672e-02,\n",
              "                       1.8667e-02,  3.6630e-02,  3.4238e-02, -1.9072e-02, -2.3200e-02,\n",
              "                       2.3868e-02, -4.1296e-03,  3.5641e-03, -1.7887e-02, -2.8080e-02,\n",
              "                       2.5498e-02,  2.9298e-02,  2.2406e-02, -2.5950e-03,  2.8695e-02,\n",
              "                       3.1996e-03,  3.5602e-02, -2.1324e-02, -1.2049e-02,  3.8762e-03,\n",
              "                       1.8266e-03, -3.7611e-02,  3.0309e-02, -2.4930e-02,  2.9155e-02,\n",
              "                      -3.2713e-02,  1.3671e-02, -1.9708e-02, -6.1535e-03, -1.0558e-02,\n",
              "                      -1.5693e-02, -3.4235e-02, -3.5057e-02,  1.6365e-02,  2.7775e-02,\n",
              "                      -3.3592e-02,  4.2016e-03,  9.7943e-03,  1.4701e-02, -2.3763e-02,\n",
              "                      -2.8359e-02, -2.5611e-02, -9.1226e-03,  4.2522e-03,  3.1462e-02,\n",
              "                      -2.0447e-02, -1.0213e-02, -1.2950e-02,  1.5270e-02, -1.2357e-02,\n",
              "                      -2.4148e-02, -1.3724e-02, -3.7999e-03,  1.8555e-02, -1.9261e-02,\n",
              "                      -2.4181e-02, -2.7522e-02, -2.5183e-02,  2.8741e-02,  2.1401e-02,\n",
              "                      -3.3081e-02,  2.3929e-02,  1.3709e-02, -3.1708e-02,  7.9679e-04,\n",
              "                       2.9082e-02,  3.7677e-02,  1.6617e-02, -3.7382e-02, -3.3329e-02,\n",
              "                      -1.0952e-02, -6.0063e-03,  2.9784e-02, -1.5767e-02,  7.5520e-03,\n",
              "                      -3.4725e-02, -1.1838e-02, -2.2909e-03, -1.1572e-02,  1.8612e-02,\n",
              "                      -7.8427e-03, -1.4418e-02,  3.5646e-02,  2.8472e-02, -2.9033e-03,\n",
              "                       3.7322e-02, -2.1974e-02, -1.8507e-03, -4.0348e-03, -1.5332e-02,\n",
              "                      -2.6000e-02, -1.8626e-02, -1.7881e-02, -2.8806e-02, -4.8746e-03,\n",
              "                       5.2117e-04, -3.5524e-02,  3.5276e-02,  1.9274e-02, -1.4597e-02,\n",
              "                       3.7489e-02,  2.4153e-02, -5.2726e-03,  3.5320e-02,  1.3490e-02,\n",
              "                      -2.2662e-02, -2.7852e-02, -1.0120e-02,  8.4886e-03, -3.0992e-02,\n",
              "                      -2.0506e-02,  7.5290e-04, -1.5898e-02,  1.6921e-02,  2.0459e-03,\n",
              "                      -1.7894e-02,  2.9129e-02, -5.4935e-03, -2.9863e-02,  1.9031e-03,\n",
              "                      -3.3494e-02,  2.4294e-02, -3.7473e-02, -1.8028e-03,  2.4746e-02,\n",
              "                       6.6127e-03,  2.1944e-02, -1.3487e-02,  2.9026e-02, -2.1637e-02,\n",
              "                      -2.6116e-02, -1.6284e-05, -7.8429e-03, -2.5580e-02, -3.3264e-02,\n",
              "                       2.3889e-02, -2.2489e-02,  3.3062e-02,  2.7630e-02, -2.4447e-02,\n",
              "                       1.5234e-02,  6.6940e-03,  3.6024e-02,  2.6909e-02, -2.7675e-02,\n",
              "                       5.4294e-03,  5.2006e-03,  2.9157e-02,  3.4057e-02,  6.1873e-04,\n",
              "                       1.3365e-02, -3.5609e-02, -1.8890e-02,  1.7682e-02, -5.2733e-03,\n",
              "                      -1.7077e-02, -2.4927e-02,  9.5001e-03,  1.3495e-02, -1.3850e-04,\n",
              "                      -3.6141e-02,  1.7146e-02, -3.0712e-02, -1.6967e-03, -1.8722e-02,\n",
              "                      -3.5153e-05,  1.5529e-02,  1.9934e-02, -2.4996e-02, -1.5817e-02,\n",
              "                       2.5603e-02, -5.3140e-03, -1.9459e-02, -9.2029e-03, -2.6543e-02,\n",
              "                       2.1321e-03,  2.9912e-02, -1.5243e-02, -7.7429e-03,  5.0050e-03,\n",
              "                       3.0519e-02, -7.3945e-03, -3.1097e-03, -1.3865e-02,  9.9026e-03,\n",
              "                      -3.2466e-02, -3.7627e-02, -1.3422e-02, -1.0427e-02,  2.1377e-03,\n",
              "                      -6.0688e-03,  2.8623e-02, -9.8816e-03, -1.5493e-02, -3.3663e-02,\n",
              "                      -1.2207e-02,  2.0714e-02,  7.5187e-03,  3.7671e-02,  3.1614e-04,\n",
              "                      -2.4504e-02, -3.7076e-02,  2.8945e-02, -2.3758e-02, -1.3764e-02,\n",
              "                       1.8083e-02,  2.4609e-02,  1.6331e-02,  1.9995e-02,  2.4576e-02,\n",
              "                       3.0222e-02, -4.0500e-03, -3.3403e-03, -1.6479e-02, -2.8774e-03,\n",
              "                       3.4440e-03, -6.8797e-03, -2.2185e-02,  3.1309e-02, -1.9372e-03,\n",
              "                      -2.4458e-02,  2.3783e-02,  2.2976e-02,  3.0641e-02, -1.9648e-02,\n",
              "                       2.1407e-03, -3.6643e-02, -2.4720e-02,  1.6860e-02, -2.2766e-02,\n",
              "                       1.4337e-02,  2.0908e-02,  1.5782e-02, -5.3099e-03,  9.5026e-03,\n",
              "                       3.2643e-02, -3.3406e-02, -1.7788e-02, -9.5856e-03, -1.9034e-03,\n",
              "                       2.6211e-02,  9.1809e-03,  8.5669e-03,  6.3824e-03, -6.7577e-03,\n",
              "                      -1.9724e-02, -1.6573e-02, -2.1311e-02,  2.8633e-02, -3.2395e-02,\n",
              "                       1.2633e-02, -1.5238e-02, -3.7148e-02,  5.4258e-03,  2.6598e-02,\n",
              "                      -3.4482e-02, -1.2404e-02,  1.3461e-02, -2.9659e-02,  1.5229e-02,\n",
              "                      -3.2967e-02, -3.2873e-03, -1.5344e-03,  3.0648e-02, -1.8912e-03,\n",
              "                       2.7574e-02,  2.2823e-02, -3.5906e-02, -5.1922e-03,  4.7518e-03,\n",
              "                      -7.5980e-03, -2.3305e-02,  1.6202e-02,  1.0993e-02,  1.2283e-02,\n",
              "                      -3.3819e-02, -5.9721e-03, -3.4620e-02,  2.0248e-02,  2.4543e-02])),\n",
              "             ('linear2.weight',\n",
              "              tensor([[-0.0402,  0.0283,  0.0263,  ...,  0.0190,  0.0062,  0.0207],\n",
              "                      [-0.0305,  0.0241, -0.0027,  ..., -0.0121,  0.0265, -0.0412],\n",
              "                      [ 0.0403,  0.0433, -0.0336,  ..., -0.0290,  0.0308,  0.0265],\n",
              "                      ...,\n",
              "                      [ 0.0118,  0.0286,  0.0321,  ...,  0.0309,  0.0178,  0.0350],\n",
              "                      [ 0.0219, -0.0409, -0.0249,  ..., -0.0075,  0.0112, -0.0412],\n",
              "                      [ 0.0391, -0.0251,  0.0126,  ..., -0.0289, -0.0140, -0.0266]])),\n",
              "             ('linear2.bias',\n",
              "              tensor([ 0.0034,  0.0428,  0.0163,  0.0247, -0.0372, -0.0156,  0.0023, -0.0048,\n",
              "                      -0.0259, -0.0240,  0.0109, -0.0052,  0.0053,  0.0254, -0.0429,  0.0255,\n",
              "                       0.0243, -0.0398, -0.0186,  0.0082,  0.0180,  0.0305, -0.0264, -0.0196,\n",
              "                       0.0145, -0.0173,  0.0378, -0.0424,  0.0216,  0.0083,  0.0173, -0.0260,\n",
              "                       0.0337,  0.0125, -0.0428, -0.0404,  0.0376, -0.0266, -0.0347,  0.0442,\n",
              "                      -0.0190, -0.0107, -0.0166, -0.0098,  0.0203, -0.0052, -0.0018,  0.0077,\n",
              "                       0.0134,  0.0328,  0.0032,  0.0238,  0.0382,  0.0102,  0.0097,  0.0187,\n",
              "                      -0.0257,  0.0304,  0.0388,  0.0267,  0.0269, -0.0171,  0.0414, -0.0082,\n",
              "                       0.0382,  0.0187,  0.0323,  0.0177, -0.0297,  0.0250,  0.0203,  0.0364,\n",
              "                       0.0275,  0.0013, -0.0099, -0.0447, -0.0296,  0.0409, -0.0354, -0.0015,\n",
              "                       0.0303, -0.0412,  0.0224,  0.0069, -0.0403,  0.0318,  0.0177,  0.0124,\n",
              "                      -0.0088, -0.0355,  0.0077, -0.0172,  0.0275,  0.0071, -0.0163, -0.0335,\n",
              "                      -0.0002, -0.0293,  0.0159, -0.0047,  0.0270, -0.0281, -0.0201,  0.0257,\n",
              "                      -0.0154,  0.0325, -0.0231,  0.0191,  0.0312, -0.0139, -0.0380, -0.0226,\n",
              "                      -0.0215, -0.0265,  0.0192,  0.0076,  0.0357,  0.0052, -0.0176, -0.0216,\n",
              "                       0.0255,  0.0401,  0.0425,  0.0320, -0.0433, -0.0057,  0.0347, -0.0163,\n",
              "                      -0.0105,  0.0146, -0.0071, -0.0056, -0.0186, -0.0376,  0.0144, -0.0251,\n",
              "                      -0.0066,  0.0323, -0.0032, -0.0388, -0.0142, -0.0332,  0.0375,  0.0266,\n",
              "                       0.0164, -0.0254, -0.0027,  0.0132, -0.0322,  0.0228, -0.0124, -0.0140,\n",
              "                       0.0079,  0.0076, -0.0159,  0.0333, -0.0412,  0.0066, -0.0095, -0.0001,\n",
              "                      -0.0306,  0.0094, -0.0402,  0.0313,  0.0328, -0.0134, -0.0336, -0.0189,\n",
              "                      -0.0128, -0.0377, -0.0234,  0.0050, -0.0004,  0.0179,  0.0183,  0.0401,\n",
              "                      -0.0184,  0.0123,  0.0027,  0.0301,  0.0408,  0.0343,  0.0263,  0.0422,\n",
              "                       0.0231,  0.0026, -0.0023, -0.0075,  0.0187,  0.0014, -0.0090, -0.0163,\n",
              "                      -0.0328, -0.0188,  0.0005, -0.0049, -0.0378, -0.0005, -0.0088, -0.0380,\n",
              "                      -0.0235,  0.0329,  0.0130, -0.0275, -0.0137, -0.0309,  0.0368, -0.0369,\n",
              "                      -0.0247, -0.0003,  0.0401,  0.0368, -0.0339, -0.0029, -0.0118,  0.0232,\n",
              "                       0.0173, -0.0110,  0.0205,  0.0209, -0.0284, -0.0289,  0.0430,  0.0308,\n",
              "                      -0.0020,  0.0035, -0.0219,  0.0291, -0.0140,  0.0424, -0.0437,  0.0114,\n",
              "                       0.0133,  0.0420,  0.0039,  0.0360,  0.0274, -0.0182, -0.0238, -0.0114,\n",
              "                       0.0217,  0.0340,  0.0350,  0.0208, -0.0355,  0.0403, -0.0026,  0.0167,\n",
              "                      -0.0211,  0.0303, -0.0166, -0.0219, -0.0043,  0.0292,  0.0298, -0.0430,\n",
              "                       0.0053,  0.0332, -0.0226,  0.0320,  0.0116, -0.0146,  0.0235, -0.0323,\n",
              "                      -0.0343,  0.0267,  0.0183, -0.0350,  0.0055,  0.0326,  0.0191, -0.0109,\n",
              "                      -0.0311,  0.0128, -0.0161,  0.0077, -0.0094,  0.0183,  0.0277, -0.0069,\n",
              "                      -0.0343,  0.0024, -0.0315,  0.0268,  0.0201,  0.0077, -0.0255, -0.0027,\n",
              "                      -0.0027, -0.0297,  0.0177, -0.0031,  0.0281, -0.0095, -0.0157, -0.0318,\n",
              "                       0.0219, -0.0220,  0.0027, -0.0091,  0.0198,  0.0192, -0.0345, -0.0232,\n",
              "                      -0.0309,  0.0443,  0.0163,  0.0328, -0.0377,  0.0066, -0.0173, -0.0147,\n",
              "                       0.0334,  0.0035,  0.0246,  0.0019,  0.0070,  0.0273, -0.0067, -0.0068,\n",
              "                      -0.0083, -0.0153,  0.0023, -0.0366, -0.0041,  0.0238,  0.0346,  0.0154,\n",
              "                      -0.0263, -0.0352,  0.0359,  0.0183,  0.0060, -0.0109,  0.0295, -0.0166,\n",
              "                      -0.0255, -0.0009,  0.0141,  0.0207, -0.0369,  0.0431, -0.0343, -0.0059,\n",
              "                       0.0005, -0.0426, -0.0205,  0.0071,  0.0189,  0.0141,  0.0193, -0.0289,\n",
              "                       0.0420, -0.0094,  0.0227, -0.0156,  0.0172, -0.0100, -0.0446,  0.0222,\n",
              "                       0.0106, -0.0234, -0.0366, -0.0316, -0.0368, -0.0150,  0.0055, -0.0385,\n",
              "                       0.0074, -0.0224,  0.0145, -0.0356,  0.0046, -0.0014,  0.0252, -0.0010,\n",
              "                       0.0193, -0.0380,  0.0412, -0.0083, -0.0372, -0.0382,  0.0230,  0.0130,\n",
              "                       0.0241, -0.0325, -0.0090,  0.0145,  0.0231,  0.0293, -0.0098, -0.0035,\n",
              "                       0.0172,  0.0435,  0.0426, -0.0172,  0.0042, -0.0352, -0.0437,  0.0295,\n",
              "                      -0.0196,  0.0346, -0.0368, -0.0039, -0.0299, -0.0319,  0.0338,  0.0254,\n",
              "                       0.0175, -0.0219,  0.0353, -0.0334, -0.0119,  0.0362,  0.0377, -0.0135,\n",
              "                      -0.0042,  0.0070,  0.0133,  0.0143, -0.0163,  0.0049,  0.0337,  0.0231,\n",
              "                      -0.0323,  0.0243,  0.0404, -0.0274,  0.0171,  0.0389,  0.0006, -0.0441,\n",
              "                      -0.0015, -0.0445,  0.0340,  0.0421,  0.0114, -0.0243, -0.0092, -0.0402,\n",
              "                       0.0016,  0.0049,  0.0011, -0.0377,  0.0003,  0.0236, -0.0369,  0.0330,\n",
              "                      -0.0005,  0.0161, -0.0268, -0.0152,  0.0424,  0.0336, -0.0438, -0.0328,\n",
              "                      -0.0392, -0.0430,  0.0233, -0.0151,  0.0340, -0.0388,  0.0149, -0.0097,\n",
              "                      -0.0181,  0.0034,  0.0190, -0.0280, -0.0114, -0.0167,  0.0292,  0.0191,\n",
              "                       0.0217, -0.0078, -0.0175,  0.0302,  0.0136, -0.0443,  0.0172, -0.0002,\n",
              "                       0.0037, -0.0260, -0.0222,  0.0424,  0.0394,  0.0116,  0.0409, -0.0421,\n",
              "                       0.0146, -0.0284, -0.0217, -0.0313, -0.0356, -0.0395, -0.0080, -0.0419,\n",
              "                       0.0215, -0.0424, -0.0353, -0.0124])),\n",
              "             ('linear3.weight',\n",
              "              tensor([[ 0.0313, -0.0056,  0.0156,  ..., -0.0097,  0.0022, -0.0443],\n",
              "                      [-0.0181,  0.0347, -0.0230,  ..., -0.0166,  0.0020, -0.0419],\n",
              "                      [-0.0376,  0.0236, -0.0180,  ...,  0.0371, -0.0164,  0.0314],\n",
              "                      ...,\n",
              "                      [ 0.0395, -0.0152,  0.0260,  ...,  0.0249,  0.0231, -0.0141],\n",
              "                      [ 0.0130, -0.0265, -0.0054,  ..., -0.0264, -0.0314,  0.0319],\n",
              "                      [-0.0426, -0.0290, -0.0283,  ..., -0.0154, -0.0330,  0.0123]])),\n",
              "             ('linear3.bias',\n",
              "              tensor([ 0.0406, -0.0222, -0.0079,  0.0007,  0.0099, -0.0348, -0.0156, -0.0126,\n",
              "                       0.0221,  0.0215]))])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "net.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gBBufCbQIT0L"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "scrolled": true,
        "id": "ERpxFN92IT0L",
        "outputId": "67b39971-4b3c-497d-e7ca-287405e8631a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-8d07404d15ea>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load('model.pt')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear1.weight',\n",
              "              tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
              "                      [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
              "                      [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
              "                      ...,\n",
              "                      [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
              "                      [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
              "                      [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]])),\n",
              "             ('linear1.bias',\n",
              "              tensor([-2.1088e-02,  1.0055e-02, -7.7552e-03, -1.9122e-02, -3.3471e-02,\n",
              "                      -2.0890e-02,  1.7957e-02,  2.6099e-02,  3.0136e-02, -3.0112e-02,\n",
              "                       2.7849e-02, -1.2145e-02, -2.8552e-02,  1.0605e-02, -7.8391e-03,\n",
              "                      -2.5345e-02,  6.5207e-03,  3.5297e-02,  1.6740e-02,  6.9777e-03,\n",
              "                      -3.3125e-02,  1.8327e-02,  1.6675e-02,  1.7545e-02,  7.4183e-03,\n",
              "                      -3.3241e-02,  6.3233e-03, -1.6696e-02, -1.5523e-02, -2.8453e-02,\n",
              "                       6.5478e-03,  2.4674e-02, -3.0306e-02, -1.9385e-02,  1.4468e-02,\n",
              "                      -2.1729e-03, -8.4098e-03, -3.4562e-02, -3.6783e-02,  2.9103e-02,\n",
              "                      -1.9729e-02, -2.3040e-02,  2.1877e-02,  6.0152e-03,  1.1391e-02,\n",
              "                      -6.1097e-03,  3.3665e-02, -8.8738e-03,  2.9855e-02, -3.3741e-02,\n",
              "                      -1.2577e-02,  3.6876e-02,  8.4248e-03,  2.4642e-02,  1.0302e-02,\n",
              "                      -6.1079e-05,  7.1781e-03, -8.0475e-03,  3.1832e-02,  2.9259e-02,\n",
              "                      -1.5856e-03,  1.4783e-02,  1.7176e-02,  1.3105e-02, -6.7287e-03,\n",
              "                       7.3206e-03,  2.7062e-02, -1.4028e-02,  2.2943e-02,  2.3746e-02,\n",
              "                      -3.6304e-02,  3.6079e-02, -2.3212e-02, -3.6907e-02,  2.5203e-02,\n",
              "                      -1.2118e-02,  2.9581e-02,  2.1207e-02, -1.2558e-02,  1.9321e-02,\n",
              "                      -8.6805e-03,  2.7435e-02, -2.9800e-02, -7.4419e-03,  3.1814e-02,\n",
              "                      -2.1617e-02,  4.0231e-03,  1.6897e-03, -2.7224e-02,  2.2252e-02,\n",
              "                      -7.8276e-03, -5.8323e-03,  2.1604e-02,  2.0243e-02, -3.0634e-02,\n",
              "                      -2.7636e-02,  2.7618e-02, -3.7075e-02,  2.7422e-02,  3.3624e-02,\n",
              "                       2.0136e-02, -1.3579e-02, -2.2899e-02, -1.4406e-02,  2.4088e-02,\n",
              "                      -9.2240e-03,  2.6004e-02,  4.2309e-03, -2.8261e-03, -3.2937e-02,\n",
              "                       3.1131e-02,  2.3983e-02,  2.5834e-02, -2.6628e-02, -2.7433e-03,\n",
              "                       1.2604e-02, -2.5830e-02,  7.5568e-03,  1.7652e-02,  2.4667e-02,\n",
              "                      -1.8043e-02,  3.3015e-02,  2.3048e-02, -2.3558e-02,  3.4824e-02,\n",
              "                      -2.8269e-02, -3.1550e-02, -2.7370e-02, -2.6664e-02,  7.4422e-03,\n",
              "                      -2.6541e-03,  3.2709e-02, -1.3939e-02, -2.2142e-03,  3.4098e-02,\n",
              "                      -2.3110e-02, -1.9643e-02,  2.7051e-02,  5.9541e-03,  1.0441e-02,\n",
              "                      -3.7375e-02,  1.6852e-02, -1.5934e-03,  3.5533e-02,  1.0102e-02,\n",
              "                       3.3332e-02,  1.0482e-02, -1.4666e-03, -9.0070e-04, -2.3667e-02,\n",
              "                       9.0613e-03,  3.0280e-02, -2.8597e-02, -4.7025e-03, -3.0936e-02,\n",
              "                       3.3503e-02,  7.9252e-03,  3.6596e-02,  2.0123e-02, -1.7245e-02,\n",
              "                       3.3844e-02,  3.7385e-03,  3.1676e-02, -3.1413e-03,  3.0088e-02,\n",
              "                       2.7965e-02,  9.2660e-03, -1.5061e-02,  2.0272e-02,  1.7319e-02,\n",
              "                       1.1421e-02,  1.6356e-02, -2.4352e-02,  2.3212e-02, -1.2722e-02,\n",
              "                      -9.1015e-03, -3.1929e-02, -1.6754e-03, -1.4019e-02,  3.1846e-02,\n",
              "                      -9.5939e-03,  2.3547e-02,  2.9385e-02,  2.3610e-02, -2.9643e-02,\n",
              "                      -3.4354e-02,  1.0636e-02,  3.2803e-02, -3.7144e-02,  1.3430e-02,\n",
              "                       4.3989e-03,  1.3182e-02, -3.5367e-02, -1.0653e-02, -2.4406e-02,\n",
              "                      -2.6916e-02,  1.7391e-02,  4.7808e-04,  2.8604e-02,  3.6015e-02,\n",
              "                       1.8232e-02, -3.7585e-02,  3.0150e-02,  1.7946e-02,  7.0479e-04,\n",
              "                       8.1254e-03, -1.2554e-03,  3.6734e-02,  1.0598e-02, -2.4759e-02,\n",
              "                      -2.6136e-02, -2.6340e-02,  2.1876e-02,  1.2150e-02,  1.5493e-02,\n",
              "                      -3.3803e-03,  2.9934e-02, -2.7638e-02,  2.2518e-02, -1.3672e-02,\n",
              "                       1.8667e-02,  3.6630e-02,  3.4238e-02, -1.9072e-02, -2.3200e-02,\n",
              "                       2.3868e-02, -4.1296e-03,  3.5641e-03, -1.7887e-02, -2.8080e-02,\n",
              "                       2.5498e-02,  2.9298e-02,  2.2406e-02, -2.5950e-03,  2.8695e-02,\n",
              "                       3.1996e-03,  3.5602e-02, -2.1324e-02, -1.2049e-02,  3.8762e-03,\n",
              "                       1.8266e-03, -3.7611e-02,  3.0309e-02, -2.4930e-02,  2.9155e-02,\n",
              "                      -3.2713e-02,  1.3671e-02, -1.9708e-02, -6.1535e-03, -1.0558e-02,\n",
              "                      -1.5693e-02, -3.4235e-02, -3.5057e-02,  1.6365e-02,  2.7775e-02,\n",
              "                      -3.3592e-02,  4.2016e-03,  9.7943e-03,  1.4701e-02, -2.3763e-02,\n",
              "                      -2.8359e-02, -2.5611e-02, -9.1226e-03,  4.2522e-03,  3.1462e-02,\n",
              "                      -2.0447e-02, -1.0213e-02, -1.2950e-02,  1.5270e-02, -1.2357e-02,\n",
              "                      -2.4148e-02, -1.3724e-02, -3.7999e-03,  1.8555e-02, -1.9261e-02,\n",
              "                      -2.4181e-02, -2.7522e-02, -2.5183e-02,  2.8741e-02,  2.1401e-02,\n",
              "                      -3.3081e-02,  2.3929e-02,  1.3709e-02, -3.1708e-02,  7.9679e-04,\n",
              "                       2.9082e-02,  3.7677e-02,  1.6617e-02, -3.7382e-02, -3.3329e-02,\n",
              "                      -1.0952e-02, -6.0063e-03,  2.9784e-02, -1.5767e-02,  7.5520e-03,\n",
              "                      -3.4725e-02, -1.1838e-02, -2.2909e-03, -1.1572e-02,  1.8612e-02,\n",
              "                      -7.8427e-03, -1.4418e-02,  3.5646e-02,  2.8472e-02, -2.9033e-03,\n",
              "                       3.7322e-02, -2.1974e-02, -1.8507e-03, -4.0348e-03, -1.5332e-02,\n",
              "                      -2.6000e-02, -1.8626e-02, -1.7881e-02, -2.8806e-02, -4.8746e-03,\n",
              "                       5.2117e-04, -3.5524e-02,  3.5276e-02,  1.9274e-02, -1.4597e-02,\n",
              "                       3.7489e-02,  2.4153e-02, -5.2726e-03,  3.5320e-02,  1.3490e-02,\n",
              "                      -2.2662e-02, -2.7852e-02, -1.0120e-02,  8.4886e-03, -3.0992e-02,\n",
              "                      -2.0506e-02,  7.5290e-04, -1.5898e-02,  1.6921e-02,  2.0459e-03,\n",
              "                      -1.7894e-02,  2.9129e-02, -5.4935e-03, -2.9863e-02,  1.9031e-03,\n",
              "                      -3.3494e-02,  2.4294e-02, -3.7473e-02, -1.8028e-03,  2.4746e-02,\n",
              "                       6.6127e-03,  2.1944e-02, -1.3487e-02,  2.9026e-02, -2.1637e-02,\n",
              "                      -2.6116e-02, -1.6284e-05, -7.8429e-03, -2.5580e-02, -3.3264e-02,\n",
              "                       2.3889e-02, -2.2489e-02,  3.3062e-02,  2.7630e-02, -2.4447e-02,\n",
              "                       1.5234e-02,  6.6940e-03,  3.6024e-02,  2.6909e-02, -2.7675e-02,\n",
              "                       5.4294e-03,  5.2006e-03,  2.9157e-02,  3.4057e-02,  6.1873e-04,\n",
              "                       1.3365e-02, -3.5609e-02, -1.8890e-02,  1.7682e-02, -5.2733e-03,\n",
              "                      -1.7077e-02, -2.4927e-02,  9.5001e-03,  1.3495e-02, -1.3850e-04,\n",
              "                      -3.6141e-02,  1.7146e-02, -3.0712e-02, -1.6967e-03, -1.8722e-02,\n",
              "                      -3.5153e-05,  1.5529e-02,  1.9934e-02, -2.4996e-02, -1.5817e-02,\n",
              "                       2.5603e-02, -5.3140e-03, -1.9459e-02, -9.2029e-03, -2.6543e-02,\n",
              "                       2.1321e-03,  2.9912e-02, -1.5243e-02, -7.7429e-03,  5.0050e-03,\n",
              "                       3.0519e-02, -7.3945e-03, -3.1097e-03, -1.3865e-02,  9.9026e-03,\n",
              "                      -3.2466e-02, -3.7627e-02, -1.3422e-02, -1.0427e-02,  2.1377e-03,\n",
              "                      -6.0688e-03,  2.8623e-02, -9.8816e-03, -1.5493e-02, -3.3663e-02,\n",
              "                      -1.2207e-02,  2.0714e-02,  7.5187e-03,  3.7671e-02,  3.1614e-04,\n",
              "                      -2.4504e-02, -3.7076e-02,  2.8945e-02, -2.3758e-02, -1.3764e-02,\n",
              "                       1.8083e-02,  2.4609e-02,  1.6331e-02,  1.9995e-02,  2.4576e-02,\n",
              "                       3.0222e-02, -4.0500e-03, -3.3403e-03, -1.6479e-02, -2.8774e-03,\n",
              "                       3.4440e-03, -6.8797e-03, -2.2185e-02,  3.1309e-02, -1.9372e-03,\n",
              "                      -2.4458e-02,  2.3783e-02,  2.2976e-02,  3.0641e-02, -1.9648e-02,\n",
              "                       2.1407e-03, -3.6643e-02, -2.4720e-02,  1.6860e-02, -2.2766e-02,\n",
              "                       1.4337e-02,  2.0908e-02,  1.5782e-02, -5.3099e-03,  9.5026e-03,\n",
              "                       3.2643e-02, -3.3406e-02, -1.7788e-02, -9.5856e-03, -1.9034e-03,\n",
              "                       2.6211e-02,  9.1809e-03,  8.5669e-03,  6.3824e-03, -6.7577e-03,\n",
              "                      -1.9724e-02, -1.6573e-02, -2.1311e-02,  2.8633e-02, -3.2395e-02,\n",
              "                       1.2633e-02, -1.5238e-02, -3.7148e-02,  5.4258e-03,  2.6598e-02,\n",
              "                      -3.4482e-02, -1.2404e-02,  1.3461e-02, -2.9659e-02,  1.5229e-02,\n",
              "                      -3.2967e-02, -3.2873e-03, -1.5344e-03,  3.0648e-02, -1.8912e-03,\n",
              "                       2.7574e-02,  2.2823e-02, -3.5906e-02, -5.1922e-03,  4.7518e-03,\n",
              "                      -7.5980e-03, -2.3305e-02,  1.6202e-02,  1.0993e-02,  1.2283e-02,\n",
              "                      -3.3819e-02, -5.9721e-03, -3.4620e-02,  2.0248e-02,  2.4543e-02])),\n",
              "             ('linear2.weight',\n",
              "              tensor([[-0.0402,  0.0283,  0.0263,  ...,  0.0190,  0.0062,  0.0207],\n",
              "                      [-0.0305,  0.0241, -0.0027,  ..., -0.0121,  0.0265, -0.0412],\n",
              "                      [ 0.0403,  0.0433, -0.0336,  ..., -0.0290,  0.0308,  0.0265],\n",
              "                      ...,\n",
              "                      [ 0.0118,  0.0286,  0.0321,  ...,  0.0309,  0.0178,  0.0350],\n",
              "                      [ 0.0219, -0.0409, -0.0249,  ..., -0.0075,  0.0112, -0.0412],\n",
              "                      [ 0.0391, -0.0251,  0.0126,  ..., -0.0289, -0.0140, -0.0266]])),\n",
              "             ('linear2.bias',\n",
              "              tensor([ 0.0034,  0.0428,  0.0163,  0.0247, -0.0372, -0.0156,  0.0023, -0.0048,\n",
              "                      -0.0259, -0.0240,  0.0109, -0.0052,  0.0053,  0.0254, -0.0429,  0.0255,\n",
              "                       0.0243, -0.0398, -0.0186,  0.0082,  0.0180,  0.0305, -0.0264, -0.0196,\n",
              "                       0.0145, -0.0173,  0.0378, -0.0424,  0.0216,  0.0083,  0.0173, -0.0260,\n",
              "                       0.0337,  0.0125, -0.0428, -0.0404,  0.0376, -0.0266, -0.0347,  0.0442,\n",
              "                      -0.0190, -0.0107, -0.0166, -0.0098,  0.0203, -0.0052, -0.0018,  0.0077,\n",
              "                       0.0134,  0.0328,  0.0032,  0.0238,  0.0382,  0.0102,  0.0097,  0.0187,\n",
              "                      -0.0257,  0.0304,  0.0388,  0.0267,  0.0269, -0.0171,  0.0414, -0.0082,\n",
              "                       0.0382,  0.0187,  0.0323,  0.0177, -0.0297,  0.0250,  0.0203,  0.0364,\n",
              "                       0.0275,  0.0013, -0.0099, -0.0447, -0.0296,  0.0409, -0.0354, -0.0015,\n",
              "                       0.0303, -0.0412,  0.0224,  0.0069, -0.0403,  0.0318,  0.0177,  0.0124,\n",
              "                      -0.0088, -0.0355,  0.0077, -0.0172,  0.0275,  0.0071, -0.0163, -0.0335,\n",
              "                      -0.0002, -0.0293,  0.0159, -0.0047,  0.0270, -0.0281, -0.0201,  0.0257,\n",
              "                      -0.0154,  0.0325, -0.0231,  0.0191,  0.0312, -0.0139, -0.0380, -0.0226,\n",
              "                      -0.0215, -0.0265,  0.0192,  0.0076,  0.0357,  0.0052, -0.0176, -0.0216,\n",
              "                       0.0255,  0.0401,  0.0425,  0.0320, -0.0433, -0.0057,  0.0347, -0.0163,\n",
              "                      -0.0105,  0.0146, -0.0071, -0.0056, -0.0186, -0.0376,  0.0144, -0.0251,\n",
              "                      -0.0066,  0.0323, -0.0032, -0.0388, -0.0142, -0.0332,  0.0375,  0.0266,\n",
              "                       0.0164, -0.0254, -0.0027,  0.0132, -0.0322,  0.0228, -0.0124, -0.0140,\n",
              "                       0.0079,  0.0076, -0.0159,  0.0333, -0.0412,  0.0066, -0.0095, -0.0001,\n",
              "                      -0.0306,  0.0094, -0.0402,  0.0313,  0.0328, -0.0134, -0.0336, -0.0189,\n",
              "                      -0.0128, -0.0377, -0.0234,  0.0050, -0.0004,  0.0179,  0.0183,  0.0401,\n",
              "                      -0.0184,  0.0123,  0.0027,  0.0301,  0.0408,  0.0343,  0.0263,  0.0422,\n",
              "                       0.0231,  0.0026, -0.0023, -0.0075,  0.0187,  0.0014, -0.0090, -0.0163,\n",
              "                      -0.0328, -0.0188,  0.0005, -0.0049, -0.0378, -0.0005, -0.0088, -0.0380,\n",
              "                      -0.0235,  0.0329,  0.0130, -0.0275, -0.0137, -0.0309,  0.0368, -0.0369,\n",
              "                      -0.0247, -0.0003,  0.0401,  0.0368, -0.0339, -0.0029, -0.0118,  0.0232,\n",
              "                       0.0173, -0.0110,  0.0205,  0.0209, -0.0284, -0.0289,  0.0430,  0.0308,\n",
              "                      -0.0020,  0.0035, -0.0219,  0.0291, -0.0140,  0.0424, -0.0437,  0.0114,\n",
              "                       0.0133,  0.0420,  0.0039,  0.0360,  0.0274, -0.0182, -0.0238, -0.0114,\n",
              "                       0.0217,  0.0340,  0.0350,  0.0208, -0.0355,  0.0403, -0.0026,  0.0167,\n",
              "                      -0.0211,  0.0303, -0.0166, -0.0219, -0.0043,  0.0292,  0.0298, -0.0430,\n",
              "                       0.0053,  0.0332, -0.0226,  0.0320,  0.0116, -0.0146,  0.0235, -0.0323,\n",
              "                      -0.0343,  0.0267,  0.0183, -0.0350,  0.0055,  0.0326,  0.0191, -0.0109,\n",
              "                      -0.0311,  0.0128, -0.0161,  0.0077, -0.0094,  0.0183,  0.0277, -0.0069,\n",
              "                      -0.0343,  0.0024, -0.0315,  0.0268,  0.0201,  0.0077, -0.0255, -0.0027,\n",
              "                      -0.0027, -0.0297,  0.0177, -0.0031,  0.0281, -0.0095, -0.0157, -0.0318,\n",
              "                       0.0219, -0.0220,  0.0027, -0.0091,  0.0198,  0.0192, -0.0345, -0.0232,\n",
              "                      -0.0309,  0.0443,  0.0163,  0.0328, -0.0377,  0.0066, -0.0173, -0.0147,\n",
              "                       0.0334,  0.0035,  0.0246,  0.0019,  0.0070,  0.0273, -0.0067, -0.0068,\n",
              "                      -0.0083, -0.0153,  0.0023, -0.0366, -0.0041,  0.0238,  0.0346,  0.0154,\n",
              "                      -0.0263, -0.0352,  0.0359,  0.0183,  0.0060, -0.0109,  0.0295, -0.0166,\n",
              "                      -0.0255, -0.0009,  0.0141,  0.0207, -0.0369,  0.0431, -0.0343, -0.0059,\n",
              "                       0.0005, -0.0426, -0.0205,  0.0071,  0.0189,  0.0141,  0.0193, -0.0289,\n",
              "                       0.0420, -0.0094,  0.0227, -0.0156,  0.0172, -0.0100, -0.0446,  0.0222,\n",
              "                       0.0106, -0.0234, -0.0366, -0.0316, -0.0368, -0.0150,  0.0055, -0.0385,\n",
              "                       0.0074, -0.0224,  0.0145, -0.0356,  0.0046, -0.0014,  0.0252, -0.0010,\n",
              "                       0.0193, -0.0380,  0.0412, -0.0083, -0.0372, -0.0382,  0.0230,  0.0130,\n",
              "                       0.0241, -0.0325, -0.0090,  0.0145,  0.0231,  0.0293, -0.0098, -0.0035,\n",
              "                       0.0172,  0.0435,  0.0426, -0.0172,  0.0042, -0.0352, -0.0437,  0.0295,\n",
              "                      -0.0196,  0.0346, -0.0368, -0.0039, -0.0299, -0.0319,  0.0338,  0.0254,\n",
              "                       0.0175, -0.0219,  0.0353, -0.0334, -0.0119,  0.0362,  0.0377, -0.0135,\n",
              "                      -0.0042,  0.0070,  0.0133,  0.0143, -0.0163,  0.0049,  0.0337,  0.0231,\n",
              "                      -0.0323,  0.0243,  0.0404, -0.0274,  0.0171,  0.0389,  0.0006, -0.0441,\n",
              "                      -0.0015, -0.0445,  0.0340,  0.0421,  0.0114, -0.0243, -0.0092, -0.0402,\n",
              "                       0.0016,  0.0049,  0.0011, -0.0377,  0.0003,  0.0236, -0.0369,  0.0330,\n",
              "                      -0.0005,  0.0161, -0.0268, -0.0152,  0.0424,  0.0336, -0.0438, -0.0328,\n",
              "                      -0.0392, -0.0430,  0.0233, -0.0151,  0.0340, -0.0388,  0.0149, -0.0097,\n",
              "                      -0.0181,  0.0034,  0.0190, -0.0280, -0.0114, -0.0167,  0.0292,  0.0191,\n",
              "                       0.0217, -0.0078, -0.0175,  0.0302,  0.0136, -0.0443,  0.0172, -0.0002,\n",
              "                       0.0037, -0.0260, -0.0222,  0.0424,  0.0394,  0.0116,  0.0409, -0.0421,\n",
              "                       0.0146, -0.0284, -0.0217, -0.0313, -0.0356, -0.0395, -0.0080, -0.0419,\n",
              "                       0.0215, -0.0424, -0.0353, -0.0124])),\n",
              "             ('linear3.weight',\n",
              "              tensor([[ 0.0313, -0.0056,  0.0156,  ..., -0.0097,  0.0022, -0.0443],\n",
              "                      [-0.0181,  0.0347, -0.0230,  ..., -0.0166,  0.0020, -0.0419],\n",
              "                      [-0.0376,  0.0236, -0.0180,  ...,  0.0371, -0.0164,  0.0314],\n",
              "                      ...,\n",
              "                      [ 0.0395, -0.0152,  0.0260,  ...,  0.0249,  0.0231, -0.0141],\n",
              "                      [ 0.0130, -0.0265, -0.0054,  ..., -0.0264, -0.0314,  0.0319],\n",
              "                      [-0.0426, -0.0290, -0.0283,  ..., -0.0154, -0.0330,  0.0123]])),\n",
              "             ('linear3.bias',\n",
              "              tensor([ 0.0406, -0.0222, -0.0079,  0.0007,  0.0099, -0.0348, -0.0156, -0.0126,\n",
              "                       0.0221,  0.0215]))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "torch.load('model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c2TwFwh0IT0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4eae6b-d3b4-4276-96b6-99bb336ce7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-6c6a62611f0a>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load('model.pt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "net.load_state_dict(torch.load('model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "In2V1vnqIT0L"
      },
      "outputs": [],
      "source": [
        "torch.save(torch.rand(100, 100), \"tensor.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VaPLq-wGIT0M",
        "outputId": "11a42de8-6b59-461f-d922-93dcb4e1d730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2432\n",
            "drwxr-xr-x 1 root root    4096 Oct 14 08:54 .\n",
            "drwxr-xr-x 1 root root    4096 Oct 14 08:23 ..\n",
            "drwxr-xr-x 4 root root    4096 Oct 10 13:27 .config\n",
            "-rw-r--r-- 1 root root 2426420 Oct 14 08:54 model.pt\n",
            "drwxr-xr-x 1 root root    4096 Oct 10 13:27 sample_data\n",
            "-rw-r--r-- 1 root root   41111 Oct 14 08:54 tensor.pt\n"
          ]
        }
      ],
      "source": [
        "! ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GpbmhDYGIT0M",
        "outputId": "37b32ad0-8949-46e3-f4cb-f40441854a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-f0854697d241>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  a = torch.load(\"tensor.pt\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5397, 0.6305, 0.6956,  ..., 0.4076, 0.2034, 0.5527],\n",
              "        [0.5431, 0.7084, 0.3521,  ..., 0.0615, 0.4107, 0.0168],\n",
              "        [0.9113, 0.1546, 0.4954,  ..., 0.2272, 0.1934, 0.7761],\n",
              "        ...,\n",
              "        [0.8949, 0.9497, 0.2219,  ..., 0.4994, 0.1716, 0.7696],\n",
              "        [0.3522, 0.4587, 0.2488,  ..., 0.6451, 0.1017, 0.4625],\n",
              "        [0.4956, 0.8417, 0.1473,  ..., 0.1457, 0.3538, 0.3098]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "a = torch.load(\"tensor.pt\")\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TeTptR1rIT0M"
      },
      "source": [
        "### Оптимизаторы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TefShtycIT0M"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "McB9l-njIT0S",
        "outputId": "72520af1-3745-4762-8c89-39d81148d713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.optim.sgd.SGD, torch.optim.adam.Adam)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "optim.SGD, optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FIeSsXg6IT0S"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(net.parameters(), betas=(0.9, 0.999), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "G5NyPrneIT0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66083c18-37c5-4083-d27b-ab979598e1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0046, -0.0147, -0.0108,  ..., -0.0097, -0.0142, -0.0183],\n",
            "        [-0.0269,  0.0245,  0.0160,  ...,  0.0221,  0.0033, -0.0027],\n",
            "        [-0.0318, -0.0120, -0.0059,  ..., -0.0002, -0.0039,  0.0289],\n",
            "        ...,\n",
            "        [ 0.0335, -0.0154, -0.0097,  ..., -0.0269,  0.0093, -0.0069],\n",
            "        [ 0.0231, -0.0092,  0.0288,  ...,  0.0022,  0.0373,  0.0132],\n",
            "        [ 0.0060, -0.0098, -0.0267,  ..., -0.0337,  0.0169, -0.0013]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.1088e-02,  1.0055e-02, -7.7552e-03, -1.9122e-02, -3.3471e-02,\n",
            "        -2.0890e-02,  1.7957e-02,  2.6099e-02,  3.0136e-02, -3.0112e-02,\n",
            "         2.7849e-02, -1.2145e-02, -2.8552e-02,  1.0605e-02, -7.8391e-03,\n",
            "        -2.5345e-02,  6.5207e-03,  3.5297e-02,  1.6740e-02,  6.9777e-03,\n",
            "        -3.3125e-02,  1.8327e-02,  1.6675e-02,  1.7545e-02,  7.4183e-03,\n",
            "        -3.3241e-02,  6.3233e-03, -1.6696e-02, -1.5523e-02, -2.8453e-02,\n",
            "         6.5478e-03,  2.4674e-02, -3.0306e-02, -1.9385e-02,  1.4468e-02,\n",
            "        -2.1729e-03, -8.4098e-03, -3.4562e-02, -3.6783e-02,  2.9103e-02,\n",
            "        -1.9729e-02, -2.3040e-02,  2.1877e-02,  6.0152e-03,  1.1391e-02,\n",
            "        -6.1097e-03,  3.3665e-02, -8.8738e-03,  2.9855e-02, -3.3741e-02,\n",
            "        -1.2577e-02,  3.6876e-02,  8.4248e-03,  2.4642e-02,  1.0302e-02,\n",
            "        -6.1079e-05,  7.1781e-03, -8.0475e-03,  3.1832e-02,  2.9259e-02,\n",
            "        -1.5856e-03,  1.4783e-02,  1.7176e-02,  1.3105e-02, -6.7287e-03,\n",
            "         7.3206e-03,  2.7062e-02, -1.4028e-02,  2.2943e-02,  2.3746e-02,\n",
            "        -3.6304e-02,  3.6079e-02, -2.3212e-02, -3.6907e-02,  2.5203e-02,\n",
            "        -1.2118e-02,  2.9581e-02,  2.1207e-02, -1.2558e-02,  1.9321e-02,\n",
            "        -8.6805e-03,  2.7435e-02, -2.9800e-02, -7.4419e-03,  3.1814e-02,\n",
            "        -2.1617e-02,  4.0231e-03,  1.6897e-03, -2.7224e-02,  2.2252e-02,\n",
            "        -7.8276e-03, -5.8323e-03,  2.1604e-02,  2.0243e-02, -3.0634e-02,\n",
            "        -2.7636e-02,  2.7618e-02, -3.7075e-02,  2.7422e-02,  3.3624e-02,\n",
            "         2.0136e-02, -1.3579e-02, -2.2899e-02, -1.4406e-02,  2.4088e-02,\n",
            "        -9.2240e-03,  2.6004e-02,  4.2309e-03, -2.8261e-03, -3.2937e-02,\n",
            "         3.1131e-02,  2.3983e-02,  2.5834e-02, -2.6628e-02, -2.7433e-03,\n",
            "         1.2604e-02, -2.5830e-02,  7.5568e-03,  1.7652e-02,  2.4667e-02,\n",
            "        -1.8043e-02,  3.3015e-02,  2.3048e-02, -2.3558e-02,  3.4824e-02,\n",
            "        -2.8269e-02, -3.1550e-02, -2.7370e-02, -2.6664e-02,  7.4422e-03,\n",
            "        -2.6541e-03,  3.2709e-02, -1.3939e-02, -2.2142e-03,  3.4098e-02,\n",
            "        -2.3110e-02, -1.9643e-02,  2.7051e-02,  5.9541e-03,  1.0441e-02,\n",
            "        -3.7375e-02,  1.6852e-02, -1.5934e-03,  3.5533e-02,  1.0102e-02,\n",
            "         3.3332e-02,  1.0482e-02, -1.4666e-03, -9.0070e-04, -2.3667e-02,\n",
            "         9.0613e-03,  3.0280e-02, -2.8597e-02, -4.7025e-03, -3.0936e-02,\n",
            "         3.3503e-02,  7.9252e-03,  3.6596e-02,  2.0123e-02, -1.7245e-02,\n",
            "         3.3844e-02,  3.7385e-03,  3.1676e-02, -3.1413e-03,  3.0088e-02,\n",
            "         2.7965e-02,  9.2660e-03, -1.5061e-02,  2.0272e-02,  1.7319e-02,\n",
            "         1.1421e-02,  1.6356e-02, -2.4352e-02,  2.3212e-02, -1.2722e-02,\n",
            "        -9.1015e-03, -3.1929e-02, -1.6754e-03, -1.4019e-02,  3.1846e-02,\n",
            "        -9.5939e-03,  2.3547e-02,  2.9385e-02,  2.3610e-02, -2.9643e-02,\n",
            "        -3.4354e-02,  1.0636e-02,  3.2803e-02, -3.7144e-02,  1.3430e-02,\n",
            "         4.3989e-03,  1.3182e-02, -3.5367e-02, -1.0653e-02, -2.4406e-02,\n",
            "        -2.6916e-02,  1.7391e-02,  4.7808e-04,  2.8604e-02,  3.6015e-02,\n",
            "         1.8232e-02, -3.7585e-02,  3.0150e-02,  1.7946e-02,  7.0479e-04,\n",
            "         8.1254e-03, -1.2554e-03,  3.6734e-02,  1.0598e-02, -2.4759e-02,\n",
            "        -2.6136e-02, -2.6340e-02,  2.1876e-02,  1.2150e-02,  1.5493e-02,\n",
            "        -3.3803e-03,  2.9934e-02, -2.7638e-02,  2.2518e-02, -1.3672e-02,\n",
            "         1.8667e-02,  3.6630e-02,  3.4238e-02, -1.9072e-02, -2.3200e-02,\n",
            "         2.3868e-02, -4.1296e-03,  3.5641e-03, -1.7887e-02, -2.8080e-02,\n",
            "         2.5498e-02,  2.9298e-02,  2.2406e-02, -2.5950e-03,  2.8695e-02,\n",
            "         3.1996e-03,  3.5602e-02, -2.1324e-02, -1.2049e-02,  3.8762e-03,\n",
            "         1.8266e-03, -3.7611e-02,  3.0309e-02, -2.4930e-02,  2.9155e-02,\n",
            "        -3.2713e-02,  1.3671e-02, -1.9708e-02, -6.1535e-03, -1.0558e-02,\n",
            "        -1.5693e-02, -3.4235e-02, -3.5057e-02,  1.6365e-02,  2.7775e-02,\n",
            "        -3.3592e-02,  4.2016e-03,  9.7943e-03,  1.4701e-02, -2.3763e-02,\n",
            "        -2.8359e-02, -2.5611e-02, -9.1226e-03,  4.2522e-03,  3.1462e-02,\n",
            "        -2.0447e-02, -1.0213e-02, -1.2950e-02,  1.5270e-02, -1.2357e-02,\n",
            "        -2.4148e-02, -1.3724e-02, -3.7999e-03,  1.8555e-02, -1.9261e-02,\n",
            "        -2.4181e-02, -2.7522e-02, -2.5183e-02,  2.8741e-02,  2.1401e-02,\n",
            "        -3.3081e-02,  2.3929e-02,  1.3709e-02, -3.1708e-02,  7.9679e-04,\n",
            "         2.9082e-02,  3.7677e-02,  1.6617e-02, -3.7382e-02, -3.3329e-02,\n",
            "        -1.0952e-02, -6.0063e-03,  2.9784e-02, -1.5767e-02,  7.5520e-03,\n",
            "        -3.4725e-02, -1.1838e-02, -2.2909e-03, -1.1572e-02,  1.8612e-02,\n",
            "        -7.8427e-03, -1.4418e-02,  3.5646e-02,  2.8472e-02, -2.9033e-03,\n",
            "         3.7322e-02, -2.1974e-02, -1.8507e-03, -4.0348e-03, -1.5332e-02,\n",
            "        -2.6000e-02, -1.8626e-02, -1.7881e-02, -2.8806e-02, -4.8746e-03,\n",
            "         5.2117e-04, -3.5524e-02,  3.5276e-02,  1.9274e-02, -1.4597e-02,\n",
            "         3.7489e-02,  2.4153e-02, -5.2726e-03,  3.5320e-02,  1.3490e-02,\n",
            "        -2.2662e-02, -2.7852e-02, -1.0120e-02,  8.4886e-03, -3.0992e-02,\n",
            "        -2.0506e-02,  7.5290e-04, -1.5898e-02,  1.6921e-02,  2.0459e-03,\n",
            "        -1.7894e-02,  2.9129e-02, -5.4935e-03, -2.9863e-02,  1.9031e-03,\n",
            "        -3.3494e-02,  2.4294e-02, -3.7473e-02, -1.8028e-03,  2.4746e-02,\n",
            "         6.6127e-03,  2.1944e-02, -1.3487e-02,  2.9026e-02, -2.1637e-02,\n",
            "        -2.6116e-02, -1.6284e-05, -7.8429e-03, -2.5580e-02, -3.3264e-02,\n",
            "         2.3889e-02, -2.2489e-02,  3.3062e-02,  2.7630e-02, -2.4447e-02,\n",
            "         1.5234e-02,  6.6940e-03,  3.6024e-02,  2.6909e-02, -2.7675e-02,\n",
            "         5.4294e-03,  5.2006e-03,  2.9157e-02,  3.4057e-02,  6.1873e-04,\n",
            "         1.3365e-02, -3.5609e-02, -1.8890e-02,  1.7682e-02, -5.2733e-03,\n",
            "        -1.7077e-02, -2.4927e-02,  9.5001e-03,  1.3495e-02, -1.3850e-04,\n",
            "        -3.6141e-02,  1.7146e-02, -3.0712e-02, -1.6967e-03, -1.8722e-02,\n",
            "        -3.5153e-05,  1.5529e-02,  1.9934e-02, -2.4996e-02, -1.5817e-02,\n",
            "         2.5603e-02, -5.3140e-03, -1.9459e-02, -9.2029e-03, -2.6543e-02,\n",
            "         2.1321e-03,  2.9912e-02, -1.5243e-02, -7.7429e-03,  5.0050e-03,\n",
            "         3.0519e-02, -7.3945e-03, -3.1097e-03, -1.3865e-02,  9.9026e-03,\n",
            "        -3.2466e-02, -3.7627e-02, -1.3422e-02, -1.0427e-02,  2.1377e-03,\n",
            "        -6.0688e-03,  2.8623e-02, -9.8816e-03, -1.5493e-02, -3.3663e-02,\n",
            "        -1.2207e-02,  2.0714e-02,  7.5187e-03,  3.7671e-02,  3.1614e-04,\n",
            "        -2.4504e-02, -3.7076e-02,  2.8945e-02, -2.3758e-02, -1.3764e-02,\n",
            "         1.8083e-02,  2.4609e-02,  1.6331e-02,  1.9995e-02,  2.4576e-02,\n",
            "         3.0222e-02, -4.0500e-03, -3.3403e-03, -1.6479e-02, -2.8774e-03,\n",
            "         3.4440e-03, -6.8797e-03, -2.2185e-02,  3.1309e-02, -1.9372e-03,\n",
            "        -2.4458e-02,  2.3783e-02,  2.2976e-02,  3.0641e-02, -1.9648e-02,\n",
            "         2.1407e-03, -3.6643e-02, -2.4720e-02,  1.6860e-02, -2.2766e-02,\n",
            "         1.4337e-02,  2.0908e-02,  1.5782e-02, -5.3099e-03,  9.5026e-03,\n",
            "         3.2643e-02, -3.3406e-02, -1.7788e-02, -9.5856e-03, -1.9034e-03,\n",
            "         2.6211e-02,  9.1809e-03,  8.5669e-03,  6.3824e-03, -6.7577e-03,\n",
            "        -1.9724e-02, -1.6573e-02, -2.1311e-02,  2.8633e-02, -3.2395e-02,\n",
            "         1.2633e-02, -1.5238e-02, -3.7148e-02,  5.4258e-03,  2.6598e-02,\n",
            "        -3.4482e-02, -1.2404e-02,  1.3461e-02, -2.9659e-02,  1.5229e-02,\n",
            "        -3.2967e-02, -3.2873e-03, -1.5344e-03,  3.0648e-02, -1.8912e-03,\n",
            "         2.7574e-02,  2.2823e-02, -3.5906e-02, -5.1922e-03,  4.7518e-03,\n",
            "        -7.5980e-03, -2.3305e-02,  1.6202e-02,  1.0993e-02,  1.2283e-02,\n",
            "        -3.3819e-02, -5.9721e-03, -3.4620e-02,  2.0248e-02,  2.4543e-02],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0402,  0.0283,  0.0263,  ...,  0.0190,  0.0062,  0.0207],\n",
            "        [-0.0305,  0.0241, -0.0027,  ..., -0.0121,  0.0265, -0.0412],\n",
            "        [ 0.0403,  0.0433, -0.0336,  ..., -0.0290,  0.0308,  0.0265],\n",
            "        ...,\n",
            "        [ 0.0118,  0.0286,  0.0321,  ...,  0.0309,  0.0178,  0.0350],\n",
            "        [ 0.0219, -0.0409, -0.0249,  ..., -0.0075,  0.0112, -0.0412],\n",
            "        [ 0.0391, -0.0251,  0.0126,  ..., -0.0289, -0.0140, -0.0266]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0034,  0.0428,  0.0163,  0.0247, -0.0372, -0.0156,  0.0023, -0.0048,\n",
            "        -0.0259, -0.0240,  0.0109, -0.0052,  0.0053,  0.0254, -0.0429,  0.0255,\n",
            "         0.0243, -0.0398, -0.0186,  0.0082,  0.0180,  0.0305, -0.0264, -0.0196,\n",
            "         0.0145, -0.0173,  0.0378, -0.0424,  0.0216,  0.0083,  0.0173, -0.0260,\n",
            "         0.0337,  0.0125, -0.0428, -0.0404,  0.0376, -0.0266, -0.0347,  0.0442,\n",
            "        -0.0190, -0.0107, -0.0166, -0.0098,  0.0203, -0.0052, -0.0018,  0.0077,\n",
            "         0.0134,  0.0328,  0.0032,  0.0238,  0.0382,  0.0102,  0.0097,  0.0187,\n",
            "        -0.0257,  0.0304,  0.0388,  0.0267,  0.0269, -0.0171,  0.0414, -0.0082,\n",
            "         0.0382,  0.0187,  0.0323,  0.0177, -0.0297,  0.0250,  0.0203,  0.0364,\n",
            "         0.0275,  0.0013, -0.0099, -0.0447, -0.0296,  0.0409, -0.0354, -0.0015,\n",
            "         0.0303, -0.0412,  0.0224,  0.0069, -0.0403,  0.0318,  0.0177,  0.0124,\n",
            "        -0.0088, -0.0355,  0.0077, -0.0172,  0.0275,  0.0071, -0.0163, -0.0335,\n",
            "        -0.0002, -0.0293,  0.0159, -0.0047,  0.0270, -0.0281, -0.0201,  0.0257,\n",
            "        -0.0154,  0.0325, -0.0231,  0.0191,  0.0312, -0.0139, -0.0380, -0.0226,\n",
            "        -0.0215, -0.0265,  0.0192,  0.0076,  0.0357,  0.0052, -0.0176, -0.0216,\n",
            "         0.0255,  0.0401,  0.0425,  0.0320, -0.0433, -0.0057,  0.0347, -0.0163,\n",
            "        -0.0105,  0.0146, -0.0071, -0.0056, -0.0186, -0.0376,  0.0144, -0.0251,\n",
            "        -0.0066,  0.0323, -0.0032, -0.0388, -0.0142, -0.0332,  0.0375,  0.0266,\n",
            "         0.0164, -0.0254, -0.0027,  0.0132, -0.0322,  0.0228, -0.0124, -0.0140,\n",
            "         0.0079,  0.0076, -0.0159,  0.0333, -0.0412,  0.0066, -0.0095, -0.0001,\n",
            "        -0.0306,  0.0094, -0.0402,  0.0313,  0.0328, -0.0134, -0.0336, -0.0189,\n",
            "        -0.0128, -0.0377, -0.0234,  0.0050, -0.0004,  0.0179,  0.0183,  0.0401,\n",
            "        -0.0184,  0.0123,  0.0027,  0.0301,  0.0408,  0.0343,  0.0263,  0.0422,\n",
            "         0.0231,  0.0026, -0.0023, -0.0075,  0.0187,  0.0014, -0.0090, -0.0163,\n",
            "        -0.0328, -0.0188,  0.0005, -0.0049, -0.0378, -0.0005, -0.0088, -0.0380,\n",
            "        -0.0235,  0.0329,  0.0130, -0.0275, -0.0137, -0.0309,  0.0368, -0.0369,\n",
            "        -0.0247, -0.0003,  0.0401,  0.0368, -0.0339, -0.0029, -0.0118,  0.0232,\n",
            "         0.0173, -0.0110,  0.0205,  0.0209, -0.0284, -0.0289,  0.0430,  0.0308,\n",
            "        -0.0020,  0.0035, -0.0219,  0.0291, -0.0140,  0.0424, -0.0437,  0.0114,\n",
            "         0.0133,  0.0420,  0.0039,  0.0360,  0.0274, -0.0182, -0.0238, -0.0114,\n",
            "         0.0217,  0.0340,  0.0350,  0.0208, -0.0355,  0.0403, -0.0026,  0.0167,\n",
            "        -0.0211,  0.0303, -0.0166, -0.0219, -0.0043,  0.0292,  0.0298, -0.0430,\n",
            "         0.0053,  0.0332, -0.0226,  0.0320,  0.0116, -0.0146,  0.0235, -0.0323,\n",
            "        -0.0343,  0.0267,  0.0183, -0.0350,  0.0055,  0.0326,  0.0191, -0.0109,\n",
            "        -0.0311,  0.0128, -0.0161,  0.0077, -0.0094,  0.0183,  0.0277, -0.0069,\n",
            "        -0.0343,  0.0024, -0.0315,  0.0268,  0.0201,  0.0077, -0.0255, -0.0027,\n",
            "        -0.0027, -0.0297,  0.0177, -0.0031,  0.0281, -0.0095, -0.0157, -0.0318,\n",
            "         0.0219, -0.0220,  0.0027, -0.0091,  0.0198,  0.0192, -0.0345, -0.0232,\n",
            "        -0.0309,  0.0443,  0.0163,  0.0328, -0.0377,  0.0066, -0.0173, -0.0147,\n",
            "         0.0334,  0.0035,  0.0246,  0.0019,  0.0070,  0.0273, -0.0067, -0.0068,\n",
            "        -0.0083, -0.0153,  0.0023, -0.0366, -0.0041,  0.0238,  0.0346,  0.0154,\n",
            "        -0.0263, -0.0352,  0.0359,  0.0183,  0.0060, -0.0109,  0.0295, -0.0166,\n",
            "        -0.0255, -0.0009,  0.0141,  0.0207, -0.0369,  0.0431, -0.0343, -0.0059,\n",
            "         0.0005, -0.0426, -0.0205,  0.0071,  0.0189,  0.0141,  0.0193, -0.0289,\n",
            "         0.0420, -0.0094,  0.0227, -0.0156,  0.0172, -0.0100, -0.0446,  0.0222,\n",
            "         0.0106, -0.0234, -0.0366, -0.0316, -0.0368, -0.0150,  0.0055, -0.0385,\n",
            "         0.0074, -0.0224,  0.0145, -0.0356,  0.0046, -0.0014,  0.0252, -0.0010,\n",
            "         0.0193, -0.0380,  0.0412, -0.0083, -0.0372, -0.0382,  0.0230,  0.0130,\n",
            "         0.0241, -0.0325, -0.0090,  0.0145,  0.0231,  0.0293, -0.0098, -0.0035,\n",
            "         0.0172,  0.0435,  0.0426, -0.0172,  0.0042, -0.0352, -0.0437,  0.0295,\n",
            "        -0.0196,  0.0346, -0.0368, -0.0039, -0.0299, -0.0319,  0.0338,  0.0254,\n",
            "         0.0175, -0.0219,  0.0353, -0.0334, -0.0119,  0.0362,  0.0377, -0.0135,\n",
            "        -0.0042,  0.0070,  0.0133,  0.0143, -0.0163,  0.0049,  0.0337,  0.0231,\n",
            "        -0.0323,  0.0243,  0.0404, -0.0274,  0.0171,  0.0389,  0.0006, -0.0441,\n",
            "        -0.0015, -0.0445,  0.0340,  0.0421,  0.0114, -0.0243, -0.0092, -0.0402,\n",
            "         0.0016,  0.0049,  0.0011, -0.0377,  0.0003,  0.0236, -0.0369,  0.0330,\n",
            "        -0.0005,  0.0161, -0.0268, -0.0152,  0.0424,  0.0336, -0.0438, -0.0328,\n",
            "        -0.0392, -0.0430,  0.0233, -0.0151,  0.0340, -0.0388,  0.0149, -0.0097,\n",
            "        -0.0181,  0.0034,  0.0190, -0.0280, -0.0114, -0.0167,  0.0292,  0.0191,\n",
            "         0.0217, -0.0078, -0.0175,  0.0302,  0.0136, -0.0443,  0.0172, -0.0002,\n",
            "         0.0037, -0.0260, -0.0222,  0.0424,  0.0394,  0.0116,  0.0409, -0.0421,\n",
            "         0.0146, -0.0284, -0.0217, -0.0313, -0.0356, -0.0395, -0.0080, -0.0419,\n",
            "         0.0215, -0.0424, -0.0353, -0.0124], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0313, -0.0056,  0.0156,  ..., -0.0097,  0.0022, -0.0443],\n",
            "        [-0.0181,  0.0347, -0.0230,  ..., -0.0166,  0.0020, -0.0419],\n",
            "        [-0.0376,  0.0236, -0.0180,  ...,  0.0371, -0.0164,  0.0314],\n",
            "        ...,\n",
            "        [ 0.0395, -0.0152,  0.0260,  ...,  0.0249,  0.0231, -0.0141],\n",
            "        [ 0.0130, -0.0265, -0.0054,  ..., -0.0264, -0.0314,  0.0319],\n",
            "        [-0.0426, -0.0290, -0.0283,  ..., -0.0154, -0.0330,  0.0123]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0406, -0.0222, -0.0079,  0.0007,  0.0099, -0.0348, -0.0156, -0.0126,\n",
            "         0.0221,  0.0215], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in net.parameters():\n",
        "    print(param)\n",
        "    # param = param - param.grad * self.lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FMRHHbWCIT0S",
        "outputId": "9c6ec43c-4d20-4f5a-e9a3-ac34bf912807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I7rQVH2iIT0T"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(\n",
        "    [\n",
        "        {'params': net.linear1.parameters()},\n",
        "        {'params': net.linear2.parameters(), 'lr': 1e-5}\n",
        "    ],\n",
        "    lr=1e-2,\n",
        "    momentum=0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "66xUp0SoIT0T",
        "outputId": "d8e69acb-3811-4d9f-f563-48827fa2bb72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.01\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              "\n",
              "Parameter Group 1\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 1e-05\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uwS5En4LIT0U"
      },
      "outputs": [],
      "source": [
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EY6U6-3VIT0U"
      },
      "outputs": [],
      "source": [
        "optimizer.zero_grad(set_to_none=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Sa7XRBDBIT0U"
      },
      "source": [
        "### Функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FhH_U4kSIT0U",
        "outputId": "6498e6fb-2a86-47e1-c6ee-69db322da1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.nn.modules.loss.L1Loss,\n",
              " torch.nn.modules.loss.MSELoss,\n",
              " torch.nn.modules.loss.CrossEntropyLoss,\n",
              " torch.nn.modules.loss.NLLLoss)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "nn.L1Loss, nn.MSELoss, nn.CrossEntropyLoss, nn.NLLLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qyd2VrLrIT0U"
      },
      "outputs": [],
      "source": [
        "loss = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QDvLIZ8JIT0V",
        "outputId": "1d7baab3-5217-42ca-e8a1-855e143ebada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R2b0xYGcIT0V",
        "outputId": "a8c8c48a-5333-4ab6-bc88-12dfda26a78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0137, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "\n",
        "output = loss(x, target)\n",
        "\n",
        "print(output)\n",
        "\n",
        "output.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IPETMZVKIT0V",
        "outputId": "b4412111-fe88-447e-f75d-9c041a53b5e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2806,  0.3366, -0.1580,  0.0341,  0.1883],\n",
              "        [-0.1676, -0.4071, -0.1092, -0.1474, -0.0891],\n",
              "        [-0.0386, -0.1187,  0.0167,  0.1531,  0.0929]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "XYfJ8Zn-IT0W",
        "outputId": "9f282a00-9d52-4b05-941b-84b5575c6ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.4255,  0.5458, -0.7552, -1.5978, -0.4948],\n",
              "         [ 0.3404,  0.9444,  1.2021, -0.7827,  0.7318],\n",
              "         [ 1.0336,  1.5382,  0.6612, -0.7450, -0.8578]], requires_grad=True),\n",
              " tensor([2, 4, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "x = torch.randn(3, 5, requires_grad=True)\n",
        "y = torch.empty(3, dtype=torch.long).random_(5)\n",
        "\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1f1h3MOYIT0W",
        "outputId": "fd91bae2-1671-4444-b3e6-3fcb7630b132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8312, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "loss(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "92jFS3GMIT0W"
      },
      "source": [
        "### Датасеты и даталоадеры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QlqsHmE4IT0W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xsKqxtwtIT0X"
      },
      "outputs": [],
      "source": [
        "n_features = 2\n",
        "n_objects = 300\n",
        "\n",
        "torch.manual_seed(0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KHxnEYdaIT0X",
        "outputId": "f9bdbe56-9f80-4f82-9851-1cc710b85260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1]), torch.Size([300, 2]), torch.Size([300, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "w_true = torch.randn(n_features, 1)\n",
        "\n",
        "X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
        "X *= (torch.arange(n_features) * 2 + 1)\n",
        "\n",
        "Y = X @ w_true\n",
        "Y += torch.rand_like(Y)\n",
        "\n",
        "w_true.shape, X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-NAYwCopIT0a"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Cr-bDuAeIT0a",
        "outputId": "b19d7f23-f9f3-4184-aa8e-15d204b44146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-4.6143,  9.1984]), tensor([-21.7897]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "dataset[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-MCq2HyIT0a",
        "outputId": "5acea55e-f202-4f13-8271-8f5f87e2055c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-4.6143,  9.1984]), tensor([-21.7897]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "X[7], Y[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fpzbGgD5IT0a"
      },
      "outputs": [],
      "source": [
        "# надо отнаследоваться от Dataset и определить методы __init__, __len__ и __getitem__\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, w_true, n_features, n_objects):\n",
        "        self.X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
        "        self.X *= (torch.arange(n_features) * 2 + 1)\n",
        "\n",
        "        self.Y = self.X @ w_true\n",
        "        self.Y += torch.rand_like(self.Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.X[item], self.Y[item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rScrtv12IT0b"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(w_true, n_features, n_objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "bXenxTlxIT0b",
        "outputId": "b770657a-4132-472c-982c-59a76da2976e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.5203, 0.0341]), tensor([0.5043]))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "dataset[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "rQ2EAvmRIT0b",
        "outputId": "63b9d0a1-faf8-4e84-b3ba-5e9ac6057e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5203, 0.0341])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "dataset.X[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PA9qs2k2IT0c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XJ2ZJr05IT0c"
      },
      "outputs": [],
      "source": [
        "loader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "3aZ6lRL9IT0c",
        "outputId": "d7977f06-c7b0-4c18-a937-c71b4d2ff68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=tensor([[ -1.9544,  -8.2094],\n",
            "        [  4.5845,   9.1393],\n",
            "        [  0.1284, -10.1301],\n",
            "        [  2.5808, -10.2925],\n",
            "        [ -3.5544,  -7.6309],\n",
            "        [  3.0918,   2.9245],\n",
            "        [  3.2522, -10.7559],\n",
            "        [ -1.9986,  -4.8979],\n",
            "        [ -2.1489,   7.9412],\n",
            "        [  2.9777,   9.5652],\n",
            "        [ -3.6368,  13.0093],\n",
            "        [ -3.9203,  -6.4179],\n",
            "        [  4.8749,  -2.7275],\n",
            "        [ -4.0901,  -5.5824],\n",
            "        [  1.2312,  12.3718],\n",
            "        [ -0.5430,  12.5512]])\tx.shape=torch.Size([16, 2])\n",
            "y=tensor([[ 15.5352],\n",
            "        [-14.2323],\n",
            "        [ 20.6960],\n",
            "        [ 22.7205],\n",
            "        [ 12.4630],\n",
            "        [ -2.4578],\n",
            "        [ 24.4322],\n",
            "        [  8.3829],\n",
            "        [-16.5956],\n",
            "        [-15.6222],\n",
            "        [-27.8552],\n",
            "        [ 10.3858],\n",
            "        [  9.7823],\n",
            "        [  8.5530],\n",
            "        [-22.4970],\n",
            "        [-24.8679]])\ty.shape=torch.Size([16, 1])\n"
          ]
        }
      ],
      "source": [
        "for x, y in loader:\n",
        "    print(f\"{x=}\\t{x.shape=}\")\n",
        "    print(f\"{y=}\\t{y.shape=}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JUbTRzbzIT0c"
      },
      "source": [
        "### Общая структура обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pBzFIdgPIT0d"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "\n",
        "for x, y in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(x)\n",
        "\n",
        "    loss = loss_fn(output, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "gO2UfWtaIT0d"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "HfmvPWQVIT0d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "\n",
        "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(tqdm(data_loader)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x)\n",
        "\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "LbUZV50TIT0d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(tqdm(data_loader)):\n",
        "        output = model(x)\n",
        "\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QCCnydtuIT0d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "\n",
        "def plot_stats(\n",
        "    train_loss: list[float],\n",
        "    valid_loss: list[float],\n",
        "    title: str\n",
        "):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.title(title + ' loss')\n",
        "\n",
        "    plt.plot(train_loss, label='Train loss')\n",
        "    plt.plot(valid_loss, label='Valid loss')\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "02HU0NEzIT0e"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def fit(model, train_loader, valid_loader, optimizer, loss_fn, num_epochs, title):\n",
        "    train_loss_history, valid_loss_history = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "        valid_loss = evaluate(model, valid_loader, loss_fn)\n",
        "\n",
        "        train_loss_history.append(train_loss)\n",
        "        valid_loss_history.append(valid_loss)\n",
        "\n",
        "        clear_output()\n",
        "\n",
        "        plot_stats(train_loss_history, valid_loss_history, title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "F5OCYF9-IT0e"
      },
      "source": [
        "## Обучение первой нейросети в `PyTorch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "REWLduHTIT0e"
      },
      "outputs": [],
      "source": [
        "class CustomTaskNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "model = CustomTaskNetwork()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "loss_fn = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "4dfE2zSfIT0e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "dataset = TensorDataset(X, Y)\n",
        "\n",
        "train_dataset, valid_dataset = random_split(\n",
        "    dataset,\n",
        "    (int(len(dataset) * 0.8), len(dataset) -  int(len(dataset) * 0.8)),\n",
        "    generator=torch.Generator().manual_seed(300)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "44Z7mFZSIT0f"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "epJu3r20IT0f",
        "outputId": "76579a89-a7fb-44f4-b6a2-e2c2f354843b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABS0AAALGCAYAAACgUbSwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADJ+ElEQVR4nOzdeXxU9b3/8feZmcxknZCEnbAlQNg32ZewryKKgivaosWlRUXtteq1Vnttbftr60pdkGLVqigqbuy77LIr+x72nezJZGbO7w+uuU3RsmSS7yR5PR8PHjDnnDnzHvnAQ99+zzmWbdu2AAAAAAAAACBMOEwHAAAAAAAAAIB/RWkJAAAAAAAAIKxQWgIAAAAAAAAIK5SWAAAAAAAAAMIKpSUAAAAAAACAsEJpCQAAAAAAACCsUFoCAAAAAAAACCuUlgAAAAAAAADCCqUlAAAAAAAAgLBCaQkAAIAf1L9/fz322GNGPvvll19WWlpaSM+5efNm3XzzzWrfvr3S0tK0bdu2Kz7XoUOHlJaWpk8++SSECQEAAPA9l+kAAAAAKF87duzQpEmT9O233+rUqVOqVq2amjRpov79++v22283Ha9MFBUVaeLEiXK73Xr88ccVGRmpunXrmo4FAACAH0FpCQAAUIWsX79ed9xxh+rWrasxY8aoRo0aOnr0qDZt2qS33367RGk5e/ZsWZZlMG3oZGRk6PDhw3r22Wc1ZswY03EAAABwEZSWAAAAVchrr72muLg4TZ8+XV6vt8S+06dPl3jtdrvLM1qZOnPmjCQpLi7OcBIAAABcCu5pCQAAUIVkZGSoSZMmFxSWkpSUlFTi9b/f0/KTTz5RWlqa1q5dq2effVbdunVTp06d9NRTT8nn8ykrK0uPPvqoOnfurM6dO+tPf/qTbNsufv/394GcMmWK3nrrLfXr109t27bV2LFjtXPnzkvK/9lnn+n6669X27Zt1aVLFz300EM6evTof3zPY489prFjx0qSHnzwQaWlpZVYUbpnzx49+OCD6tatm9q2bashQ4bo+eefv6Q8/27lypW69dZb1b59e3Xq1En33Xef9uzZU+KYnJwc/e53v1P//v3VunVrde/eXePGjdOWLVuKj9m/f7/uv/9+9ezZU23atFF6eroeeughZWdnX1EuAACAioaVlgAAAFVIvXr1tGHDBu3cuVPNmjW7onM8++yzql69uu6//35t2rRJ06ZNU1xcnDZs2KA6derooYce0tKlSzVlyhQ1a9ZM1113XYn3z5gxQ7m5ubr11ltVWFiod955Rz/5yU/0xRdfqHr16j/6ua+++qpefPFFDRs2TKNHj9aZM2f07rvv6rbbbtOMGTN+sIiVpJtuukm1atXSa6+9pttvv11t2rQp/pzt27frtttuk8vl0k033aR69eopIyNDCxcu1EMPPXRZ/1xWrFih8ePHKzk5WRMmTFBBQYHeffdd3XLLLfrkk0+UnJwsSfrNb36jOXPmaOzYsUpNTdW5c+e0bt067dmzR61atZLP59Ndd90ln8+nsWPHqnr16jp+/LgWL16srKwsVosCAIAqgdISAACgCrnzzjs1fvx4XXfddWrbtq2uuuoqde/eXV27dlVERMQlnSMpKUmTJ0+WZVm67bbblJGRoSlTpuimm27SM888I+l8Udi/f399/PHHF5SWGRkZmjt3rmrVqiVJSk9P15gxYzR58mQ9/vjjP/iZhw8f1ssvv6yJEyfq3nvvLd4+ePBgjRo1Su+9916J7f+qQ4cO8vl8eu2119SpUycNHTq0eN+zzz4r27b16aeflngwzy9/+ctL+mfxr/70pz8pPj5e06ZNU7Vq1SRJAwcO1KhRo/Tyyy/rj3/8oyRpyZIluvHGG0usYh0/fnzxr/fs2aNDhw7pxRdfLJF1woQJl50JAACgouLycAAAgCqkZ8+e+uCDD9S/f39t375db775pu666y6lp6drwYIFl3SO0aNHl3hAT9u2bWXbtkaPHl28zel0qnXr1jp48OAF7x84cGBxYfn9+9u1a6clS5b86GfOmzdPwWBQw4YN05kzZ4p/VK9eXQ0bNtTq1asvKfu/OnPmjL755hvdcMMNFzxJ/HIfQHTixAlt27ZNo0aNKi4sJal58+bq0aNHie/m9Xq1adMmHT9+/AfPFRsbK0latmyZ8vPzLysHAABAZcFKSwAAgCqmbdu2euWVV+Tz+bR9+3bNnz9fb731lh588EHNmDFDTZo0+Y/v//eC7/vLlevUqXPB9szMzAve37Bhwwu2NWrUSLNmzfrRz9y/f79s29bgwYN/cL/Ldfn/Wvt9oXqll8n/qyNHjkiSGjdufMG+1NRULVu2THl5eYqOjtYvf/lLPfbYY+rbt69atWqlPn366LrrrlP9+vUlSfXr19e4ceM0depUffHFF+rUqZP69++vkSNHcmk4AACoMigtAQAAqii32622bduqbdu2atSokR5//HHNnj37opchOxw/fLHOj20PhWAwKMuyNHnyZDmdzgv2R0dHl9lnh9rw4cPVqVMnzZs3T8uXL9eUKVM0efJkvfzyy+rTp4+k8w8PGjVqlBYsWKDly5fr2Wef1euvv64PP/xQtWvXNvwNAAAAyh6lJQAAANS6dWtJ5y9zLmsHDhy4YNv+/ftVr169H31PgwYNZNu2kpOTf3A145X4fmXjpT65/D/5fvXpvn37Lti3d+9eJSQklChWa9asqdtuu0233XabTp8+rVGjRum1114rLi0lKS0tTWlpafr5z3+u9evX65ZbbtH7779/2Q8IAgAAqIi4pyUAAEAVsmrVKtm2fcH27++5mJKSUuYZ5s+fX+J+jps3b9amTZuUnp7+o+8ZPHiwnE6nXnnllQvy27ats2fPXnaOxMREde7cWR9//HHx5d3/es7LUbNmTbVo0UIzZsxQVlZW8fadO3dq+fLlxWVkIBBQdnZ2ifcmJSWpZs2a8vl8kqScnBz5/f4SxzRr1kwOh6P4GAAAgMqOlZYAAABVyLPPPqv8/HwNGjRIKSkpKioq0vr16zVr1izVq1dP119/fZlnaNCggW655Rbdcsst8vl8evvtt1WtWjX97Gc/+4/vmThxov7yl7/o8OHDGjhwoGJiYnTo0CHNnz9fN954o+66667LzvLkk0/qlltu0ahRo3TTTTcpOTlZhw8f1uLFi/XZZ59d1rkeffRRjR8/XjfddJNGjx6tgoICvfvuu4qLiyu+5D43N1d9+vTRkCFD1Lx5c0VHR2vFihX69ttvi58mvmrVKv32t7/V0KFD1ahRIwUCAX322WdyOp0aMmTIZX9HAACAiojSEgAAoAp59NFHNXv2bC1ZskTTpk1TUVGR6tatq1tvvVX33XefvF5vmWe47rrr5HA49I9//EOnT59W27Zt9etf/1o1a9b8j++7++671ahRI7311luaNGmSJKl27drq2bOn+vfvf0VZmjdvrg8//FAvvvii3n//fRUWFqpu3boaNmzYZZ+rR48eevPNN/XSSy/ppZdeksvlUufOnfVf//VfxZeiR0ZG6pZbbtHy5cs1d+5c2batBg0a6De/+Y1uvfVWSecvC+/Vq5cWLVqk48ePKyoqSmlpaZo8ebLat29/Rd8TAACgorHsy732BQAAALgChw4d0oABA/Too49e0apIAAAAVB3c0xIAAAAAAABAWKG0BAAAAAAAABBWKC0BAAAAAAAAhBXuaQkAAAAAAAAgrLDSEgAAAAAAAEBYobQEAAAAAAAAEFYoLQEAAAAAAACEFZfpABWNbdsKBivvbUAdDqtSfz+UL+YJocZMIZSYJ4QS84RQY6YQSswTQol5Qmk5HJYsy7rocZSWlykYtHXmTK7pGGXC5XIoISFGWVl58vuDpuOggmOeEGrMFEKJeUIoMU8INWYKocQ8IZSYJ4RCYmKMnM6Ll5ZcHg4AAAAAAAAgrFBaAgAAAAAAAAgrlJYAAAAAAAAAwgqlJQAAAAAAAICwQmkJAAAAAAAAIKzw9HAAAAAAAACUqWAwqEDAbzoGypjT6ZLDEZo1kpSWAAAAAAAAKBO2bSsr64zy83NMR0E5iYqKldebKMuySnUeSksAAAAAAACUie8Ly9jYBLndnlIXWQhftm3L5ytUTs5ZSVJ8fFKpzkdpCQAAAAAAgJALBgPFhWVsrNd0HJQDt9sjScrJOau4uIRSXSrOg3gAAAAAAAAQcoFAQNL/FVmoGr7//S7tPUwpLQEAAAAAAFBmuCS8agnV7zelJQAAAAAAAICwwj0tAQAAAAAAgB/Rq1enix7zxBO/0fDh11zR+SdMuFvR0dH6059euKL3/6tevTrp5z9/ULfeenupz2UapSUAAAAAAADwI157bWqJ1/feO06jR9+kgQOHFm+rVy/5is//yCOPyenkYuh/R2kJAAAAAAAA/IjWrdtcsK1mzdo/uP17hYUF8ngiL+n8jRunXHG2yozSEgAAAAAAALhCU6a8rg8+eFcvvviqXnzxL9q1a4d+9rP7dOutt+vVV1/WypXLdPToEcXExKpduw66//6HVb169eL3//vl4d+f77XXpurPf35OO3duV9269TRhwkPq2rX7ZeebMeNjTZv2Tx07dlRJSdU1YsS1uuOOO+VwnF/dmZ2drb/97UWtXLlcWVmZqlYtQW3atNUzzzx3SfvLCqUlAAAAAAAAUApFRUV65pkndeONt+qee34hrzdeknT27Bndfvs4Va9eQ+fOndUHH/xTEybcrXff/VAu14/Xcn6/X7/97ZMaPfpm/fSnP9M///kPPfnko5o+/QvFx1e75FzTp3+gF174s0aPvkk9evTWt99u0tSpk5WTk6MJEyZKkl5++a9avXqF7r33ftWuXUenT5/SqlUris9xsf1lhdISAAAAAAAA5ca2bfmKgkY+2x3hkGVZIT+v3+/X3Xf/XAMGDC6x/YknflP860AgoNat22rUqOFav36tunTp9qPnKyoq0r33TlD37r0kSQ0aNNSYMSO1atUKDRky/JIyBQIBvfXWmxowYLAmTvwvSVKXLt3k9/v1wQfv6vbbf6r4+Gratm2LBg4cqmHDRhS/d+DAIcW/vtj+skJpCQAAAAAAgHJh27aee3e9dh/ONPL5TZLj9fhtHcukuPy+YPxXK1cu1z/+MUX79u1Rbm5u8faDBw/8x9LS4XCoU6euxa/r1Kkrj8ejEydOXHKeAwf269y5c+rff2CJ7f37D9I770zV1q1b1L17TzVr1lyzZn2ppKTq6tatu1JSmpQ4/mL7ywqlJQAAAAAAAMpP6PtC4yIjIxUdHV1i27ZtW/TYYw+rd+8+Gjv2J6pWLVGWZemee36qwkLffzyfx+NRREREiW0RERHy+QovOVN2drYkKSEhscT2xMTE/92fJUl66KFH5fW+rmnT3tXf/vaiataspdtvH6dRo0Zf0v6yQmkJAAAAAACAcmFZlh6/rWOluzz8h865dOlixcbG6re//UPxQ2+OHTsa8s/+MV6vV5J09uzZEtvPnDkjSYqLO78/NjZWDz74iB588BHt2bNbH330vv7ylz8oJSVV7dp1uOj+suIoszMDAAAAAAAA/8ayLHncTiM/yqKw/DGFhQVyuVwlPnPu3Fnl9vkNGjRUtWoJWrRofontCxfOU0REhFq2bHXBe1JTm+iBBx6WJO3fv++y94cSKy0BAAAAAACAEOvcuas+/PB9Pf/8n5Se3k/ffbdZc+bMLLfPdzqd+ulP79ILL/xZCQmJ6t69p7Zs+Vbvvfe2xoy5pfgp5Pfdd6d69+6nlJRUOZ0OzZ79lSIiIopXUV5sf1mhtAQAAAAAAABCrHv3Xrrvvvv18ccfaubML9SmTTv96U8v6JZbri+3DKNH3yyXy6UPPnhPn376kZKSqmvcuPG64447i49p06ad5sz5SkeOHJHDYSklpYn++Mfn1ahR40vaX1Ys27btMv2ESiYQCOrMmdyLH1gBuVwOJSTE6OzZXPn9Zu4tgcqDeUKoMVMIJeYJocQ8IdSYKYQS84RQutx5Kiry6fTpo0pKqqOICHc5JEQ4uNjve2JijJzOi9+xkpWWKDZr1QGdyfHppn6ppqMAAAAAAACgCqO0RLFlm4/q4Ikc1a8eox6ta5uOAwAAAAAAgCqKp4ejWI8254vKmasOKMhdAwAAAAAAAGAIpSWK9euQrOhIl46cytWm3adMxwEAAAAAAEAVRWmJYtGRLg3r3kiSNGtVhtkwAAAAAAAAqLIoLVHCyPRUuZyWdh/O1M6D50zHAQAAAAAAQBVEaYkSEr2R6tW2riRp9mpWWwIAAAAAAKD8UVriAsO6NZAlaePuUzp8Msd0HAAAAAAAAFQxlJa4QJ2kGHVsVkMSqy0BAAAAAABQ/igt8YOGdWsoSVq19bjOZBUYTgMAAAAAAICqhNISPyilrlfNG1RTIGhr7jcHTccBAAAAAAAw4tFHH9LNN4/60f3Tp3+gXr066fDhQ5d0vl69Oum9994pfj1hwt169NGJF33f0KF9NWXK6//xmNGjr9Ff//rHS8oR7igt8aO+X225ZOMR5RYUGU4DAAAAAABQ/gYNGqJDhw5q27YtP7h//vy5atWqjerVS76i8z/yyGOaMGFiKRJWTpSW+FGtGycquUasCosCWrj+sOk4AAAAAAAA5a53776KiorWvHmzL9h39OgRfffdZg0aNOSKz9+4cYoaNGhUioSVk8t0AIQvy7I0rFsDTf5iq+avPaghnevLHeE0HQsAAAAAAKDcREZGqnfvPlq4cL4mTHhIDsf/rQGcP3+OnE6nBgwYrFOnTumNNyZpw4b1On36lGrWrKl+/QZq3LjxcrvdP3r+CRPuVnR0tP70pxeKt3399WK9+urLOnbsqFJTm+jhh391xfmXLFmoqVPfVEbGfsXFeTVw4GDdffcv5PF4JEl+v1+vvz5JCxbM1dmzZ+T1epWW1lJPPfU/io2Nvej+skJpif+oS4ua+mTJXp3OKtDyb4+qX8crW+oMAAAAAAAgSbZtS36fmQ93uWVZ1mW/bdCgIZo7d5Y2bFinq67qXLx93rzZ6tSpqxISErVnz255vfG6//6HFBcXp4MHM/T3v7+h06dP6YknfnPJn7Vr1w49+eSv1LVrD91//0M6cuSInnrqcfl8l3/rvmXLlujJJ3+lAQMG6957JygjY79ef32Sjh8/pmef/ZMk6Z13pmrGjI913333q3HjFGVmntOaNatUVOS7pP1lhdIS/5HT4dCQLvX13vxdmr0mQ+nt68rp4K4CAAAAAADg8tm2rbzPf6fg8d1GPt9Zq6miRj5x2cVl587dVK1agubPn1NcWu7du1t79+7RrbfeIUlKTW1S4t6Ubdq0U2RklH73u9/o4Yd/pcjIyEv6rHfffUs1a9bWc8/9WU7n+StePR6P/vCH/7mszJL097+/oVat2ujpp38nSerWrYc8nkj9v//3e+3Zs1upqU20bdsWdenSVddfP6b4fX37Dij+9cX2lxXaJ1xU77Z1FRsVoZPnCrRux0nTcQAAAAAAQAVm6fJXOprmcrnUr99ALV68UEVF51c8zps3R5GRkUpP7yfpfCH74YfvaezYMerfv6f69u2m3/72SQUCAR05cmlPFpekrVu3qGfP3sWFpST163f5JWFeXp527dqpvn37l9g+YMBgSdLmzRslSc2aNdfKlSs0Zcrr2rZti4LBYInjL7a/rLDSEhflcTvVv2M9fb58v2atylDn5jWvaCk1AAAAAACo2izLUtTIJyrc5eHS+UvEP/30I61evUK9evXR/Plz1bNnuqKjoyVJH374niZNelG33nqHOnbspLi4OG3btlV//esf5fNd+vc9ffqUEhISSmyLiYmV2+25rLw5OdmybVuJiUkltsfGxsrtdisrK1OSdMcdd8qyLM2e/ZWmTp2satUSdP31YzRu3HhZlnXR/WWF0hKXZMBVyZq9OkMHjmdr64GzatUo0XQkAAAAAABQAVmWJUVcXgEXDtq0aac6depq3rw5qlYtUUePHtaDDz5SvH/RogXq2TNd9947oXjb/v37LvtzkpKq6+zZsyW25ebmyOcrvKzzxMbGybIsnT17psT2nJwc+Xw+eb3xkiS326277rpHd911jw4dOqivvvpcf//7G6pbt56GDr36ovvLCpeH45LERbvVu11dSdKsVQcMpwEAAAAAAChflmVp4MAhWr58qb744lPFx8erW7cexfsLCwsUERFR4j1z58667M9p0aKVli//WoFAoHjbokULLvs80dHRatq0mRYvLvnehQvnSZLatm1/wXuSk+vrnnt+Ia83XgcO7L/s/aHESktcsiGd62vR+sPauv+s9h/LUqPaXtORAAAAAAAAys2gQUP0zjtTNXPmF7r22uvlcv1ftda5c1d99NEH+vjjaapfv6HmzJmpQ4cu/V6W3xs79icaP/4nevzxX2rUqNE6cuSwPvjg3cu+PFyS7rzzbj3++C/129/+WoMHD1NGxgG98cYk9e3bX6mpTSRJjz/+iNLSWqhp0zRFRUVp+fKlys7OUseOnS5pf1mhtMQlq14tSl1a1tSqLcc1e3WG7r22telIAAAAAAAA5SYlpYlSU5tqz55dGjRoaIl9P/3peJ07d05vvvm6pPNP2J448Zf61a8euqzPaNasuX772z/otdde1n//93+pceNUPf307/XIIxMu/uZ/06tXH/3P//xBU6e+qccff0Rer1cjR47SPff837natGmnhQvn64MP3lUgEFD9+g311FP/o86du17S/rJi2bZtl+knVDKBQFBnzuSajlEmXC6HEhJidPZsrvz+H34SVMbxbD099RtZlvTc3d1UMyG6nFOioriUeQIuBzOFUGKeEErME0KNmUIoMU8Ipcudp6Iin06fPqqkpDqKiHCXQ0KEg4v9vicmxsjpvPgdK7mnJS5Lg1pxap2SKNuW5qw5aDoOAAAAAAAAKiFKS1y24V0bSpKWfXtUWbk+w2kAAAAAAABQ2VBa4rKlNaimxnW8KvIHNX/d5d9QFgAAAAAAAPhPKC1x2SzL0vBuDSRJi9YfUoHPbzgRAAAAAAAAKhNKS1yRDk1rqFZClHIL/Fq68YjpOAAAAAAAAKhEKC1xRRwOS0O7nl9tOeebg/IHeAodAAAAAAC4kG3bpiOgHIXq95vSElesR+vaio9x62x2oVZvPW46DgAAAAAACCNOp1OS5PMVGk6C8vT977fT6SrVeUr3blRpES6nBnWur+mL92j26gx1b11bDssyHQsAAAAAAIQBh8OpqKhY5eSclSS53R5Z9AaVlm3b8vkKlZNzVlFRsXI4SrdWktISpdK3fT19uWK/Dp/K1eY9p9W+SXXTkQAAAAAAQJjwehMlqbi4ROUXFRVb/PteGpSWKJXoSJf6dqin2aszNGvVAUpLAAAAAABQzLIsxccnKS4uQYGA33QclDGn01XqFZbfo7REqQ3qVF/z1x7UrkOZ2n0oU02S401HAgAAAAAAYcThcMjhcJuOgQokrB7Es2TJEo0dO1bdunVT69atNWDAAD333HPKzs4ucdzChQs1cuRItWnTRkOGDNHHH398wbl8Pp/++Mc/qmfPnmrfvr3GjRunvXv3ltdXqVIS4jzq3qq2JGnmqgOG0wAAAAAAAKCiC6vS8ty5c2rbtq2eeeYZTZkyRePGjdOMGTP04IMPFh+zdu1aTZgwQe3bt9fkyZM1bNgw/fd//7dmz55d4lzPPvusPvroIz300EN6+eWX5fP59NOf/vSCAhShMbRrA1mSNu4+pSOnck3HAQAAAAAAQAUWVpeHX3vttSVed+3aVW63W7/+9a91/Phx1apVS6+++qratm2r3/72t5Kkbt266eDBg3rppZc0dOhQSdKxY8c0ffp0/eY3v9Ho0aMlSW3atFG/fv30wQcfaPz48eX7xaqAOkkx6tCshtbvPKnZqzN059UtTEcCAAAAAABABRVWKy1/SLVq1SRJRUVF8vl8Wr16dXE5+b3hw4drz549OnTokCRp2bJlCgaDJY6rVq2aevbsqaVLl5Zb9qpmWNcGkqSVW47pTFaB4TQAAAAAAACoqMKytAwEAiosLNSWLVs0adIk9e/fX8nJycrIyFBRUZFSUlJKHJ+amipJxfes3Lt3r5KSkhQfH3/BcdzXsuyk1otXs/rVFAjamrf2oOk4AAAAAAAAqKDC6vLw7/Xr10/Hjx+XJPXu3Vt/+ctfJEmZmZmSJK/XW+L4719/vz8rK0txcXEXnNfr9RYfUxouV1h2vaXmdDpK/HwlrunZSH/5YKOWbDyi69JTFBMZEap4qGBCMU/Av2KmEErME0KJeUKoMVMIJeYJocQ8oTyFZWn5xhtvKD8/X7t379arr76qe++9V1OnTjUdS5LkcFhKSIgxHaNMeb1RV/zePp2iNX3xHh04lq2VW09ozIBmIUyGiqg08wT8EGYKocQ8IZSYJ4QaM4VQYp4QSswTykNYlpbNmzeXJHXo0EFt2rTRtddeq3nz5qlJkyaSdMETwLOysiSp+HJwr9ernJycC86blZV1wSXjlysYtJWVlVeqc4Qrp9MhrzdKWVn5CgSCV3yeoV0a6PXPt+izJXuU3ra23C5nCFOiogjVPAHfY6YQSswTQol5QqgxUwgl5gmhxDwhFLzeqEtarRuWpeW/SktLU0REhDIyMtS/f39FRERo79696t27d/Ex39+n8vt7XaakpOjUqVPKzMwsUVLu3bv3gvthXgm/v3L/wQwEgqX6jlel1VCS16PTWYVauuGI+naoF8J0qGhKO0/Av2OmEErME0KJeUKoMVMIJeYJocQ8oTyE/U0INm3apKKiIiUnJ8vtdqtr166aM2dOiWNmzpyp1NRUJScnS5J69eolh8OhuXPnFh+TmZmpZcuWKT09vVzzV0Uup0ODO59/kvjsNRkKBm3DiQAAAAAAAFCRhNVKywkTJqh169ZKS0tTZGSktm/frilTpigtLU0DBw6UJN13332644479PTTT2vYsGFavXq1vvzySz3//PPF56ldu7ZGjx6tP/3pT3I4HKpVq5Zef/11xcXF6eabbzb19aqU9HZ19fnyfTpxNl/rd55Up+Y1TUcCAAAAAABABRFWpWXbtm01c+ZMvfHGG7JtW/Xq1dOYMWN01113ye12S5I6deqkl19+WS+88IKmT5+uunXr6tlnn9WwYcNKnOvJJ59UTEyM/vKXvyg3N1cdO3bU1KlTf/Cp4gg9j9upAVcl6/Pl+zVz1QFdlVZDlmWZjgUAAAAAAIAKwLJtm2t3L0MgENSZM7mmY5QJl8uhhIQYnT2bG5J7U2Tl+fTo31bI5w/qv25urxaNEkOQEhVFqOcJYKYQSswTQol5QqgxUwgl5gmhxDwhFBITYy7pQTxhf09LVFzeaLd6ta0jSZq5OsNwGgAAAAAAAFQUlJYoU0O6NJDDsrRl3xkdOJZtOg4AAAAAAAAqAEpLlKka1aLUucX5h/DMXsNqSwAAAAAAAFwcpSXK3LCuDSRJa7Yd18lz+YbTAAAAAAAAINxRWqLMNagVp1aNE2Xb0hxWWwIAAAAAAOAiKC1RLob/72rLZZuPKivPZzgNAAAAAAAAwhmlJcpF84YJalQ7Tj5/UAvWHjIdBwAAAAAAAGGM0hLlwrIsDe/WUJK0cP0hFfj8hhMBAAAAAAAgXFFaotx0bFZDNROilFvg19ebjpqOAwAAAAAAgDBFaYly43BYGtrl/L0t536TIX8gaDgRAAAAAAAAwhGlJcpVzza15Y1x63RWodZsO246DgAAAAAAAMIQpSXKVYTLqUGdkiVJs1ZnyLZtw4kAAAAAAAAQbigtUe76dagnj9upwydz9e3e06bjAAAAAAAAIMxQWqLcRUdGqG/7upKkmasyDKcBAAAAAABAuKG0hBGDOzeQ02Fp58Fz2nM403QcAAAAAAAAhBFKSxiREOdR91a1JUkzVx0wnAYAAAAAAADhhNISxgzt2kCStHHXKR09nWs4DQAAAAAAAMIFpSWMqVs9Rh2aVpctafZq7m0JAAAAAACA8ygtYdSwrg0lSSu3HNPZ7ELDaQAAAAAAABAOKC1hVJPkeDVNjpc/YGve2oOm4wAAAAAAACAMUFrCuGHdzq+2XLzhsPIKigynAQAAAAAAgGmUljCubWqS6lWPUYEvoMUbj5iOAwAAAAAAAMMoLWGcw7KKnyQ+75uDKvIHDCcCAAAAAACASZSWCAtdW9ZSQpxHmbk+rfjumOk4AAAAAAAAMIjSEmHB5XRoSOf6kqTZqzMUDNqGEwEAAAAAAMAUSkuEjfT2dRUT6dLxs/nasOuk6TgAAAAAAAAwhNISYSPS7VK/jsmSpJmrMmTbrLYEAAAAAACoiigtEVYGXpWsCJdD+45maUfGOdNxAAAAAAAAYAClJcKKN8atXm3qSJJmrj5gOA0AAAAAAABMoLRE2BnStYEsS/pu7xllHM82HQcAAAAAAADljNISYadmtSh1bl5TkjR7TYbhNAAAAAAAAChvlJYIS8O6NpQkrdl6QqfO5RtOAwAAAAAAgPJEaYmw1LB2nFo1SlDQtjXnm4Om4wAAAAAAAKAcUVqimP/oTuVsXS7btk1HkSQN7XZ+teXXm44oO89nOA0AAAAAAADKC6UliuUu/rtOfPpX+TM2m44iSWrZMEENa8XJ5w9qwbpDpuMAAAAAAACgnFBaolhEw3aSpPxVH8m2g4bTSJZlaVi3BpKkhesPq9AXMJwIAAAAAAAA5YHSEsUiO46Q5YlW4HSG/HvWmI4jSeqUVlM1qkUqJ79IX28+YjoOAAAAAAAAygGlJYo5IuNUrdu1kqTCtZ/IDvoNJ5IcDktDu5xfbTlnzUH5A+ZXgAIAAAAAAKBsUVqihPguV8uKipeddUJF25eajiNJ6tmmjrzRETqdVaBvtp8wHQcAAAAAAABljNISJTjcUYrsNFKS5Fv3mWx/oeFEkjvCqQGd6kuSZq3KCJunmwMAAAAAAKBsUFriAp6W/WTFVZednynfd/NMx5Ek9e9YTx63U4dO5ui7fWdMxwEAAAAAAEAZorTEBSynS55O10uSfBtnyi7MNZxIiomMUJ92dSVJs1YdMJwGAAAAAAAAZYnSEj/IldpNjsRkyZcn38avTMeRJA3uXF9Oh6XtGee090iW6TgAAAAAAAAoI5SW+EGWwyFP59GSJN938xXMPWs4kZTojVS3lrUksdoSAAAAAACgMqO0xI9yNmgnR60mUsAn3/rPTceRJA3t1lCStH7nSR07k2c4DQAAAAAAAMoCpSV+lGVZ8nQZI0kq2r5EwcxjhhNJ9arHqH2T6rIlzV6dYToOAAAAAAAAygClJf4jV500Oeu3leygCtd+ajqOJGlYtwaSpBXfHdW5nELDaQAAAAAAABBqlJa4KE+X8/e29O9ZrcAp8/eSbJpcTU3qxcsfsDVv7UHTcQAAAAAAABBilJa4KGdSA7madJMkFX7zseE0532/2nLxhsPKK/AbTgMAAAAAAIBQorTEJfF0ul6ynAoc3Cz/ke2m46hdk+qqWz1G+YUBLdl02HQcAAAAAAAAhBClJS6Jw1tTES36SJIKv5ku27bN5rEsDe1yfrXl3G8OqsgfNJoHAAAAAAAAoUNpiUvm7jhScroVPL5bgQMbTcdRt1a1lBDnUWaOTyu3mH+yOQAAAAAAAEKD0hKXzBFdTe42gyX972rLoNnVjS6nQ4M61ZckzV6doaDh1Z8AAAAAAAAIDUpLXBZ3u2GSO1rBs4fl373SdBz1aV9X0R6Xjp3J04adp0zHAQAAAAAAQAhQWuKyWJ4YudtfLUkqXPep7ECR0TxRHpf6dawnSZq1+oDxe20CAAAAAACg9CgtcdncrQfKiq4mO/uUirYtNh1HAzvVl8vp0N4jWdp58JzpOAAAAAAAACglSktcNsvlkbvjtZIk3/rPZRcVGM0TH+NWr7Z1JEmzVmcYzQIAAAAAAIDSo7TEFYlo3luWt5bsgmz5vp1rOo6GdKkvy5I27zmtQydyTMcBAAAAAABAKVBa4opYDpc8nUZJknybZilYkG00T62EaF2VVlMSqy0BAAAAAAAqOkpLXDFXahc5khpIRfnybfzKdBwN79ZAkrRm23GdzjR7yToAAAAAAACuHKUlrphlOeTpMlqSVLRlvoI5p43maVTbqxYNExQI2przDastAQAAAAAAKipKS5SKM7mNnHXSpIBfvnWfmY6jYf+72nLppiPKyS8ynAYAAAAAAABXgtISpWJZljxdxkiSinZ+rcC5I0bztGqUqAa1YuUrCmrhukNGswAAAAAAAODKUFqi1Jy1msjVsINk2/J984nRLJZlaVjXhpKk+esOqbAoYDQPAAAAAAAALh+lJULC3fkGSZb8+9YqcGKv0SydmtdQ9fhI5eQXadnmo0azAAAAAAAA4PJRWiIknInJcjXtIUkq/OZjs1kcDg3tev7elnPWZCgQDBrNAwAAAAAAgMtDaYmQ8XS6TnI4FTi8Rf7DW41m6dmmjmKjInQqs0DfbD9hNAsAAAAAAAAuD6UlQsYRV0MRLftLkgrXfCTbto1l8UQ4NbBTsiRp1qoMo1kAAAAAAABweSgtEVLuDtdILo+CJ/fJv3+d0Sz9OybLE+HUwRM52rL/jNEsAAAAAAAAuHSUlggpR5RX7rZDJEm+bz6WHTT39O7YqAilt6sr6fxqSwAAAAAAAFQMlJYIOXfbobI8sQqeOyr/zuVGswzuXF9Oh6VtB85q39Eso1kAAAAAAABwaSgtEXKWO1ruDiMkSYXrZsj2+4xlSYqPVJcWtSRJs1YdMJYDAAAAAAAAl47SEmUiomV/WTGJsnPPqGjrIqNZhnVrIElat+Okjp/NM5oFAAAAAAAAF0dpiTJhudxyX3WtJMm34QvZvnxjWZJrxKptapJsSXNWc29LAAAAAACAcBdWpeWsWbN03333KT09Xe3bt9e1116r6dOny7bt4mNuv/12paWlXfBjz549Jc6VnZ2tJ554Ql26dFGHDh30wAMP6MSJE+X9laq0iGa95IivLbswR77Ns41mGd6toSRp2bfHlJlTaDQLAAAAAAAA/jOX6QD/6q233lK9evX02GOPKSEhQStWrNCvf/1rHTt2TBMmTCg+rmPHjvrVr35V4r3JycklXk+cOFG7d+/W008/LY/HoxdeeEHjx4/Xxx9/LJcrrL52pWU5nHJ3vkEF8yfJt3m2IloNkCPKayRL0+R4pdbzas/hLM1fd0g39Ek1kgMAAAAAAAAXF1bt3auvvqrExMTi1927d9e5c+c0depU/fznP5fDcX5hqNfrVfv27X/0PBs2bNCyZcs0ZcoU9erVS5LUuHFjDR8+XHPnztXw4cPL9Hvg/7gad5KjRmMFT+6Tb8MXiuxxm5EclmVpWNeGeuWTb7Vw/WEN79ZQUZ6wGn8AAAAAAAD8r7C6PPxfC8vvtWjRQjk5OcrLu/QHqCxdulRer1c9e/Ys3paSkqIWLVpo6dKlIcmKS2NZljydR0uSirYuUjD7pLEs7ZtWV52kaOUX+rVk4xFjOQAAAAAAAPCfhVVp+UPWrVunWrVqKTY2tnjbmjVr1L59e7Vp00Zjx47VN998U+I9e/fuVePGjWVZVontKSkp2rt3b7nkxv9xJbeSs15LKehX4boZxnI4LEtDu5x/kvi8tQflDwSNZQEAAAAAAMCPC+vrY9euXauZM2eWuH9l586dde2116pRo0Y6ceKEpkyZonHjxumdd95Rhw4dJElZWVmKi4u74Hzx8fH67rvvSp3L5Qr7rveKOJ2OEj+HUnS3G5X98dPy71whq8PVciYlX/xNZaBXu7qasWyfzmYXas22E0pvX9dIjqqgLOcJVRMzhVBinhBKzBNCjZlCKDFPCCXmCeUpbEvLY8eO6aGHHlLXrl11xx13FG9/4IEHShzXt29fjRgxQn/72980efLkMs/lcFhKSIgp888xyeuNCv1JE9oo2Lybcrevkn/Dp6o+5rHQf8Yluq5PqqZ+uVWz12Tomj5N5HBYF38TrliZzBOqNGYKocQ8IZSYJ4QaM4VQYp4QSswTykNYlpZZWVkaP368qlWrppdffrn4ATw/JDo6Wn369NGcOXOKt3m9Xh07duyCYzMzMxUfH1+qbMGgraysS7+/ZkXidDrk9UYpKytfgTK4dNrZ4Tppx2rl7fxGJ7dtkqt2k5B/xqXo1qKmps3bqUMncrRg9X51al7TSI7KrqznCVUPM4VQYp4QSswTQo2ZQigxTwgl5gmh4PVGXdJq3bArLQsKCnTPPfcoOztb06ZN+8HLvC8mJSVFK1eulG3bJe5ruW/fPjVr1qzUGf3+yv0HMxAIls13jKutiGa9VLTja+WtnKaoEY9dcN/R8hDhdKj/VfX05YoDmrZwt1o3TpSLpe1lpszmCVUWM4VQYp4QSswTQo2ZQigxTwgl5gnlIayaGr/fr4kTJ2rv3r168803VatWrYu+Jy8vT4sXL1abNm2Kt6WnpyszM1MrV64s3rZv3z5t3bpV6enpZZIdl8Z91XWS06XA0R0KHCr9/UWv1LCuDeWNcev4mTzNX3vIWA4AAAAAAABcKKxKy2eeeUaLFi3Svffeq5ycHG3cuLH4h8/n09q1a3Xvvffq448/1qpVq/T555/rtttu08mTJ/WLX/yi+DwdOnRQr1699MQTT2jWrFlauHChHnjgAaWlpWnw4MEGvyEcsUmKaDlAklS4Zrps28z/mYnyuHRDnxRJ0hcr9ikz12ckBwAAAAAAAC4UVpeHL1++XJL0hz/84YJ9CxYsUI0aNVRUVKTnn39e586dU1RUlDp06KBnnnlGbdu2LXH8Cy+8oOeee05PPfWU/H6/evXqpSeffFIuV1h95SrJ3WGEirYvUfD0Afn3fqOI1K5GcvRsU0cL1x/WgWPZ+nTpHv10WAsjOQAAAAAAAFCSZdu2bTpERRIIBHXmTK7pGGXC5XIoISFGZ8/mlvm9KQrXfybf2k9lxddSzJjfyXKYKZN3H8rU799dJ0vSUz/trIa1L/8eqvhh5TlPqBqYKYQS84RQYp4QaswUQol5QigxTwiFxMSYS3oQT1hdHo6qw916sKzIONmZx1W0Y5mxHE2S49WtZS3Zkt6bv1N0+AAAAAAAAOZRWsIIyx0ld8eRkiTfuhmy/YXGsozumyp3hEO7DmVqzbYTxnIAAAAAAADgPEpLGBPRoq+s2CTZeefk+26BsRyJ3khd3a2hJOnDRbtVWBQwlgUAAAAAAACUljDIckbI0+l6SZJv01eyC83dK3RIlwZK8kbqbHahZq06YCwHAAAAAAAAKC1hmKtJdzkS6kmFufJtmmUshzvCqZv6N5EkzVqdodOZBcayAAAAAAAAVHWUljDKcjjk7nyDJMn33VwF884Zy3JVWg2l1a+mIn9QHy3ebSwHAAAAAABAVUdpCeNcDTvIUTNV8vvkW/+5sRyWZemWgU1lWdKabSe08+A5Y1kAAAAAAACqMkpLGGdZljxdxkiSirYtUTDL3BO8G9SKU592dSVJ783fqWDQNpYFAAAAAACgqqK0RFhw1W0uZ/02kh1Q4dpPjWa5Lj1F0R6XMo7n6OvNR4xmAQAAAAAAqIooLRE2PJ1HS5L8u1cpcDrDWA5vtFvX9mosSfpk6V7lFRQZywIAAAAAAFAVUVoibDirN5QrpYskW4XffGw0S7+O9VQnKVrZeUX6fPl+o1kAAAAAAACqGkpLhBVP5+sly6FAxib5j+4wlsPldOiWAU0lSQvWHdLR07nGsgAAAAAAAFQ1lJYIK4742oponi5J8q2ZLts29yCc1ilJapeapEDQ1rSFu43lAAAAAAAAqGooLRF23B2vlZwRChzfpcDBTUaz3DSgqZwOS5v3nNbmPaeMZgEAAAAAAKgqKC0RdhwxCXK3HiRJKlwzXbYdNJaldmK0BnWqL0n6YMFu+QPmsgAAAAAAAFQVlJYIS+52wyV3lIJnDsm/e5XRLNf0bCRvdISOncnTgnWHjGYBAAAAAACoCigtEZasyFi5210tSSpc+6nsgN9YliiPSzf0SZUkfb58n7JyfcayAAAAAAAAVAWUlghb7taDZEXFy84+qaLti41m6dm2jhrWjlN+YUCfLN1rNAsAAAAAAEBlR2mJsGVFeOS+6lpJkm/957KLCo1lcViWbh3YVJL09aYjOnAs21gWAAAAAACAyo7SEmEtIi1dVlwN2flZ8n0312iWpsnV1LVlLdmS3p+/U7ZtG80DAAAAAABQWVFaIqxZTpc8na+XJPk2zpRdkGM0z5i+qXK7HNp5KFPfbD9hNAsAAAAAAEBlRWmJsOdK7SpHYn2pKF+FG78ymiXRG6nh3RpKkj5atFuFRQGjeQAAAAAAACojSkuEPctyyNNltCSpaMt8BXPPGs0ztGsDJXk9Op1VqNmrM4xmAQAAAAAAqIwoLVEhOOu3lbN2MylQJN+6z4xmcUc4dWP/8w/lmbXqgE5nFhjNAwAAAAAAUNlQWqJCsCxL7u9XW+5YquC5Y0bzdEqroWb1q8nnD+qjxbuNZgEAAAAAAKhsKC1RYbhqN5OzQTvJDqpw7SdGs1iWpVsHNpUlac22E9p58JzRPAAAAAAAAJUJpSUqFE/n0ZIs+feuUeDkfqNZGtSKU3r7upKk9+bvVDBoG80DAAAAAABQWVBaokJxJtWXq0k3SVLhN9MNp5FGpacoyuNSxvEcLfv2qOk4AAAAAAAAlQKlJSocT6dRkuVU4NB38h/ZZjSLN9qta3s2kiR9smSP8gr8RvMAAAAAAABUBpSWqHAc3pqKaNFXklS45iPZttnLsvtflaw6SdHKyivSFyv2Gc0CAAAAAABQGVBaokJyd7xGcrkVPLFX/gPrjWZxOR26eUBTSdL8tYd09HSu0TwAAAAAAAAVHaUlKiRHdDW52wyRJPm++Vh2MGg0T5uUJLVNTVIgaGvawt1GswAAAAAAAFR0lJaosNzthkmeGAXPHpF/9wrTcXTzgKZyOixt3nNam/ecNh0HAAAAAACgwqK0RIVluaPlaX+1JKlw7aeyA0VG89ROjNbATsmSpA8W7JI/YHb1JwAAAAAAQEVFaYkKLaLVQFnR1WTnnFbR1kWm4+iaHo0VFx2hY2fytHD9YdNxAAAAAAAAKiRKS1Rolsst91XXSZJ8G76Q7cs3mic60qUb+qRKkj5btk9ZeT6jeQAAAAAAACoiSktUeBFpvWXF15ZdkC3ft3NMx1GvNnXUsFac8gv9+nTpXtNxAAAAAAAAKhxKS1R4lsMpT+frJUm+zbMVzM8ymsfhsHTLwKaSpKUbjyjjeLbRPAAAAAAAABUNpSUqBVfjTnJUbygVFci38SvTcdSsfjV1aVFTtqT35u+SbdumIwEAAAAAAFQYlJaoFCzLIU+XMZKkoi0LFMw5bTiRNKZvE7ldDu08eE5rd5w0HQcAAAAAAKDCoLREpeGs10rOui2koF+Fa2eYjqOk+EgN69ZQkvThwl3yFQUMJwIAAAAAAKgYKC1RaViWJU+X0ZIk/65lCpw9bDiRNLRrAyV6PTqdVajZazJMxwEAAAAAAKgQKC1RqThrpsrVqKNk2/J984npOPJEOHVjvyaSpJkrD+hMVoHhRAAAAAAAAOGP0hKVjrvTDZJlyb9/nQIn9pqOo87Na6pZcrx8/qA+WrzHdBwAAAAAAICwR2mJSseZWE+upj0lSYVrPjL+5G7LsnTLwGayJK3eelw7D54zmgcAAAAAACDcUVqiUvJcdZ3kcClwZJsCh7eYjqOGtePUu11dSdL783cpaLhIBQAAAAAACGeUlqiUHHHVFdGyvySpcM1046stJen69BRFeZw6cDxbyzcfNR0HAAAAAAAgbFFaotJydxghRUQqeGq//PvWmo4jb4xbI3s2liR9vGSP8gv9hhMBAAAAAACEJ0pLVFqOKK/cbYZIkgq/+Vh2MGA4kTTgqmTVSoxWVl6Rvlix33QcAAAAAACAsERpiUrN3XaorMg42ZnHVLRzmek4cjkdumVAE0nSvG8O6tiZPMOJAAAAAAAAwg+lJSo1yx11/jJxSb51M2T7fYYTSW1Tq6ttapICQVvTFuwyHQcAAAAAACDsUFqi0oto0U9WbJLs3LMq2rrAdBxJ0k39m8jpsLRpz2l9u/e06TgAAAAAAABhhdISlZ7lcstz1XWSpMINX8r2mb8ku05SjAZclSxJ+mDBLvkDQcOJAAAAAAAAwgelJaoEV9MeclSrKxXmyrdpluk4kqSRPRspLjpCR0/nadH6w6bjAAAAAAAAhA1KS1QJlsMpd+cbJEm+b+comJdpOJEUHRmh69NTJEkzlu1TVp75+20CAAAAAACEA0pLVBmuRh3lqJEi+X3ybfjcdBxJUu+2ddWgZqzyC/2a8fU+03EAAAAAAADCAqUlqgzLsuTpOkaSVLRtsYJZJw0nkhwOS7cOaiZJWrLxsDKOZxtOBAAAAAAAYB6lJaoUV90WctZrJQUDKlz3qek4kqRm9aupS4uasm3p/fm7ZNu26UgAAAAAAABGUVqiyvF0GS1J8u9aqcDpg4bTnDembxNFuBzacfCc1u0wvwIUAAAAAADAJEpLVDnOGo3lSuksyVbh8ndk20HTkZQUH6lhXRtIkqYt3C1fUcBwIgAAAAAAAHMoLVElebrdLLk8ChzbqaJti03HkSQN69ZQCXEenc4q0Jw1GabjAAAAAAAAGENpiSrJEZtUfJl44eoPFcw5YziR5Ilw6sZ+TSRJX606oDNZBYYTAQAAAAAAmEFpiSorouUAOWo1kYoKVLDs7bB4AE6XFjXVJDlevqKgpi/ZYzoOAAAAAACAEZSWqLIsh0ORvcdJDqcCGRvl3/eN6UiyLEu3DWwmS9KqLce1+1Cm6UgAAAAAAADljtISVZozsZ7c7UdIkgqXvyu7IMdwIqlh7Tj1bldHkvTP+TsVDIMVoAAAAAAAAOWJ0hJVnrvDCDmq1ZWdn6WCVdNMx5EkjUpPVZTHqQPHsrX826Om4wAAAAAAAJQrSktUeZYzQpHp4yRZ8u/8Wv5DW0xHUnyMW9f0aCxJ+njJXuUX+g0nAgAAAAAAKD+UloAkZ+2mimjVX5JU8PVbsv2FhhNJAzslq1ZClLJyffpyxX7TcQAAAAAAAMoNpSXwvzydR8uKSZSdfVKFaz81HUcup0M3D2gqSZr7zUEdP5NnOBEAAAAAAED5oLQE/pfljlJkrzskSUXfzlHg5H6zgSS1TU1S65REBYK2pi3cbToOAAAAAABAuaC0BP6Fq2F7uVK7SratgqV/lx00ey9Jy7J0y4Cmcjosbdx9St/tPW00DwAAAAAAQHmgtAT+jafHbZInRsHTGfJtnmM6juokxWjAVcmSpPcX7JI/EDScCAAAAAAAoGxRWgL/xhHlVWT3WyVJvnUzFMw8ZjiRNLJnI8VGRejo6Twt2nDYdBwAAAAAAIAyRWkJ/ABX0x5y1mslBYpUsPQt2bZtNE90ZISu75MiSfrs633KzvMZzQMAAAAAAFCWwqq0nDVrlu677z6lp6erffv2uvbaazV9+vQLCqOPPvpIQ4YMUZs2bTRy5EgtWrTognNlZ2friSeeUJcuXdShQwc98MADOnHiRHl9FVRwlmUpsvdPJZdbgaPbVbRjqelISm9bV/Vrxiqv0K8ZX+8zHQcAAAAAAKDMhFVp+dZbbykqKkqPPfaYXn31VaWnp+vXv/61Jk2aVHzMV199pV//+tcaNmyYJk+erPbt22vChAnauHFjiXNNnDhRy5cv19NPP60///nP2rdvn8aPHy+/3+yDVVBxOLw15Ol0vSSpcNUHCuadM5vHYenWgU0lSYs3HtbBEzlG8wAAAAAAAJQVl+kA/+rVV19VYmJi8evu3bvr3Llzmjp1qn7+85/L4XDopZde0tVXX62JEydKkrp166adO3dq0qRJmjx5siRpw4YNWrZsmaZMmaJevXpJkho3bqzhw4dr7ty5Gj58eLl/N1RMEa0HqWjPagVP7lPh8ncVNWiC0TxpDRLUqXlNrd1+Qu/P36n/uqWDLMsymgkAAAAAACDUwmql5b8Wlt9r0aKFcnJylJeXp4MHD2r//v0aNmxYiWOGDx+ulStXyuc7f5+/pUuXyuv1qmfPnsXHpKSkqEWLFlq61Pxlvqg4LIdTkenjJMsp/761Ktq3znQk3dgvVREuh7ZnnNO6HSdNxwEAAAAAAAi5sCotf8i6detUq1YtxcbGau/evZLOr5r8V6mpqSoqKtLBgwclSXv37lXjxo0vWIGWkpJSfA7gUjmTGsjd7nxRXrj8HdmFuUbzVI+P0rCuDSRJHy7aLV9RwGgeAAAAAACAUAury8P/3dq1azVz5kz96le/kiRlZmZKkrxeb4njvn/9/f6srCzFxcVdcL74+Hh99913pc7lcoV913tFnE5HiZ/xf5xdrpN//1oFzx2T75vpiuk7zmiea3o21rLNR3Uqs0Dz1x3SyF6NL/6mcsY8IdSYKYQS84RQYp4QaswUQol5QigxTyhPYVtaHjt2TA899JC6du2qO+64w3ScYg6HpYSEGNMxypTXG2U6QhiKUdSIn+vou0/Jt3WRkjr2U1TDVkYT3Tmytf78z3X6YsV+jUhPVVJ8eP6+MU8INWYKocQ8IZSYJ4QaM4VQYp4QSswTykNYlpZZWVkaP368qlWrppdfflkOx/kGPz4+XpKUnZ2tGjVqlDj+X/d7vV4dO3bsgvNmZmYWH3OlgkFbWVl5pTpHuHI6HfJ6o5SVla9AIGg6TvjxNpK7ZT/5ti7S8S8myXvT72S53MbitGlUTU2T47XrUKbe+GSz7r2utbEsP4R5QqgxUwgl5gmhxDwh1JgphBLzhFBinhAKXm/UJa3WDbvSsqCgQPfcc4+ys7M1bdq0Epd5p6SkSDp/z8rvf/3964iICNWvX7/4uJUrV8q27RL3tdy3b5+aNWtW6ox+f+X+gxkIBCv9d7xS7i5jVLR/g4KZx5W3ZoY8XUYbzXPLwKb6n7fWasV3x9S3Qz01qVe6Ur4sME8INWYKocQ8IZSYJ4QaM4VQYp4QSswTykNY3YTA7/dr4sSJ2rt3r958803VqlWrxP769eurUaNGmj17dontM2fOVPfu3eV2n1/1lp6erszMTK1cubL4mH379mnr1q1KT08v+y+CSstyR8vT63ZJkm/TLAVOZxjN06i2Vz3b1pEkvT9/p4K2bTQPAAAAAABAKIRVafnMM89o0aJFuvfee5WTk6ONGzcW//D5fJKk+++/X19++aVeeuklrV69Wr/5zW+0efNm/fznPy8+T4cOHdSrVy898cQTmjVrlhYuXKgHHnhAaWlpGjx4sKmvh0oiotFVcjXuJNkBFSydKjto9undN6SnKNLt1L6j2Vrx7YW3RQAAAAAAAKhowury8OXLl0uS/vCHP1ywb8GCBUpOTtaIESOUn5+vyZMn64033lDjxo31yiuvqEOHDiWOf+GFF/Tcc8/pqaeekt/vV69evfTkk0/K5Qqrr4wKytNzrPyHtyp4cp+Kvpsnd9uhxrLEx3o0smdjfbhot6Yv2aOr0mooysOcAwAAAACAisuyba4nvRyBQFBnzuSajlEmXC6HEhJidPZsLvemuAS+7UtUuHSq5HQrZsyzcnhrGsviDwT16zdX6/jZfA3r1kBj+jYxluV7zBNCjZlCKDFPCCXmCaHGTCGUmCeEEvOEUEhMjLmkB/GE1eXhQEUSkZYuZ90WUsCngq//IZP9v8vp0E0DmkqS5n1zUMfPVs4n3AMAAAAAgKqB0hK4QpZlKbL3TyRnhAKHt8i/a7nRPO1Sk9S6caL8AVsfLtxtNAsAAAAAAEBpUFoCpeCIry33VddJkgpWvq9gXqaxLJZl6eYBTeWwLG3YdUpb9p0xlgUAAAAAAKA0KC2BUnK3HSJHUgOpMFeFK98zmqVu9Rj1v6qeJOn9BbvkD3CPEQAAAAAAUPFQWgKlZDlciuxzp2Q55N+zWv4DG43mubZXY8VGRejIqVwt3nDYaBYAAAAAAIArQWkJhICzeiNFtBkiSSpY9rZsX76xLDGREbo+PUWSNOPrfcrO8xnLAgAAAAAAcCUoLYEQ8XS6TlZcDdm5Z1S4ZrrRLOnt6iq5RqzyCv2asWyf0SwAAAAAAACXi9ISCBHL5VFk+jhJUtHWhfIf22Usi8Nh6daBTSVJizcc1qETOcayAAAAAAAAXC5KSyCEXPVaytWstyRbhUunyg4UGcvSvGGCOqXVkG1L783fKdu2jWUBAAAAAAC4HJSWQIhFdrtJVpRXwXNH5NvwpdEsN/ZrIpfToe0Z57R+50mjWQAAAAAAAC4VpSUQYlZkrDw9x0qSfBu/VOCMuSd4V68WpaFdG0iS3pu/S7kF5lZ+AgAAAAAAXCpKS6AMuBp3lqthBykYUMHSKbKDQWNZru7WULUSonQ2u1Bvz97BZeIAAAAAACDsUVoCZcCyLHl63i5FRCp4Yq+Kti4wlsXjduruka3kdFj6ZvsJrfjumLEsAAAAAAAAl4LSEigjjthEebreKEkqXDNdwZzTxrI0ruPVyF6NJUnvztupE+fyjWUBAAAAAAC4GEpLoAxFtOgrZ+1mkr9QBV//w+il2Vd3a6imyfEq9AU0+YstChi8ZB0AAAAAAOA/obQEypBlOeRJ/6nkcClwcLP8e1YZy+JwWBo/oqWiPE7tOZylr1YcMJYFAAAAAADgP6G0BMqYs1pduTuOlCQVrnhPwYJsY1mqV4vS2EFpkqTPl+/XnsOZxrIAAAAAAAD8GEpLoBy42w2XIyFZdkG2Cle+bzRLt1a11LVlLQVtW5O/2Kr8Qr/RPAAAAAAAAP+O0hIoB5bTpcg+4yRZ8u9aIf/Bb81lsSzdPriZkrwenTiXr/fn7zKWBQAAAAAA4IdQWgLlxFkzVRGtB0mSCr5+S3ZRgbEs0ZER+tmIlrIkLfv2qNZuP2EsCwAAAAAAwL+jtATKkafz9bJik2TnnFbhN58YzZLWIEHDujWUJP1j9nadzS40mgcAAAAAAOB7lJZAObIiIhXZ+yeSpKLv5ilwYo/RPNf1bqyGteKUW+DXm19uVdC2jeYBAAAAAACQKC2Bcueq31auJt0l2SpYOlV2wNyDcFxOh+4e2VJul0PbDpzVvG8OGssCAAAAAADwPUpLwABPj1tlRcYpeOaQfJtmGs1SJylGNw9oKkn6eMkeZRzPNpoHAAAAAACA0hIwwBEZJ0+PWyVJvvWfK3DuiNE8fdrXVfsm1eUP2Hrji63yFQWM5gEAAAAAAFUbpSVgiCu1m5z120pBvwqXviXbDhrLYlmWfjq8ubwxbh05lauPFpu91yYAAAAAAKjaKC0BQyzLUmSvOySXR4FjO1W0bbHRPN5ot+4c3kKStGDdIX2797TRPAAAAAAAoOqitAQMcsRVl6fLaElS4eoPFcw9azRP29QkDbgqWZI05attysrzGc0DAAAAAACqJkpLwLCIlgPkqJkqFRWocNnbsm3baJ4xfVNVr3qMsnJ9emvmduN5AAAAAABA1UNpCRhmORyKTL9TcjjlP7BB/n3fGM3jjnBq/DUt5XJa2rj7lJZsNPuQIAAAAAAAUPVQWgJhwJlYT+72IyRJhcvflV2QYzRPg1pxuj49VZL0wYJdOno612geAAAAAABQtVBaAmHC3WGEHNXqyM7PUuHqaabjaHCX+mrRMEE+f1BvfLFV/oC5p5sDAAAAAICqhdISCBOWM0Ke9DslWSra8bX8h7cazeOwLP1sREvFRLp04Fi2Plu2z2geAAAAAABQdVBaAmHEVbupIlr2lyQVfP2WbH+h0TwJcR79ZGhzSdLMlQe0I8Ps080BAAAAAEDVQGkJhBlPl9GyYhJlZ51Q4doZpuOoU/Oa6tWmjmxJb365VXkFRaYjAQAAAACASo7SEggzljtKkb3ukCQVfTtbgVP7zQaSdMvApqpZLUqnswr1ztydpuMAAAAAAIBKjtISCEOuhu3lSuki2bYKlvxddtBvNE+Ux6Xx17SUw7K0eutxrdxyzGgeAAAAAABQuVFaAmHK0+M2yROj4OkM+TbPNR1HqfXiNbJnI0nSu3N36NS5fLOBAAAAAABApUVpCYQpR3S8IrvfIknyrftUwczjhhNJV/doqCb14pVfGNCbX25VMGibjgQAAAAAACohSksgjLma9pSzXispUHT+aeK22ZLQ6XDoZ9e0VKTbqZ2HMjVz1QGjeQAAAAAAQOVEaQmEMcuyFNn7J5LTrcCRbSrasdR0JNWsFqXbBjWTJH22bJ/2Hc0ynAgAAAAAAFQ2lJZAmHN4a8rTeZQkqXDVNAXzzpkNJKlH69rq1LymAkFbb3y+RQU+sw8KAgAAAAAAlQulJVABRLQeLEf1RpIvT4XL3zUdR5Zl6Y4haUqI8+j42Xx9sGC36UgAAAAAAKASobQEKgDL4VRknzslyyH/vrUq2r/OdCTFRkXoZyNaypK0dNMRrd950nQkAAAAAABQSVBaAhWEM6mB3O2GS5IKl70juzDXcCKpRcMEDenaQJL01qztOpdTaDgRAAAAAACoDCgtgQrE3XGkrPhasvPOqXDNR6bjSJJG9U5Rg5qxyskv0pSvtilo+AnnAAAAAACg4itVaXnkyBGtXbu2xLbt27fr0Ucf1cSJEzV//vxShQNQkuVyK7L3OElS0bbF8h/dYTiRFOFy6O6RrRThcmjLvjNasPaQ6UgAAAAAAKCCK1Vp+eyzz+qVV14pfn3q1CndcccdmjdvntauXav7779fc+fOLXVIAP/HVbe5Ipr3kSQVLJ0q2+8znEiqWz1GN/ZrIkn6aPEeHTqRYzgRAAAAAACoyEpVWm7evFk9evQofj1jxgwVFBTos88+09KlS9W9e3f9/e9/L3VIACV5ut4oK7qa7Mxj8q3/3HQcSVL/jvXUNjVJ/kBQb3yxRT5/wHQkAAAAAABQQZWqtMzMzFRSUlLx68WLF6tz585q0KCBHA6HBg0apL1795Y6JICSLE+MPD1vlyT5Ns1S4HSG4USSZVkaN7yF4qIjdOhkrj5atMd0JAAAAAAAUEGVqrRMTEzUkSNHJElZWVnauHGjevfuXbw/EAjI7/eXLiGAHxTR+Cq5Gl0l2YHzl4kHg6YjKT7GrXHDW0iS5qzO0IYdJwwnAgAAAAAAFVGpSssePXronXfe0dSpU/Xoo4/Ktm0NGDCgeP/u3btVp06dUocE8MM8PcdK7igFT+5T0XfzTMeRJLVvUl39OtSTJL3wwXpl55m/5yYAAAAAAKhYSlVaPvLII0pJSdEf//hHLV++XI8++qjq168vSfL5fJo1a5a6d+8ekqAALuSISZCn282SpMK1HyuYddJwovNu7N9EdZKidSarUH//apts2zYdCQAAAAAAVCCu0ry5evXq+uCDD5SdnS2PxyO32128LxgM6h//+Idq165d6pAAflxEWrr8u1YqcHS7Cr5+S1HDfynLsoxm8kQ4dd91rfXbt77Ruh0n9fXmo0pvV9doJgAAAAAAUHGUaqXl9+Li4koUlpIUGRmp5s2bq1q1aqH4CAA/wrIsRab/VHK6FDi8Rf5dK0xHkiQ1quPV2KHn72/5/vxdOn4mz3AiAAAAAABQUZSqtFy5cqXefPPNEtumT5+uvn37qkePHvr973+vQCBQqoAALs4RX1vuq66TJBWsfE/B/Cyzgf7XdX2bqEXDBBUWBfTGF1vlD5h/WBAAAAAAAAh/pSotX375ZW3fvr349Y4dO/Sb3/xGiYmJ6tKli9555x1NmTKl1CEBXJy77VA5khpIhbkqXPGe6TiSJKfD0t0jWyna49K+o1n6Yvl+05EAAAAAAEAFUKrScs+ePWrdunXx688++0yxsbH65z//qRdeeEFjxozRZ599VuqQAC7OcrgUmX6nZFny71klf8ZG05EkSUnxkbpjaJok6cuV+7Xz4DmzgQAAAAAAQNgrVWmZn5+v2NjY4tdff/21evXqpaioKElSmzZtdOTIkdIlBHDJnDUaKaLNEElSwddvy/blG050XpcWtdSjdW3ZtvTml1uVV+A3HQkAAAAAAISxUpWWderU0bfffitJOnDggHbt2qVevXoV78/MzLzgAT0Aypan0yhZcTVk555R4TfTTccpdtugZqoeH6lTmQX657ydpuMAAAAAAIAwVqrS8pprrtGHH36oe++9V3fddZfi4+M1YMCA4v1btmxRo0aNSpsRwGWwXB5F9v6pJKloy0IFju0yG+h/RXlcGn9NS1mWtHLLMa3Zdtx0JAAAAAAAEKZKVVree++9uvvuu3Xs2DHVqVNHkyZNktfrlSSdO3dOa9asUf/+/UMSFMClcyW3kqtZL0m2CpZOlR0oMh1JktQ0uZpGdG8kSXp79g6dziwwGwgAAAAAAIQly7Zt23SIiiQQCOrMmVzTMcqEy+VQQkKMzp7Nld8fNB0HpWQX5Cj3oydk52fJ3fFaeTqNKtfP/7F58geCeu7d9dp3NEtp9avpv27pIIfDKtdsqJj4OwqhxDwhlJgnhBozhVBinhBKzBNCITExRk7nxddRlmql5b/Kzc3Vnj17tGfPHuXmVs5SD6hIrMhYeXqMlST5Nn6pwJnDhhOd53I6dPfIlvJEOLXj4DnNXpNhOhIAAAAAAAgzpS4tN2/erNtvv11dunTRiBEjNGLECHXp0kV33HFH8UN6AJjhSuksZ4P2UjCggsVvyPYXmo4kSaqVEK1bBzaVJH26dK8OHMs2nAgAAAAAAISTUpWWmzZt0tixY7V161aNHj1ajz/+uB5//HGNHj1aW7du1dixY7V58+ZQZQVwmSzLUmSvO2R5YhU8dUAFS/6ucLkjRK+2dXRVsxoKBG29/vkWFRYFTEcCAAAAAABhwlWaNz///POqVauW3nvvPdWoUaPEvvvvv1+33HKLnn/+eU2dOrVUIQFcOUdsoiIHTVD+V/9P/j2r5UuoJ0/HkaZjybIs/WRYc+05kqljZ/L04cLdun1ImulYAAAAAAAgDJR6peVNN910QWEpSdWrV9eNN96ojRs3luYjAISAq25zeXr+7/0t136iov3rDCc6LzYqQndd3VKStGjDYW3cdcpwIgAAAAAAEA5KVVo6HA4FAj9+SWcwGJTDEbJn/QAoBXfLfopoNUCSVLDwDQVOHzSc6LxWjRM1uHN9SdLUWduUmesznAgAAAAAAJhWqkaxQ4cO+uc//6nDhy98KvGRI0f03nvvqWPHjqX5CAAh5Ol+q5z1Wkr+QuXPeUHB/CzTkSRJN/RJUXKNWGXnFWnqzG1hc99NAAAAAABgRqlKy4cffljZ2dkaNmyYHnnkEb388st6+eWX9fDDD2vYsGHKysrSI488EqqsAErJcjgVNeDnsry1ZOecVsG8V2QH/KZjKcLl1D0jW8rldGjzntNauP7C/xECAAAAAACqjlKVli1bttRHH32k3r17a+HChZo0aZImTZqkRYsWqXfv3nr//feVkJAQqqwAQsCKjFXUkAeliCgFju1U4fK3w2JlY70asRrTL1WS9OGi3Tp8KtdwIgAAAAAAYEqpbzjZpEkTTZo0SevWrdOyZcu0bNkyrVu3Tq+88ooWLVqkvn37hiAmgFByJtRV1ID7JMtS0falKtoy33QkSdLAq5LVunGiivxBTf58i4r8QdORAAAAAACAASF7So7D4VD16tVVvXp1Hr4DVACuBm3l6XqjJKlw5XvyH/rOcCLJsizdeXULxUZFKONEjj5dutd0JAAAAAAAYEBYtYsHDhzQU089pWuvvVYtW7bUiBEjLjjm9ttvV1pa2gU/9uzZU+K47OxsPfHEE+rSpYs6dOigBx54QCdOnCivrwJUCBFthsrVrJdk28qf/zcFzx0zHUnVYj0aN6y5JGnOmgxt23/GcCIAAAAAAFDewqq03LVrl5YsWaKGDRsqNTX1R4/r2LGjpk2bVuJHcnJyiWMmTpyo5cuX6+mnn9af//xn7du3T+PHj5ffb/6hI0C4sCxLkb1/IketJpIvT3lzXpBdaP5ekh2a1VCf9nVlS3rzq23KyS8yHQkAAAAAAJSjsCot+/fvryVLluill15Sq1atfvQ4r9er9u3bl/jh8XiK92/YsEHLli3T7373Ow0fPlwDBgzQiy++qB07dmju3Lnl8VWACsNyRihq0ARZMYmyM48pf8GrsoMB07F0c/+mqpUYrbPZhXp7zo6weFgQAAAAAAAoH67LfcOWLVsu+djLvRw7VPfCXLp0qbxer3r27Fm8LSUlRS1atNDSpUs1fPjwkHwOUFk4oqspasiDyvv8dwoc+k6Fqz9UZPdbjGbyuJ26+5qW+v0767R2+wmtSE1SzzZ1jGYCAAAAAADl47JLyxtuuEGWZV3SsbZtX/Kxl2PNmjVq3769AoGA2rVrpwcffFCdO3cu3r937141btz4gs9OSUnR3r082AP4Ic7qDRXZd7wK5k9S0bdz5Eyop4jm6UYzNa7j1bW9GuuTpXv17rydapocr5oJ0UYzAQAAAACAsnfZpeVzzz1XFjkuWefOnXXttdeqUaNGOnHihKZMmaJx48bpnXfeUYcOHSRJWVlZiouLu+C98fHx+u670j8h2eUKq6vqQ8bpdJT4GVWPq1lX6dxhFaydoYJl/1BEUh256qRd0blCNU8jezXWln1ntOPgOb351Tb99x1XyRmiVdmoWPg7CqHEPCGUmCeEGjOFUGKeEErME8rTZZeWo0aNKoscl+yBBx4o8bpv374aMWKE/va3v2ny5Mll/vkOh6WEhJgy/xyTvN4o0xFgULXBt+lEznHlbl+p3Dkvq96df1REfM0rPl8o5unROzrrgb8s0u5DmZq39rBuGdK81OdExcXfUQgl5gmhxDwh1JgphBLzhFBinlAeLru0DDfR0dHq06eP5syZU7zN6/Xq2LFjFxybmZmp+Pj4Un1eMGgrKyuvVOcIV06nQ15vlLKy8hUIBE3HgUERve+U89RhBU5l6Mj7zynu+idlRURe1jlCOU8RlnT70OZ6bcZ3+mDeTjWp61WT5NL9WUbFw99RCCXmCaHEPCHUmCmEEvOEUGKeEApeb9Qlrdat8KXlD0lJSdHKlSsvuKfmvn371KxZs1Kf3++v3H8wA4Fgpf+OuAgrQpGDH1Tep88ocDpDOfNeV+SgX8iyLv8SgFDNU5fmNbWxZS2t2npcr874Vk+P66IoT6X8KwwXwd9RCCXmCaHEPCHUmCmEEvOEUGKeUB4q/E0I8vLytHjxYrVp06Z4W3p6ujIzM7Vy5cribfv27dPWrVuVnm72wSJAReGITVLUoPslh0v+/evkWzfDdCSNHdxMSV6PTp4r0Pvzd5mOAwAAAAAAykhYLVPKz8/XkiVLJEmHDx9WTk6OZs+eLUnq0qWL9u7dqzfffFODBg1SvXr1dOLECU2dOlUnT57Uiy++WHyeDh06qFevXnriiSf0q1/9Sh6PR88//7zS0tI0ePBgI98NqIictZsqsvdPVLBkinzrP5cjIVkRqV2M5YmOjND4a1rpj++t17Jvj6ptapI6Nb/y+20CAAAAAIDwFFal5enTp/Xggw+W2Pb967ffflu1a9dWUVGRnn/+eZ07d05RUVHq0KGDnnnmGbVt27bE+1544QU999xzeuqpp+T3+9WrVy89+eSTcrnC6isDYS8irbcCZw+raPNsFSx+Uw5vTTlrNDKWp1n9ahreraG+WnlA/5i9XSl1vUr0Xt79NgEAAAAAQHizbNu2TYeoSAKBoM6cyTUdo0y4XA4lJMTo7Nlc7k2BEuxgUPlzXlDg4GZZMQmKHvUbOaKr/cf3lOU8+QNB/f6dddp/LFstGibokZvby/Ev969F5cTfUQgl5gmhxDwh1JgphBLzhFBinhAKiYkxl/Qgngp/T0sAZc9yOBQ14F45qtWRnXtW+XNfku33Gcvjcjp098hWckc4tO3AWc1dc9BYFgAAAAAAEHqUlgAuieWOVtSQByVPjIIn9qrg67dkcqF27cRo3TygqSTpk6V7lHE821gWAAAAAAAQWpSWAC6ZI762ogb+QrIc8u9aoaLNs4zm6dOurjo0rS5/wNbrn2+RryhgNA8AAAAAAAgNSksAl8VVr6U83W+VJBWu/kj+AxuNZbEsSz8d1lzxMW4dPZ2njxbtMZYFAAAAAACEDqUlgMsW0WqAIpr3lWQrf+FrCpw5bCxLXLRbd13dQpK0YP0hbd5z2lgWAAAAAAAQGpSWAC6bZVny9BwrZ500qahA+XNekF2QYyxP65QkDbwqWZL095nblJVr7iFBAAAAAACg9CgtAVwRy+lS5KAJsuJqyM4+qfz5k2QH/cbyjO6bqnrVY5SV69Nbs7YraPAhQQAAAAAAoHQoLQFcMUdk3PknikdEKnBkmwpXvGcsizvCqbtHtpLLaWnj7lOavpj7WwIAAAAAUFFRWgIoFWdisqL63SPJUtHWhfJtXWgsS/2asfrJ0OaSpNmrMzR7dYaxLAAAAAAA4MpRWgIoNVejDnJ3uUGSVLj8XfmPbDOWpWebOhrTN1WS9OGi3Vr53TFjWQAAAAAAwJWhtAQQEu52V8vVpLtkB5U/7xUFMo8byzK0awMN7lxf0vkH8/BEcQAAAAAAKhZKSwAhYVmWItPHyVGjsVSYq5yZLyhYmGcsy439m6hby1oKBG39bca32nMk00gWAAAAAABw+SgtAYSM5XIravADsqKrKXj2sE7MeEF2MGgki8OydOfVLdSqcaJ8RUG9+NFmHT2dayQLAAAAAAC4PJSWAELKEZOgqMEPSM4I5e1ep/zVHxnL4nI69ItRrdW4Tpxy8ov012kbdTa70FgeAAAAAABwaSgtAYScs2aKYvr/TJJUuOErFe1cbixLpNulB8e0U63EaJ3OKtRfP9yo3IIiY3kAAAAAAMDFUVoCKBPupt1Vrcf1kqSCr6cqcHy3sSzeaLceubGd4mPdOnwyVy9N3yxfUcBYHgAAAAAA8J9RWgIoMwl9b1FE445SwK/8uS8pmHPGWJbq1aL08I3tFeVxadehTL322RYFDN1vEwAAAAAA/GeUlgDKjGU5FDPgHjkSk2XnZyl/7ouy/ebuKVm/ZqweuKGNXE6HNu4+pbdn75Bt28byAAAAAACAH0ZpCaBMWe4oRQ15UFZknIKnDqhg8RSjRWFagwTde20rWZb09eaj+vTrvcayAAAAAACAH0ZpCaDMOeJqKHLQBMlyyr93jXwbvjCap2OzGrpjSJok6csVBzR/7UGjeQAAAAAAQEmUlgDKhatOmjy9bpck+dZ+oqJ9a43m6dO+nkb1bixJen/+Lq3ZdtxoHgAAAAAA8H8oLQGUG3eLvopoPUiSVLDoDQVOZxjNM6JHI/XvWE+2pMlfbNWW/eYeFAQAAAAAAP4PpSWAcuXpdrOc9VpJfp/y57yoYH6WsSyWZenWgc3UqXlNBYK2XvnkWx04lm0sDwAAAAAAOI/SEkC5shxORQ38uaz4WrJzTqtg3iuyA0XG8jgclsaPaKkWDRNU6Avo+Q836vjZPGN5AAAAAAAApSUAAyxPjKKGPCi5oxQ4tlOFy942+kTxCJdDE65vowY1Y5WVV6S/fLBRmTmFxvIAAAAAAFDVUVoCMMJZra6iBtwnWZaKdnytou/mGs0T5XHpoRvbqUa1SJ3KLNBfP9ykvAK/0UwAAAAAAFRVlJYAjHHVbytP15slSYWrPpD/4LdG88THevTITe3ljY7QwRM5euWTzSryB4xmAgAAAACgKqK0BGBURJvBcjXrLdm28hf8TcFzR43mqZkQrYdubK9It1PbM85p8hdbFQyau3QdAAAAAICqiNISgFGWZSmy9x1y1Goi+fKVN+cF2YW5RjM1rB2n+69vI5fT0todJ/XP+TuN3nMTAAAAAICqhtISgHGWM0JRg+6XFZMoO/O48uf/TXbQ7GXZLRol6mcjWsqStGj9YX2xfL/RPAAAAAAAVCWUlgDCgiM6/vwTxV1uBQ5vUeGqD0xHUpcWtXTroGaSpBnL9mnxhsOGEwEAAAAAUDVQWgIIG87qDRXZ725JUtF38+TbvsRwImnAVcka0aORJOmduTu0bscJs4EAAAAAAKgCKC0BhJWIxp3kvmqUJKlw2dvyH91hOJE0qndjpberK9uWXv98q3ZknDUdCQAAAACASo3SEkDYcXccKVdKZykYUMG8VxTMPmk0j2VZun1IM3VoWl3+QFAvfbxZGcezjWYCAAAAAKAyo7QEEHYsy1Jk35/JUb2h7IJs5c95SXZRgdFMTodD94xspWbJ8covDOj5Dzfp5Ll8o5kAAAAAAKisKC0BhCXL5VHU4AdkRXkVPHNQBYvekG0HjWZyRzj1wOi2Sq4Ro8xcn/46baOy8nxGMwEAAAAAUBlRWgIIW47YJEUNfkByuOTfv16+tZ+ajqToyAg9dGN7JXkjdfxsvl74cJPyC/2mYwEAAAAAUKlQWgIIa85aTRSZPk6S5NvwhYp2rzKcSEqI8+jhm9opNipC+49l62+ffit/wOwqUAAAAAAAKhNKSwBhL6JZT0W0HSZJKlgyRYGT+wwnkuokxWjimHbyRDi1Zf9ZTflqm4K2bToWAAAAAACVAqUlgArB02WMnA3aSYEi5c99ScG8c6YjKaWuV78Y1VpOh6XVW4/rgwW7ZFNcAgAAAABQapSWACoEy+FQVP975ahWV3bu2fNPFPebfwhO65Qk3Xl1C0nS/LWHNGt1huFEAAAAAABUfJSWACoMyx2lqCEPSp4YBU/uVcHSqWGxsrF7q9q6uX8TSdL0xXv09eYjhhMBAAAAAFCxUVoCqFAc8bUUNfAXkuWQf/dK+TbNNB1JkjS4SwMN69pAkvSPWTu0cfcpw4kAAAAAAKi4KC0BVDiuei3l6XGbJMm3Zrr8BzYYTnTe6L6p6tm6toK2rddmfKfdhzJNRwIAAAAAoEKitARQIblbDVBEi36SbOUvfF2BM4dMR5JlWfrJsOZqm5oknz+oF6dv0uGTOaZjAQAAAABQ4VBaAqiwPD1vk7NOc6moQPlzXlSwINt0JLmcDt13XWul1vUqt8Cvv364SWeyCkzHAgAAAACgQqG0BFBhWQ6XogZNkBVXQ3b2SRXMmyQ76DcdS54Ipx4c0051kqJ1NrtQf5m2UTn5RaZjAQAAAABQYVBaAqjQrMhYRQ2ZKEVEKnB0uwqX/9N0JElSbFSEHrmpvRLiPDp6Ok8vfrRJhb6A6VgAAAAAAFQIlJYAKjxnYj1F9b9XkqWibYvk27LAdCRJUqI3Ug/f2E4xkS7tOZKlVz/7Tv5A0HQsAAAAAADCHqUlgErB1bC93F1GS5IKV7yrol0rDCc6r16NWD04up3cLoc27zmtf8zaLtu2TccCAAAAACCsUVoCqDTc7YYronm6ZNsqWDRZvq2LTEeSJDVJjte917WWw7K0/Ltjmr54j+lIAAAAAACENUpLAJWGZVny9P6pIloNkGSrcNk/5Ns823QsSVL7JtX102HNJUmzVmdozpoMw4kAAAAAAAhflJYAKhXLcsjTY6zc7YZLkgpXfaDCdZ+FxSXZvdrW0ei+qZKkaQt3a+WWY4YTAQAAAAAQnigtAVQ6lmXJ3WWM3J2ulyT51n2qwtXTwqK4HNa1gQZ1qi9J+vtX2/Td3tOGEwEAAAAAEH4oLQFUSpZlydNxpDzdb5EkFW2ercJlb8u2zT6927Is3TSgibq2rKVA0NakT7/T3iNZRjMBAAAAABBuKC0BVGruNkPkSR8nyVLRtkUqWPym7GDAaCaHZemuq1uoVeNEFRYF9MJHm3T0dK7RTAAAAAAAhBNKSwCVnrt5H0X2v0eyHPLvWqGCBa/KDviNZnI5HfrFqNZqXCdOOflF+uu0TTqbXWg0EwAAAAAA4YLSEkCVENGkmyIHTZAcLvn3rVX+3Jdk+31GM0W6XXpwTDvVSojS6awC/fXDjcorKDKaCQAAAACAcEBpCaDKiGjUUVFDJ0pOtwIHNyt/1l9l+/KNZvJGu/XITe0VH+vW4ZO5emn6ZvmKzF6+DgAAAACAaZSWAKoUV3JrRQ1/RIqIVODoduXN/H+yC83eT7J6tSg9fGN7RXmc2nkoU69/vkWBoNkHBgEAAAAAYBKlJYAqx1UnTdFXPyp5YhQ8sVd5X/5BwXyzT/CuXzNWD9zQVi6nQxt2ndI7c3bKtm2jmQAAAAAAMIXSEkCV5KyZouhrHpMV5VXw9EHlf/GcgrlnjWZKa5Cge69tJcuSlm46ohlf7zOaBwAAAAAAUygtAVRZzsT6ir7mCVkxiQqeO6q8z3+vYNZJo5k6Nquh24ekSZK+WLFfC9YdMpoHAAAAAAATKC0BVGmOarUVPfJxWd6asrNPKu+L3ytw7ojRTH3b19N1vRtLkt6bt1Nrth03mgcAAAAAgPJGaQmgynPE1VD0NY/LkVBXdu5Z5X/+nAKnM4xmuqZHI/XrWE+2pMlfbNXW/WeM5gEAAAAAoDxRWgKAJEdMgqKueVyOpIayC7KV98UfFDixx1gey7J028Bm6pRWQ4GgrVc++VYHjmUbywMAAAAAQHmitASA/+WIjFP0iEflqNVE8uUp76v/J/+RbebyOCyNv6aVmjeopgJfQM9/uFEnzuYZywMAAAAAQHmhtASAf2F5YhQ9/Jdy1m0hFRUof9Zf5T+42VieCJdD99/QVg1qxiorr0h/mbZRmbk+Y3kAAAAAACgPlJYA8G+siEhFDX1IzgbtpECR8ue8qKJ9a43lifK49NCN7VSjWqROnivQ8x9uVH6h31geAAAAAADKGqUlAPwAy+VW1KD75UrpLAUDKpj/NxXtWmEsT3ysRw/f1F7e6AhlHM/RK598qyJ/0FgeAAAAAADKEqUlAPwIy+lSZP/75GrWS7KDKlg0Wb6ti4zlqZUQrYdubC+P26ltB85q8hdbFAzaxvIAAAAAAFBWKC0B4D+wHA5F9rlTEa0GSLJVuOwf8m2eZSxPw9pxuv/6NnI6LK3dcVLvzd8p26a4BAAAAABULpSWAHARluWQp8dYudtfLUkqXDVNhetmGCsLWzZK1PhrWsqStHD9Yb03bxcrLgEAAAAAlQqlJQBcAsuy5OkyRu5O10uSfOtmqHD1NGPFZZcWtTR2cDNJ0oL1h/TSx5t5OA8AAAAAoNIIq9LywIEDeuqpp3TttdeqZcuWGjFixA8e99FHH2nIkCFq06aNRo4cqUWLLrzHXHZ2tp544gl16dJFHTp00AMPPKATJ06U9VcAUMl5Oo6Up/stkqSizbNVuOxt2baZB+L065isn1/XWhEuhzbvOa0//HO9zmQVGMkCAAAAAEAohVVpuWvXLi1ZskQNGzZUamrqDx7z1Vdf6de//rWGDRumyZMnq3379powYYI2btxY4riJEydq+fLlevrpp/XnP/9Z+/bt0/jx4+X3sxIJQOm42wyRJ32cJEtF2xapYPGbsoMBI1k6Na+pR2/tIG90hA6eyNH/vL1WB45lG8kCAAAAAECohFVp2b9/fy1ZskQvvfSSWrVq9YPHvPTSS7r66qs1ceJEdevWTb/97W/Vpk0bTZo0qfiYDRs2aNmyZfrd736n4cOHa8CAAXrxxRe1Y8cOzZ07t7y+DoBKzN28jyL73yNZDvl3rVDBgldlB8z8T5HUuvF68o5Oqlc9Rpk5Pj33z3XasPOkkSwAAAAAAIRCWJWWDsd/jnPw4EHt379fw4YNK7F9+PDhWrlypXw+nyRp6dKl8nq96tmzZ/ExKSkpatGihZYuXRr64ACqpIgm3RQ5aILkcMm/b63y574k2+8zkqV6tSg9PvYqtWqcKF9RUK988q3mrsngyeIAAAAAgAoprErLi9m7d68kqXHjxiW2p6amqqioSAcPHiw+rnHjxrIsq8RxKSkpxecAgFCIaNRRUUMnSk63Agc3K3/WX2X78o1kiY506cHRbdW3fV3Zkj5YuFvvzt2pQNDMPTcBAAAAALhSLtMBLkdmZqYkyev1ltj+/evv92dlZSkuLu6C98fHx+u7774rdQ6Xq0J1vZfM6XSU+Bkojao0T65GbeW85r+U89VfFDi6Xfmz/qzYq38pR2RM+WdxOTTu6haqUz1GH8zfpUUbDutUZoEm3NBGUZ4K9Vf+BarSTKHsMU8IJeYJocZMIZSYJ4QS84TyVLH/C9YAh8NSQkL5FxHlyeuNMh0BlUiVmaeEjvImPKNjH/yPAsf3KP/LP6rOrU/JGRNvJM6tw1qqcXKC/vLeOn2797R+/846PXVXN9VMjDaSJ5SqzEyhXDBPCCXmCaHGTCGUmCeEEvOE8lChSsv4+PP/8Z+dna0aNWoUb8/Kyiqx3+v16tixYxe8PzMzs/iYKxUM2srKyivVOcKV0+mQ1xulrKx8BQJcTorSqZLzFFVHsSMfV/bnf5LvxH4dfOu/FTfyV3LEJhqJ0zzZqyduv0p/nbZRB45l6+EXluihm9oppa6ZIrW0quRMocwwTwgl5gmhxkwhlJgnhBLzhFDweqMuabVuhSotU1JSJJ2/Z+X3v/7+dUREhOrXr1983MqVK2Xbdon7Wu7bt0/NmjUrdQ6/v3L/wQwEgpX+O6L8VLl5iq+n6GseV95Xf1Lw3FFlffo7RV/9qBzeGhd/bxmoXyNWv76jk174aLMOnczR799ep/HXtNRVaTWN5AmFKjdTKFPME0KJeUKoMVMIJeYJocQ8oTxUqJsQ1K9fX40aNdLs2bNLbJ85c6a6d+8ut9stSUpPT1dmZqZWrlxZfMy+ffu0detWpaenl2tmAFWPo1ptRY98Qpa3puzsk8r74vcKnDtiLE+iN1KPj+2oNilJ8vmDmvTpd5q1+gBPFgcAAAAAhK2wWmmZn5+vJUuWSJIOHz6snJyc4oKyS5cuSkxM1P33369f/vKXatCggbp27aqZM2dq8+bNevfdd4vP06FDB/Xq1UtPPPGEfvWrX8nj8ej5559XWlqaBg8ebOS7AahaHHHVFT3yCeV/9ScFzx5R/ufPKerq/5IzqYGRPFEelx4Y3Ubvz9+lhesP66NFe3T8TL7GDm4mFzfRBgAAAACEGcsOo6U2hw4d0oABA35w39tvv62uXbtKkj766CNNnjxZR44cUePGjfXwww+rX79+JY7Pzs7Wc889p3nz5snv96tXr1568sknVatWrVJlDASCOnMmt1TnCFcul0MJCTE6ezaXZd4oNebpvGBBtvK/+rOCpw9I7mhFD39EzpqpRjPNW3tQH8zfJVtSy0YJ+vl1rRUdGWE006VgphBKzBP+f3t3Hh5XWfd//HPObNm3ZmnTdEn3dC8tXVhaVtmKovRR4BFRAeERUFRUQAERVMAd9PGHFGQRFRQelNICgqVspdBCaem+N0nbNE2afSaznPP7Y5Jp0nRJ25PMJHm/ritXZu4558x3ypfT4cN9zu0k+glOo6fgJPoJTqKf4IScnNRO3dMyoULLnoDQEugc+ukAu7lRTS//WlbFZsmTpOTzvil3YUlca1q5aZ8e/tcaNYciKsxN1TfnTVReVmKvAEhPwUn0E5xEP8Fp9BScRD/BSfQTnNDZ0JJrAgGgixm+VKVceItchSVSKCD/ol8pvHNVXGuaPDJXt/73ScpK82rXvkb95Mnl2lJeG9eaAAAAAABoRWgJAN3A8CQp+fxvyTV4khQJyf/qbxXa+kFcaxrSP113XHWyBuenqa4ppAf++pE+WL83rjUBAAAAACARWgJAtzHcXiV/6ia5h02XrIgCr/+vQhvfiWtN2ek+3frFkzR5RK5CYUt/eOETvbR0OyuLAwAAAADiitASALqRYbqVdNb1co86TbJtBd6Yr+DaxXGtKcnr1o2fm6BzphVJkp5bslV/Wrhe4Qj3qAEAAAAAxAehJQB0M8M0lTTnq/KMO1uSrea3n1Bw1aK41mSahq44Z5T++9xRMgzp7dW79atnVqoxEIprXQAAAACAvonQEgDiwDBM+U75oryTL5IkNb/3jJpXvBD3y7LPnlqkb86bJJ/XpfU7a/STJ1do7/6muNYEAAAAAOh7CC0BIE4Mw5Bv+n/Je/KlkqTgihfUvOyZuAeXE4f30+1fnKqcDJ/2VDfp3idXaFNZTVxrAgAAAAD0LYSWABBnvikXyzfrCklSaNXLan77Sdl2fO8nOSg/TT/80jQN6Z+uBn9IP//rR3pv7Z641gQAAAAA6DsILQEgAXgnfEq+2V+RZCi0brECb8yXbUXiWlNWmk+3XnGSpozMVThi64//Wqt/vbMt7jNBAQAAAAC9H6ElACQI75g5SjrrOskwFd70rgKv/0F2JBzXmnxel2743ASdP32wJOmFt7Zp/oJ1CoVZWRwAAAAA0HUILQEggXhGzFTSuTdKplvhbcvlf/VB2eFgXGsyDUOfP2uEvnTeaJmGoaVr9uiXz6xUg5+VxQEAAAAAXYPQEgASjGfoSUo+/2bJ5VWkdJX8i34pO+iPd1k6Y8pA3fz5iUr2ubSxtEY/eXK5KqpZWRwAAAAA4DxCSwBIQO6i8Uq+8DuSJ0mR3RvUtPDnspsb412Wxhf3021fnKp+GUmq2O/XvU8u14ad++NdFgAAAACglyG0BIAE5R4wWilzvy/5UmXt3aqmBffJ8tfFuywV5aXph1dNU/GADDUGwvrF31bq3U92x7ssAAAAAEAvQmgJAAnMlVeslItvlZGcIauqVP4XfyarMf4zGzNTvfreFVM0bXSeIpat+QvW6YW3trKyOAAAAADAEYSWAJDgXDmDlHLx7TJSc2TV7FbTv34qq64y3mXJ53Hp+kvG68KZQyRJ/3pnu/744lqFwpE4VwYAAAAA6OkILQGgBzCz+ivl07fLyMiXXV+pphd/qkjNrniXJdMwNO+M4fryBWPkMg0tW1uhn/9tpeqa4rviOQAAAACgZyO0BIAewkzPVcqnb5eZXSi7cb/8//qZIvt2xLssSdLsSYX61ucnKdnn1uayWv3kyeXaXRX/hYMAAAAAAD0ToSUA9CBmSpaSL75NZr8hsgP1alpwv8Jla+JdliRp7NAc/eDKqcrNTFJlTUA/eXKF1u2I//03AQAAAAA9D6ElAPQwZlK6UuZ+T2bBCCnYJP/CX6h52bOyrXC8S1Nhbqp+eNU0DR+YoabmsH71zEq9tSr+l7EDAAAAAHoWQksA6IEMX6pSLvquPCVnSrIV/Hihmv75U1l1e+NdmjJSvPre5VM0vSRfEcvWnxau13NLtshiZXEAAAAAQCcRWgJAD2W4fUo6/SolnXuj5E2RVblVjc/dqdCmd+Ndmjxul7726XGae8pQSdJLS3fo4X+uUTDEyuIAAAAAgKMjtASAHs5TPE2p8+6Rq/8oKRRQYPEf5V/8iOygP651mYahz80epqsvKpHLNPTB+r36+V8/Ul0jK4sDAAAAAI6M0BIAegEzrZ+S535f3qmXSIah8KZ31Pj8jxSp3Bbv0nTqhAH6zhcmKzXJrS276nTvk8tVvo+VxQEAAAAAh0doCQC9hGG65Jt6iZIvvk1Gao7sugo1/fNeBVctkm1bca1tzJBs3X7lVOVnJWtfbUA/fWq51myvjmtNAAAAAIDERWgJAL2Mu/8opc67R+7iaZIVUfN7z8i/6FeymmriWteAfqn6wZemamRRpvzNEf36mY+1ZGV5XGsCAAAAACQmQksA6IUMX6qSzrlBvtO/LLm8ipR9oqbn7lS4dFVc60pP8eqWy6Zo5rgCWbatJ17eoGcXb2ZlcQAAAABAO4SWANBLGYYhb8kZSvncXTJzimT76+Rf9CsFlv5VdiQUt7o8blPXzh2rz5xWLEl6edlO/eH/PlEzK4sDAAAAAFoQWgJAL+fKHqiUS+6UZ9zZkqTQ6lfU9M97ZdXsiVtNhmHoM6cV69qLx8rtMrRiY6Ue+MuHqm1ojltNAAAAAIDEQWgJAH2A4fYq6dQrlfypb8rwpcnat0ONz9+l0Ia3ZMfx0uxZ4/rrlsumKC3Zo22763Xvk8tVtrchbvUAAAAAABIDoSUA9CHuoVOUMu8euQpLpHCzAkseVeA/D8sONsWtplGDsvSDL01VQU6Kquqa9dM/r9DqrVVxqwcAAAAAEH+ElgDQx5ip2Uq+8LvynnypZJgKb3lPjc/dpUjF5rjVVJCdoh9cOVVjBmcpEIzot39fpcUflsWtHgAAAABAfBFaAkAfZJimfFMuVsqnb5eRniu7vlJN//qpmj9aINuy4lJTWrJH3/7CZJ06vr8s29ZTr27U317fJMtiZXEAAAAA6GsILQGgD3MVjFDqpT+We/gMybYU/OAf8i/8uazG/XGpx+0y9dWLSvTZ2cMkSa9+UKrfPb9azUFWFgcAAACAvoTQEgD6OMOboqSzrlfSnKslt0+RXevU9I87FN6xMj71GIYuPmWorv/MOLldplZu3qf7nv5Q++tZWRwAAAAA+gpCSwCADMOQZ/TpSv3cj2T2GyK7uUH+V36jwDt/lh0OxqWm6SUF+t4VU5Se4tGOinr96LH3tbmsJi61AAAAAAC6F6ElACDGzBqglEt+KM+E8yRJoTWvqemFexTZvysu9YwYmKkffGmaBvRL0f76Zt3y2zf1/JItCoXjc99NAAAAAED3ILQEALRjuDxKmnW5ks//toykdFnVpWp6/kcKrntDtt39i+LkZyXrB1dO1dTReYpYtl54a5t+/PgH2rqrrttrAQAAAAB0D0JLAMAhuQdPVMq8e+QaOE6KBNX81uMKvPZ72c2N3V5LSpJH35g3Ud//0jSlp3hUvq9RP3lquZ75zyY1h1ikBwAAAAB6G0JLAMBhmSlZSr7wO/LN+IJkuBTetlyNz92p8J5N3V6LYRg6bdJA3Xf9LM0aVyDbll55v1R3Pfa+NuyMz2rnAAAAAICuQWgJADgiwzDlnXSBUj7zAxkZ+bIbquR/8adqXvFP2Vb331syPcWray8ep2/Om6jsdJ/27vfr/r98pKde2SB/c7jb6wEAAAAAOI/QEgDQKa78YUr93N1yjzxVsm0FV/yf/C/dL6uhKi71TBqRq3uunqE5kwslSYs/Ktcdjy7T6q3xqQcAAAAA4BxCSwBApxneZCWfea2Szvya5ElSZPcGNT53p0LbVsSlnpQkt646f4y+e/kU5WUlqbquWb9+9mPNX7BWDf5QXGoCAAAAAJw4QksAwDHzjDxFqZ+7W2ZesdTcqMC/H1LgrSdkh4NxqadkSLZ+/NUZ+tTJg2RIeveTPfrh/GVavn5vXOoBAAAAAJwYQksAwHExMwuU8ukfyDvpQklSaN1iNf3f3YpUl8WlHp/XpcvOHqnbrpyqAf1SVNcY1P++8Il+/3+rVdvQHJeaAAAAAADHh9ASAHDcDJdbvhmfV/KFt8hIzpS1v1xN/3e3gmtel23bcalpxMBM/egr0zX3lCEyDUMrNlTqh/OX6Z3Vu+NWEwAAAADg2BBaAgBOmLtovFLm3SPXoIlSJKTmd55S4NUHZQca4lKPx23qc7OH684vT9PggjQ1BsJ69KV1+s3fV6m6LhCXmgAAAAAAnUdoCQBwhJmcoeTzvyXfrCsk063wjo/U+NwdCu9aF7eaBhek64dfmqZL5wyT22Vq9dYq/XD+Mi3+qFwWsy4BAAAAIGERWgIAHGMYhrwTPqWUS+6QmdlfduN++Rc8oOYPnpNtReJSk9tl6qJZQ3X3V0/WiIGZCgQjeuqVDfr5Xz5Sxf6muNQEAAAAADgyQksAgONcuUOU8rm75Rl9uiRbwY9eVNOLP5NVXxm3mgb0S9Wt/32SLj9npLweUxtKa3TXo+/r5WU7ZVnMugQAAACAREJoCQDoEobHp6Q5Vyvp7P+RPMmyKjar8bk7FdqyLG41maahc6cN0o+vnqGSIdkKhi09u3izfvLUCpVXxuf+mwAAAACAjggtAQBdyjN8hlIv/bHM/OFS0K/A639QYMljskPNcaspPytZt1w2WV++YIySfS5t212nH/3pA/3r7W0KR6y41QUAAAAAiCK0BAB0OTMjTymfvk3eKRdLMhTa8Kaanr9LkX074laTYRiaPalQ914zU5NH5Cpi2Xrh7W368ePLtW13XdzqAgAAAAAQWgIAuolhuuU7+VIlz/2ejJQsWbV71PTCPQquflV2HFfyzk736aZLJ+hrnx6rtGSPyiobdO+Ty/X3xZsVDMVn8SAAAAAA6OsILQEA3cpdWKKUeffIPWSKZIXVvPQv8r/yG1n++M1uNAxDM8f2173XztD0knzZtrRo2U7d9acPtLG0Jm51AQAAAEBfRWgJAOh2ZlK6kj71DflOvVJyuRXZ+bGa/nGHwmVr4lpXRopX139mvG66dIIy07yqqG7S/U9/qKdf3ahAMBzX2gAAAACgLyG0BADEhWEY8o47WymfvUtmdqFsf638C3+h5mXPyrbiGxBOGZmnn1wzQ6dNHCBb0usflumO+e9rzbbquNYFAAAAAH0FoSUAIK5cOYOU8tm75Ck5Q5Kt4McL1fTPn8iq2xvXulKSPPrqhSX6zhcmq19GkqrqAvrlMyv12Evr1BgIxbU2AAAAAOjtCC0BAHFnuH1KOv3LSjr3RsmbIqtymxqfu1OhTe/GuzSNK87RPddM19lTi2RIenv1bv1w/jJ9uLEy3qUBAAAAQK9FaAkASBie4mlKnXePXP1HSaGAAov/KP/iR2QH/XGtK8nr1n+fO0rf/++TVJCTotqGoH73/Gr94YVPVNcYjGttAAAAANAbEVoCABKKmdZPyXO/L+/USyTDUHjTO2p8/kcK790a79I0alCW7v7Kybpw5hCZhqEP1u/VD+cv03tr9si27XiXBwAAAAC9BqElACDhGKZLvqmXKPni22Sk5siuq1D98/eo+s1n4j7r0utxad4Zw/XDq6aqKC9NDf6Q/vjiWj34j1XaX98c19oAAAAAoLcgtAQAJCx3/1FKnXeP3MXTJCuimreeVe3Ttyi4+lXZkfguhjO0f4bu/PI0XXJ6sVymoY+3VOmH89/TkpXlzLoEAAAAgBNEaAkASGiGL1VJ59yg1E/dIE/OANn+ejUv/Ysan7lVoQ1vybYicavN7TL16VOL9aOvnKziARnyN0f0xMsb9Iu/rdTemvjOCAUAAACAnozQEgCQ8AzDkHfEDBV97TdKmfMVGSlZshuqFFjyqJr+cYdC25bHdXbjwLw0/eDKqfrCWSPkdZtat2O/7nx0mV79oFSWxaxLAAAAADhWhJYAgB7DcLnlG3emUi97QL4ZX5B8qbJqdinw79+p6YUfK1y2Jm61maah86YP1t1XT9foQVkKhiz97fVN+tnTK7RrX2Pc6gIAAACAnojQEgDQ4xhur7yTLlDa5T+Xd8rFktsnq3Kb/At/rqYF9ysSx5XGC7JT9N0rpujK80YryevSlvI6/ehP72vBu9sVjlhxqwsAAAAAehJCSwBAj2V4U+Q7+VKlXvaAPOPPlUy3IrvWqemFH8v/6kOK7C+PS12mYejMKQN17zUzNGFYP4Ujtp5/c6vufWK5duypj0tNAAAAANCTEFoCAHo8MyVTSaf8t1K/8DO5R50qGYbC21eo6R8/lP+N+bLq98WlrpyMJN38XxN1zdwSpSa5tXNvg+55YrmeW7JFoXD8FhACAAAAgERHaAkA6DXM9Dwln3GtUubdK/fQqZJtK7zxbTU+c6sC7z4ty1/X7TUZhqFTxg/QvdfO1LTRebJsWy8t3aEf/ekDbS6v7fZ6AAAAAKAnILQEAPQ6ruyBSv7UTUq55A65CkskK6zQJ/9W41+/q+blz8sONnV7TZmpXn39sxN0w2fHKyPVq91VTfrZUyv0l9c2qjnIrEsAAAAAaIvQEgDQa7nyhytl7veVfOF3ZeYVS+FmBT/8lxr++l0FP14kOxzs9pqmjs7XvdfM0Cnj+8uW9NryMt3x6DKt3V7d7bUAAAAAQKIitAQA9HruonFKueROJZ17o8ysQqm5Uc3LnlHjM99XcN0bsq3unemYluzRNXPH6ub/mqScDJ/21Qb0i7+t1OOL1qspEO7WWgAAAAAgERFaAgD6BMMw5CmeppR59yhpztUy0vrJbtyv5rceV+Pfb1doyzLZttWtNU0c3k/3XD1DZ04ZKEl68+NduuPRZVq5OT4LBwEAAABAouhxoeXzzz+v0aNHd/j5xS9+0W67v//97zrvvPM0YcIEffrTn9bixYvjVDEAIJEYpkue0acr9Qv3yTfrChlJ6bJrKxR4/Q9qev5uhUtXybbtbqsn2efWleeN1vevmKL87GTtr2/Wg/9YpT+88Il27WvstjoAAAAAIJG4413A8Zo/f77S09NjzwsKCmKPX3rpJd1xxx26/vrrNXPmTC1cuFA33nijnn76aU2ePDkO1QIAEo3h8sg74VPyjD5dwdWvKrhqkayqHfIv+pVcA0bLd/I8ufqP7LZ6Rg/O1t1fna5/vrVNr3ywUx+s36vl6/fqpFF5unDWEBUPyOi2WgAAAAAg3npsaDlu3Djl5OQc8rUHH3xQF110kW6++WZJ0syZM7Vx40b9/ve/1yOPPNKNVQIAEp3hTZZv6mfkGXeWgitfUmjNa4rs3qCmf/1ErsGTouFlv0HdUovP49LnzxqhGWML9OK72/XhxkqtaPkZNzRbF84aqjGDs2QYRrfUAwAAAADx0uMuDz+a0tJSbd++XRdccEG78QsvvFBLly5VMNj9K8UCABKfmZSupJmXKfUL98szZrZkmIrs/FhNz90p/38ellW3t9tqGdI/XTd+boLuaVll3DQMrdm+Xz//60f66VMr9NGmSlndeAk7AAAAAHS3Hhtazp07VyUlJTr77LP18MMPKxKJrvy6detWSVJxcXG77YcPH65QKKTS0tJurxUA0HOYaf2UNPurSv2vn8o9bLokW+HNS9X4zG0KvP2krKaabqtlYG6qrpk7VvddN1NnnTRQbpepLbvq9NBzq3XXY+9r6Zo9iljdu3gQAAAAAHSHHnd5eF5enm666SZNmjRJhmHoP//5j37zm9+ooqJCd955p2prayVJGRnt7/3V+rz19RPhdvfYrPeIXC6z3W/gRNBPcFq391Ruobzn36hw5Xb53/u7wqWrFVr7H4U2vq2kCZ+Sb8pFMpNSu6WU/rmp+vKFJbpk9jC98v5Ovb68TOWVjXrkxbV64a1tumjWEJ02aYC8ble31NMbcI6Ck+gnOI2egpPoJziJfkJ3MuzuXCK1i9x///164okn9MYbb+i9997Td7/7Xb399tvKy8uLbbN69WrNmzdPf/3rX3XSSScd93vZts29xACgD/LvWKPqxU+ruXyDJMlMSlXmzEuUefKFMr1J3VpLgz+kl97Zqn+9uVV1jdHbnmSn+3TJnOE6f9ZQpSR5urUeAAAAAHBaj5tpeSgXXHCBHnvsMa1bt06ZmZmSpPr6+nahZV1dnSTFXj9elmWrrq7phI6RqFwuUxkZyaqr8ysS4XJDnBj6CU6Le09lDFXyp2+Xe/tH8i/7h6zqMu1/42nVvL9ASdM+I1/JGTJc3ffX6qemFmnOxAFasrJcC5fuUHVds/60YK2efW2jzpk2SJ+aPkjpKd5uq6eniXs/oVehn+A0egpOop/gJPoJTsjISO7UbN1eEVq2NWzYMEnRe1u2Pm597vF4NGjQia8AGw737n8xIxGr139GdB/6CU6Ld0+ZgyYrZeBEhbe8p+bl/ye7vlL+N59U4KNF8k37rNzDZ8owu+dyGZdh6KwpRZo9sVBL1+zRovd2ak91k/759jYtWrZDcyYN1HnTBykno3tngvYk8e4n9C70E5xGT8FJ9BOcRD+hO/SK0HLhwoVyuVwaO3as8vLyNHToUL388ss655xz2m0za9Yseb3MOgEAnBjDNOUZeYrcw6YrtP4NBT/8l+z6SgUW/1HmxwvlO/lSuQZP7rbbibhdpk6fWKhTxw/Qhxsr9dLSHdpRUa9/Ly/Vfz4s0ynj++vCmUNUkJPSLfUAAAAAwInqcaHl1VdfrRkzZmj06NGSpNdff13PPvusvvSlL8UuB7/pppt0yy23aPDgwZoxY4YWLlyoVatW6c9//nM8SwcA9DKGyy3vuHPkGXW6gp/8W8GPF8qqLpP/ld/KLBgh38nz5C4c0231mKahaWPyNXV0ntZsr9ZL7+7QhtIavbVqt95evVvTRufrollDNLggvdtqAgAAAIDj0eNCy+LiYj333HPas2ePLMvS0KFDdfvtt+vKK6+MbTN37lz5/X498sgj+uMf/6ji4mL97ne/05QpU+JYOQCgtzI8PvmmzJV37JkKfrxQwdX/llWxWf4F98k1aIJ8J8+TK3dI99VjGBpf3E/ji/tpc1mtXlq6XR9vqdIH6/fqg/V7NWFYP100a4hGDcrqtpoAAAAA4Fj0itXDu1MkYqm6ujHeZXQJt9tUdnaq9u9v5N4UOGH0E5zWk3rKaqpR8MN/KbRuiWRHJEnuYdPlm/Y5mVn941JT6d4GLXxvh95fV6HWv/lHFmXqollDNWFYTrddyp4oelI/IfHRT3AaPQUn0U9wEv0EJ+TkpHZqIR5Cy2NEaAl0Dv0Ep/XEnrLq9qp5+f8pvPk9SbZkmPKMPk3eky6RmZYTl5oq9jfp5WU79c7q3QpHol8BBuen6cJZQzRtdL5Ms2+Elz2xn5C46Cc4jZ6Ck+gnOIl+ghMILbsIoSXQOfQTnNaTeypSVarmD/6hyM6PowMutzzjzpFv8lwZSWlxqWl/fbNe/WCn3vhol5pD0dmgBdnJumDmEJ0yvr/cnfgS0ZP15H5C4qGf4DR6Ck6in+Ak+glOILTsIoSWQOfQT3Bab+ip8J5NCn7wD0V2b4gOeJLknXiBvBM+JcObHJeaGvwhvb6iTK8tL1VjICxJyk736bzpgzVnUqF8Xldc6upqvaGfkDjoJziNnoKT6Cc4iX6CEwgtuwihJdA59BOc1lt6yrZtRcpWq/n9f8iq2ilJMpLS5Z1ysTxjz5Th8sSlrkAwrCUrd+nl93eqtiEoSUpL9uicaUU6e2qRUpPiU1dX6S39hMRAP8Fp9BScRD/BSfQTnEBo2UUILYHOoZ/gtN7WU7ZtKbz1AzUvf152bYUkyUjrJ9/US+QeeaoMMz6XZ4fClt79ZLcWvbdTe2v8kiSf16UzpwzUp04epKw0X1zqclpv6yfEF/0Ep9FTcBL9BCfRT3ACoWUXIbQEOod+gtN6a0/ZVlihDW8ruOIF2U01kiQzq1DeqZfIXXySDNMdl7oilqXl6yv10tIdKqtskCS5XaZOmzhA588YrPys+FzO7pTe2k+ID/oJTqOn4CT6CU6in+CEzoaW8fkvIQAAIEkyTLe8JWfIM/IUhda8ruaVC2TV7FLg9f+VkZwpz+jT5RkzW2ZGfrfW5TJNzRhboOkl+Vq1pUovLd2hzeW1euOjcr25cpemj83XhTOHqCgvPgsJAQAAAOjdCC0BAEgAhtsr76QL5CmZo+CqVxRat1i2v1bBlQsUXLlAroFj5RlzhtxDp3TrfS8Nw9CkEbmaOLyfNpbW6KWlO/TJtmq9t6ZC762p0OQRubpo1hANH5jZbTUBAAAA6P0ILQEASCCGN0W+aZ+V96SLFd6xUqH1SxQp/USR8rWKlK+VkZQu96hT5R0zR2bWgO6ryzA0enC2Rg/O1vY9dVq4dIdWbKjUys37tHLzPo0ZnKWLZg3V2KHZMgyj2+oCAAAA0DsRWgIAkIAM0y1P8TR5iqfJqq9UaMNbCm14S3bjfoVWvazQqpflGjBanjFz5C6eJsPt7bbahvbP0Nc/O0G7qxq16L2dWrpmj9bvrNH6nSs1tH+6Lpo1VFNG5cokvAQAAABwnFiI5xixEA/QOfQTnEZPSbYVUaR0lYLrlihS+rHU+le4L1WeEbPkKZkjV86gbq+rqjagV97fqTc/3qVgyz+bAf1SdOHMIZoxtkDuTtxku7vRT3AS/QSn0VNwEv0EJ9FPcAKrh3cRQkugc+gnOI2eas9q3B+dfbl+ieyGqti4mT9c3jFz5B4+Q4bH16011TUF9dryUr2+olz+5rAkqV+GT+fPGKLTJw6Q1+Pq1nqOhH6Ck+gnOI2egpPoJziJfoITCC27CKEl0Dn0E5xGTx2abVmKlK9RaP0Shbd/JNmR6AuepAOzL3OHdmtN/uawFn9Urlff36m6ppAkKSPFo3NPHqQzpxQpJSn+d6ehn+Ak+glOo6fgJPoJTqKf4ARCyy5CaAl0Dv0Ep9FTR2c11Sq08W2F1r8pu64iNm7mDpFnzBnyjJgpw5vcbfUEQxG9vXq3Xl62U/tqA5KkZJ9LZ51UpHOnDVJGavfdh/Ng9BOcRD/BafQUnEQ/wUn0E5xAaNlFCC2BzqGf4DR6qvNs21Jk1/ro7MttKyQreqm23F55hs+Qp+QMmXnDum2V73DE0vvrKrTwvZ3atS/6d6jHbWr2xEKdN2OQcjO7L0htRT/BSfQTnEZPwUn0E5xEP8EJnQ0t4399FgAAcJRhmHIPHCv3wLGyAvUKb3xXofVvyKrZHVuF3MwpkmfMHHlGniLDl9ql9bhdpk4ZP0Azx/XXyk379NLS7dq2u16vf1imN1aWa+bYAp0+qVAjijJZcRwAAACAJGZaHjNmWgKdQz/BafTUibFtW5GKTQqtW6Lw1velSPRek3J55B52sjxj5sjVf1S3zL60bVvrduzXS0t3aN2O/bHxfhk+TS8p0IyxBRqUn9altdBPcBL9BKfRU3AS/QQn0U9wAjMtAQBAjGEYcvcfJXf/UbJPuUKhzUsVWrdEVnWpwpveVXjTuzKzBsgzZo7co06VmZTepbWMHZqjsUNztGVXrRZ/WK4PN1aqqq5Zi5bt1KJlOzWgX4pmjo0GmPnZKV1WCwAAAIDExEzLY8RMS6Bz6Cc4jZ5ynm3bsiq3KbT+DYU2L5PCzdEXTLfcQ0+Sp+QMuQrHyDCO/n9BT1QwFNGqLVVatrZCH2+pUjhy4J9x8YAMzRhboOkl+cpK8znyfvQTnEQ/wWn0FJxEP8FJ9BOcwEI8XYTQEugc+glOo6e6lh30K7RlmULrl8iq3BYbNzLy5RkzW55Rp8lMyeqWWpoCYX24sVLL1lVo7fZqtX5TMSSNGZKtGWMLNHV0nlKTPMf9HvQTnEQ/wWn0FJxEP8FJ9BOcQGjZRQgtgc6hn+A0eqr7RPbtUGj9EoU2LZVC/uig4ZJ7yGR5SubINXC8DLPrZ19KUm1jUMvX79V7a/doS3ldbNxlGpo4vJ9mjC3QpBG58nlcx3Rc+glOop/gNHoKTqKf4CT6CU4gtOwihJZA59BPcBo91f3sULPCW99XcP0SWRWbY+NGWr+W2Zeny0zL6bZ6Kmv8en9dhZatrVBZ5YG/i30el6aMytWMkgKNK86RuzM39aaf4CD6CU6jp+Ak+glOop/gBELLLkJoCXQO/QSn0VPxFakua5l9+a7U3PL3oGHINWiivGPOkGvwRBnmsc12PBFllQ1atjYaYO6rDcTG05I9mjYmXzNK8jVyUJbMw6xATj/BSfQTnEZPwUn0E5xEP8EJhJZdhNAS6Bz6CU6jpxKDHQ4qvG25QuuXKLJ7Q2zcSMmSZ/Tp8oyZLTM9r/vqsW1t3VWn99ZW6IP1e1XXGIy9lp3u04yS6ArkgwvSZLQJMOknOIl+gtPoKTiJfoKT6Cc4gdCyixBaAp1DP8Fp9FTisWp2K7h+icIb35EdqG8ZNeQqGifPmDlyD5kiw+XutnoilqX1O2q0bG2FVmyslL85HHutf06KZoyNBpj9c1LoJziKfoLT6Ck4iX6Ck+gnOIHQsosQWgKdQz/BafRU4rIjYYV3fKjQuiWKlK+JjRvJGfKMOi06+zKzf7fWFApHtGpLtZatq9DHm/cp1KZnhvRP1ynj++u8U4plWhb9hBPG+QlOo6fgJPoJTqKf4ARCyy5CaAl0Dv0Ep9FTPYNVt1eh9W8qtPFt2U01sXFXYUl09uXQk2S4vd1ak785rI82Veq9tRVau22/rJavPoYhjRmcrZNL8jVtdL7Skj3dWhd6D85PcBo9BSfRT3AS/QQnEFp2EUJLoHPoJziNnupZbCui8M6PFVr3hiJlq6XWrxu+VHlGnipPyRy5sgd2e111TUEtX79X76/bq42lNbFxl2lofHGOZowr0JQRefJ5u29RIfR8nJ/gNHoKTqKf4CT6CU4gtOwihJZA59BPcBo91XNZDVUKbXhLofVvym6sjo27CkbKUzJH7mEny3D7urUmt9tUyDb06tJteveTPSrd2xB7zesxNWVknmaUFGj8sBy5O/GFCn0b5yc4jZ6Ck+gnOIl+ghMILbsIoSXQOfQTnEZP9Xy2ZSlStlqh9UsU3rFSslv+OXqS5S4aJ9egCXIXjZeZ1q/Lazm4n8r3NWrZ2gq9v7ZCe2v8se1Sk9yaOjpfM8cWaNSgLJmmcYSjoq/i/ASn0VNwEv0EJ9FPcAKhZRchtAQ6h36C0+ip3sVqqjkw+7K+st1rZtYAuYrGy100Xq4BY2R4nJ+Febh+sm1b23bXRwPMdRWqbQzGXstK82p6SXQF8qH902UYBJiI4vwEp9FTcBL9BCfRT3ACoWUXIbQEOod+gtPoqd7Jti1Ze7cqXLZG4bLVsvZuOXD/S0ky3XL1HylX0QS5B42XmTPIkbCwM/1kWbY27Nyv99ZWaMWGSjU1h2OvFWQna8bYaIA5oF/qCdeDno3zE5xGT8FJ9BOcRD/BCYSWXYTQEugc+glOo6f6Bru5UeFd6xQp/UThstWyG6ravW4kZxyYhVk0XmZyxnG9z7H2Uyhs6ZOtVVq2rkIrN+1TsM0+gwvSNHNsf00vyVdORtJx1YOejfMTnEZPwUn0E5xEP8EJnQ0t3d1QCwAAQKcYvlR5iqfJUzxNtm3Lrq1QuGy1wmWfKLJrvWx/ncKb3lV407uSJLPfkNj9MF0FI2W4uuarjcdtasqoPE0ZlSd/c1grN+/TsrUVWrOtWjsrGrSzYrOeXbxZowZlacbYAk0bnaf0FG+X1AIAAAD0Bcy0PEbMtAQ6h36C0+gp2JGQIhWbFSn7ROHST2RV7Wi/gdsnV+EYuVtmYhqZ/Q97KblT/VTfFNTyDZVatrZCG0trYuMu09C44hzNKCnQ5JG5Svbx/4l7M85PcBo9BSfRT3AS/QQnMNMSAAD0KobLI3dhidyFJfJN/y9ZTbWKlK+JzsIs+0S2v06RnR8rsvNjNUsy0vrJXTRBrqJxcg8cK8Pn/L0n01O8OnPKQJ05ZaCq6wJ6f91evbd2j3ZWNGjVliqt2lIlr9vUpBG5mjm2QOOH9ZPHffQvaAAAAEBfx0zLY8RMS6Bz6Cc4jZ7Ckdi2Jau6TOHSTxQpW63Ink2SdWDhHBmmzPxhsVmY3gEjlNMvvcv6aXdVo5atrdCytRWq2O+Pjaf43BpXnKNRg7I0alCWBualymQV8h6P8xOcRk/BSfQTnEQ/wQksxNNFCC2BzqGf4DR6CsfCDjUrsnt9bBamVbO73euGL0UpxZNk9y+RUThOZlq/rqnDtrWjol7vranQ++sqVNMQbPd6is+tEUWZsRBzaP90uTvxBQ6JhfMTnEZPwUn0E5xEP8EJhJZdhNAS6Bz6CU6jp3AirIaqaIBZulrh8rVSsKnd62bWgAOrkg8YI8Pjc74Gy9bm8lpt2LlfG0trtLm8Ts2hSLttvG5TwwozNLIoS6MGZ2l4YYaSvNzNJ9FxfoLT6Ck4iX6Ck+gnOIF7WgIAALQw0/rJO2aONGaObMuSUb1d7soNqtv0oSIVm2XV7JZVs1uhT/4tmW65BoySa+B4uQeNl5kz6LAL+hxTDaYRm1EpSRHL0s6KBm0srdHG0hptKqtVgz+k9TtrtH5njfSuZBqGhvRPi+5XlKWRg7KUluw54VoAAACARMdMy2PETEugc+gnOI2egpPa9lOosV7h8rWKlK1RuGy17IaqdtsayRkHZmEWjZeZnNElNdm2rd1VTdEQs6xGm0prVFXX3GG7wtzUlhAzell5TkZSl9SDzuP8BKfRU3AS/QQn0U9wAjMtAQAAOsHwpcoz7GR5hp0s27Zl1+5RuOyT6OXku9bJ9tcpvOldhTe9K0ky+w2Re1A0wHQVjJThcubrlGEYKsxNVWFuqs6YMlCStK/Wr02ltdpYFp2NubuqSbv2NWrXvka98VG5JKlfRlLLDM5oiNk/J8WRmaEAAABAPBFaAgAAtDAMQ0bWAHmzBsg7/lzZkZAiFZuj98IsWyOraoesqh0KVu2QVr4kuX1yFY5pWZV8gozMAkcDw9zMZOVmJmvW+P6SpLqmoDaV1mpTS4i5s6JBVXUBLV2zR0vX7JEkpad4YpeSjxqUqUH5aXKZLO4DAACAnoXQEgAA4DAMl0fuwhK5C0vkmyFZTbWKlK+JrUpu++sU2fmxIjs/VrMkI62f3EUT5Bo0Xu7CEhm+VEfryUjxauroPE0dnSdJ8jeHtXVXnTaURi8n37q7TvVNIa3YWKkVGyslSUlel0YMzIyGmEWZGlaYIY/b5WhdAAAAgNMILQEAADrJTMmUOfIUeUaeItu2ZFWVKly2RpGy1Yrs2SS7oUqh9W8otP4NyTBl5g9rmYU5XmbeMBkOz3hM9rk1rjhH44pzJEmhsKUde+q1oXS/NpXValNZrfzNYX2yrVqfbKuWJLldhooHZMQWBRoxMFPJPr4SAgAAILHwDRUAAOA4GIYpV+4QuXKHSJMvlB1qVmT3+tgsTKtmt6yKzQpWbFZwxQuSN0XugWPlGjBartyhMnMHy3D7HK3J4zY1oihTI4oyJUmWZaussmWF8rJabSqtUW1jMBZovrR0hwxDGpSfplFF0RBz5KAsZaZ6Ha0LAAAAOFaElgAAAA4wPD65B0+Se/AkSZJVvy8WYIbL10rBJoW3LVd42/KWHUyZ2YUyc4vlyhsqV16xzJwiGW7nAkPTNDS4IF2DC9J1zrRBsm1be2v82rizdYXyWu2t8WtnRYN2VjTotRVlkqSCnJTY6uSjBmUpNzOJxX0AAADQrQgtAQAAuoCZnitvyRlSyRmyrYisym0Kl69RZO9WWZXbZPvrZFWXyaouU3jjW9GdDJfMnIFy5Q1tCTNbgkwHVygvyE5RQXaKTp9UKEnaX98cW9hnY2mtyisbVFHdpIrqJr21arckKTvdp5FFmRrdMhOzMDdVJiEmAAAAuhChJQAAQBczTJdcBSPkKhghSbJtW3ZTjSKV22Tt265I5fZokBmol1W1U1bVTklvRnc23TL7DYpeUp43NPo7Z6AM05mvcdnpPk0vKdD0kgJJUmMgFL18vDQ6G3P77nrtr2/W++v26v11eyVJqUlujYxdTp6pIQXpcrtYoRwAAADOIbQEAADoZoZhyEjNlpmaLQ09SVJLkNlYHQ0yK7crUrlNkX3bpeZGWZXbZFVuk9a1HMDlltlvsFwtl5abecUyswbIME98VfDUJI8mj8jV5BG5kqTmUERbd9XFQswt5XVqDIS1cvM+rdy8T5Lk9ZgaXthyOXlRpoYNzJTPwwrlAAAAOH6ElgAAAAnAMAwZaf1kpvWTiqdJagky6/cpsu+gIDPol7V3q6y9WxVqPYDbGw0y84pbZmUWy8zsf8Irlvs8LpUMyVbJkGxJUjhiaWdFdHGfTWU12lRWqwZ/SOt27Ne6HfslSS7T0ND+6RpWmKmivFQV5qWqsF8qq5QDAACg0/jmCAAAkKAMw5CRkSczI08aNl2SZNuW7LrKWIBpVW5TZN8OKRSQVbFZVsXmA0GmJ0mu3CEyc4dGF/vJLZaRmS/DOP4g0+0yNawwQ8MKM3T+jMGybFu79zXGViffUFqj/fXN2rKrTlt21bXbt19GkgbmpUZ/clM1MDdNA/qlyMusTAAAAByE0BIAAKAHMQxTRmaBzMwCeUbMlBQNMq3aPS2zMbdH75O5b7sUCiiye4Miuze0CTKTWxb6ia5Y7sobKiM977hXBzcNQwPz0jQwL01nThko27ZVVRvQxrIa7djToPJ9DSrf16jahqCq6gKqqgto1ZaqNp9Hys9KVmFuavQ4udFQs39OCvfJBAAA6MMILQEAAHo4wzDlyiqUK6tQnpGnSJJsy5JVs1vWvm0tszJ3yNq3Qwr5Fdm1TpFd6w4Emb5UuVpmY7aGmUZav+MKMg3DUG5WsnKzknXK+APjDf6Qdu1rVHllNMQsr2xU+b5GNfhDqtjvV8V+vz7atC+2vcs0VJCTosLcVBXlpraEmqnKz06W6wQveQcAAEDiI7QEAADohQzTlCtnoFw5A+UZdZokybYisvbvarmkPHqPTKuqVGpuVKR8jSLlaw7s70uLrlaeV9yyanmxjNTs456RmZbsiS7UMygrNmbbtuqaQu2CzF37GlW+r0H+5oh27Ys+X97mOG6XqQH9UtpdYl6Yl6rczCSZx1kbAAAAEg+hJQAAQB9hmC65+g2Sq98geTRbkmRHwrL2lx9YtXzfNllVZbKbGxQp+0SRsk8O7J+cIbNloZ/YquUpWcdfj2EoM9WrzNQcjR2aExu3bVv765vbzMhsiAaaVY0KhiyV7m1Q6d6GdsfyekwV9mu9X2ZaLNTMTvcdd9AKAACA+CG0BAAA6MMMl1uu3CFy5Q6RSqJjdjgoq7qsZaGfliCzuly2v06RnR8rsvPjA/unZLWbjWnmDZWZnHFiNRmGcjKSlJORpAnD+sXGLdvWvtqAdrUGmS2h5u6qJgVDlrbvqdf2PfXtjpXsc0UvLc89cL/Mgbmpykj1EmYCAAAkMEJLAAAAtGO4vXLlD5Mrf1hszA4HZVXtVKQ1xKzcIaumXHZTjcI7PpJ2fHRg/9ScaJDZb5DM9LzoCujpeTJSMk9o5XLTMJSflaz8rGRNHpkbG49Ylvbu98cuLy9ruax8T1WT/M0RbSmv05by9iuZpyV7NDA3VYV5be+Zmaa0ZM9x1wcAAADnEFoCAADgqAy3V66CEXIVjIiN2aFmRap2Ru+RWblN1r7tsmr2yG6sVrixWtq+ov1BXB6Z6bky0qMhppmRF33cGmp6k4+rNpdpakC/VA3ol9puPByxtKe6qd0l5uX7GlW5368Gf0gbSmu0obSm3T6ZqV4NzIuGmEV5aS2zNFOV7ONrMwAAQHfi2xcAAACOi+Hxyd1/pNR/ZGzMDvpbgsyt0dXL6ypl1e+T3VAlRUKyanZLNbsVOdTxfGmxWZlmeq6MjHyZ6bkyM/JlpOXIMI/tq6vbZaooL01FeWmSCmLjzaGI9lQ1tQsyyysbVVUXUG1jULWNQa3dvr/dsXIyfO0vMc+LhqQ+j+uYagIAAEDnEFoCAADAMYY3We4Bo6UBo9uN21ZYdkO1rPp9sur2ym75bdXvk11fKTtQL7u5QXZlg6zKbYc4sCEjNUdmS5DZboZmep6M5IxO36PS53FpSP90Demf3m7c3xzWrqo2q5i3rGpe0xBUdV2zquuatXpr1YGSJOVlJWtgfqqGF2UrzedSZqq35X6cPqX43Nw3EwAA4DgRWgIAAKDLGaY7OnMyI18aOLbD63bQHw006ytl11XKqo/+2PWVsuoqpUhIdkOVIg1Vh5ylKbc3FmCasdmabe6n6fEdtcZkn1vDCzM1vDCz3XhjINRmRmZD9L6ZlY1q8Ie0t8avvTV+fbRxX4fj+Twu5WT4lJPuU3ZGknLSfbFAMyc9+jvJy9dxAACAQ+FbEgAAAOLO8CbL1W+QXP0GdXjNtm3Z/tp2YaZVt092fctMzYZqKRyUtb9c2l9+6EvPkzNkpOfKTG+ZqZnR5r6aqTkyzMNf5p2a5NGoQVkaNSir3XhdY1DllQ3avb9JVfVB7a5sUFVtQNV1ATUGwmoORbS7qkm7q5oOe+wUnzsaYraEmh3DTZ88bi5BBwAAfQ+hJQAAABKaYRgyUrKklCy52tw/s5UdCctu2HfIS8+t+kqpuVG2v062v07W3q2HeAOXjLQ2l54fNFPT8KUd8jLvjFSvMlJzNGFErrKzU7V/f6PCYUtS9L6Z1XUBVdc3q7ouoP11zaquD0QvM28ZCwQjamoOq6kyrLLKxsN+/vQUT2xmZuvv7DaPs9J8cruOf1V2AACARERoCQAAgB7NcLllZPaXmdn/kK/bzY2HvvS8ZZEgWWHZ9ZWK1Fce+tJzT1L71c7T82Rm5MpombUpd1KHXXwe1yFXNG/L3xxuF2xWHxRs7q8LKBi2VN8UUn1TSDsq6g/9+SVlpnljszXb/m4NNzNTvTJN7q8JAAB6DkJLAAAA9GqGL1UuX6pcuUM6vGbbluym2pYZmpUtq51XxmZr2k01Uiggq7pUVnXpoY+fkqWm7AJZ3jTJlyYjKT16OXpy+oHHSS2PXQe+fif73BqYl6aBeWmHPK5t22oMhA8RaLb8rgtof32zIpatmoagahqCOsQ8UkmSyzSUldY6Q7N9sNk6gzM9xcPCQQAAIGEQWgIAAKDPMgxTRmq2zNTsDiueS5IdDspq2Ce7bp+s1ntots7WrKuUQn7ZTTVqbqrp3Bt6U2Jhptk2zEw+KNxseZyW7FFaskeDC9IPeTjLtlXfGDzMbM3o75qGaLBZVRdQVV3gsKW5XWZLkOlTduvl6AeFm6yIDgAAuguhJQAAAHAYhtsrV1ahlFXY4TXbtqXmRhlN+5RsN6ihcp/CjbWyA3Wy/fWyA/Utv+tkB+ol25aCTbKDTbJrK2R1pgBvcizANFvDzaT2szjTktKVnpGhofk57WZytopYlmobgh1macaCzvpm1TUGFY5YsdXQD6d1RfT0FK/Skj1KTXIrteV39Lmn/fNkj7xuk6ATAAAcM0JLAAAA4DgYhiElpcmdlqG07FSFChrlCh86irRtS2puktUaaPqjQWY02DxUyNkg2ZYU9MsO+o8t5GwJNduGnGnJ6UpPStfQ9AwZeekykvPaXa4eClva3xC9j+bhws3Oroh+MLfLVGqyW2ltAs3UZE/L8zaPW8dbwk+vh7ATAIC+jNASAAAA6GKGYUpJaXIlpUlZR9++Q8gZaBN0Hir0PDjkrDv2kDM9KV0ZyekampQhIzVdRm7rZeoFMpIzFDRTtL8prP31zWrwh9ToD0V/B8JqbPndEIiOtz6PWLbCkehMz9qG4DH9mbldhlKTPAfN6Gx5nuyOzepMa/NaarJbPo+LsBMAgF6A0BIAAABIMM6EnPUHXareJvQM1B9XyJnmSVZ6croMX6oMb7IMT3I0+MxJbv/cmyx5MhUyvPLbHjVFPKqPuNUQNNTYbLUJPENq9IfVGGgfgEbDTlu1jUHVNh5f2Bmb1XmooLPNa63jSV7CTgAAEgmhJQAAANDDHW/IaQfqZR0UZh760vUGyY5EFx4K+WUfQ23elp9oWYbkSYoGnN6WgDM1WUZWm+eeZIVdPgXlld/yRENPy6OGsFv1IVO1QZfqA1Jjc5sZni0h6ImEnS7TOOTl6yk+j3xel5K8Lvk8B/1ufexzK8kTfc49PAEAcAahJQAAANDHtIacRlKazKwBR92+XcgZqI8+DrXM0gz6D8zYDDZJoUB0saFgoN1zWRFJ9oHgs/HI7+mWlN7y0/EDuA6EnNnJMgqSJU+ybHeSQqZPQcOroLwKtASejRG3GsJu1YVcqgu6VBM0VRMwVBeIzvoMR2xFLFt1jUHVHWPY2aE0KRpmel2xIDP6291+rE0QGn3ujoWhKclu+cO2mv1BuUxDPq9LJkEoAKCPIbQEAAAAcETtQk4dPeQ8mG3bUiQUDTjbhJ0dnzdJLWGn3Rp2xp77pWBAki3ZEdnNDVJzQ4dZny5JyS0/mUcrLNkrIzNZtidJljtJEVeSQoZPIcOr5pbQ02+5FbRMNVumApHojz9iKBAy1Rgx5A8ZagwZagxJYdulkNwKBV0KBE3Vyrmg0esx2wSe7kOEou0D0naBaLug1N0ybsplmo7VBwCA03p1aLllyxbde++9+uijj5SamqrPfOYzuvnmm+X1euNdGgAAANBnGIYhub0y3F51Iko8LNu2pFBzNOAMtZ3h2fq8qX0g2jJ+8IxQRVpmU0aCsv1ByV8rU5IpyXNMH0wHrn8/VL2mR5bplm26FTE8ihhuReRS2HArLJdCdvQnaLtaglGXmi1TzRFTgYghf9hQ0HZHt5NL4ZBLoWD0cdB2qTF2DLdCMhWyo8e1OxmWetxmh0vd3S5THrcpj8uU22XI7TajY67ob7fbOPC4ZVu3y2i/X9t93MZB+5vytGzvdpvMIAUAHFavDS1ra2t11VVXaejQoXrooYdUUVGh++67T4FAQHfeeWe8ywMAAABwjAzDPLDQzwmwrXDLDE5/bFZnu8CzbSAaao7OEg0HpUgo+jgSksIh2ZFg+9fCIanN3E/DCsllhSQd4394uVp+jnOuRUQuRQyXwnIpbLtjIWeoJRhtDUFbQ9NQyKVwSxgasU1F1PLT8jhsmwq0jFm2qfBBrx9uH0st27aMWTI7BKousyXAbAlIPbEgtDX4PCg4bQlJ24agrdt53K52xzkQrBoHhawHglaXachlGjJNQy6z5bkr+pxAFQDiq9eGln/729/U2Nio3/3ud8rKypIkRSIR3X333bruuutUUFAQ3wIBAAAAxIVhumOXuzvJtu3ovTvbBJl2JBgNM2NhZzD6+6Cws+1rphWSxyU1+5tkh4Lt92vd9qAx2ZFYHS5F5LIj7TNPQwfC0DiK2MZhg85Y2BkyFQ4eCDrDRwhHWx83y5S/TaDamXDVkhH7se02j2W2/DZkmKYMwyWZpgzDjD53mZJhynS5ZBgumaYpmdHL7Q3TlKs1DHVFZ5K6XMahw9HW57HXTZmmIXdsO8OR4/i8Ltkul+obg4pErFggaxhq+W3INKMzoglqASSSXhtavvnmm5o1a1YssJSkCy64QHfddZfeeecdfe5zn4tfcQAAAAB6HcMwJJdbcrlPaDao220qOztV+/c3Khy2OrWP3RqWtoSZ7WeEtg04D/FaJCg7HP0tKyJZEdmR8IHH1oHH7V8LR9+39fVI6/M2YwdxGbZcikhGx9d6JFtSpOWnhdUuADViz+0OIal5TNu1bhPSQdvZrY/NDsdqu51tG7Il2S1jkmKvS4oFt9GnhmS0/Mg48FyGZBoyZMg22vxuu61hSjKiv2RKbV43WvaXWsZMMzpmmC1vcWD72D6tY2Z0O1MtY2b7bYzWbXTw/jpwzNbPF3vcftxo2T72uUyj5Y/DbNnNPPDHIrPlox50rNZjRP8A2tXRWqeMNsdqc9x2xzBb39OIvaehls/Tdjz6RFLso8VEP1vLP5YDg63/RGODBx+3zaYdju92mzI9btU3BRWJ2O23az2acWD/1uO3+aPv1HYH14K+qdeGllu3btWll17abiwjI0N5eXnaunXrCR3b7e6dN6x2ucx2v4ETQT/BafQUnEQ/wUn0E5x2fD11zHfk7HKxmadtg8+Dgk27ZSy2TaR9SNohII1t2xKMttm+Y5ja9v3abxPdx5JsS7Lt6P1SW57bsfH2j1u3NTos/9Seadgy227T13KX1o/eS3LpeLNirXSg82JBc5vHOui1A88P7C9Jth0dsw4eP+h9j3Tcmjbbd+b9DnWcDtsd9f3bb3/wuBF7fvR/4Vq3ObBPG0aHB4f4N74z/1Ifrv7Wlw9xjDYfJmimaMDc69V/UFEn3qv36rWhZV1dnTIyMjqMZ2Zmqra29riPa5qGsrNTT6S0hJeRcWL3CALaop/gNHoKTqKf4CT6CU6jpxKTbdvRANOyYmHnoUJP2450HGsNQVv3OdTYwcc70nscImBtf7xIm/eyZbf+tIxFP0p0e8uy229nWS2f1W7ZtuWxZUm22o+12a/t87ZjkiXbisZssXG1/Fnaatneavkztg6kXW0eG7YV2//Ab7WEyVbscbtozG753cI4aKxtFBh9j7bxUvuIzehUJOYsM/aG7es6bn0tRO9J2v6zsaWGqlJlTxwdt3ISQa8NLbuKZdmqq2uKdxldwuUylZGRrLo6vyKRzl2GAhwO/QSn0VNwEv0EJ9FPcBo91VO1rkF/kNb7icaBIfqpqxwIXWMjbaYVtg9UO74eHbfbBahtHrcLWtuOtz2m3eatD57O2D6I7Tje5jX74Ocd5zy2/WUYUmqqTw0NAUWslrC69fPYbaqyD+xny24JrA+8ZMtqf2jLareb1BKeH6JG+6Aa7ZbQ2+4w2GbyYuy53fbldp/zcH+edpsiDt4mdnzroNc71GkfdFhbHf4RtHnr5PQMFY0Yq/37Gw8utFfIyEju1NUEvTa0zMjIUH19fYfx2tpaZWZmntCxO3tfmZ4qErF6/WdE96Gf4DR6Ck6in+Ak+glOo6fgJPqpq8XuFNlx+FCPeyiX21RSdqr8+xtl009dKnrP0BOYVdsL9Nob7wwbNqzDvSvr6+tVWVmpYcOGxakqAAAAAAAAAEfTa0PL2bNn691331VdXV1s7OWXX5Zpmjr11FPjWBkAAAAAAACAI+m1oeVll12m1NRU3XDDDXr77bf13HPP6YEHHtBll12mgoKCeJcHAAAAAAAA4DB6bWiZmZmpJ554Qi6XSzfccIN++ctfat68ebr11lvjXRoAAAAAAACAI+i1C/FI0vDhw/X444/HuwwAAAAAAAAAx6DXzrQEAAAAAAAA0DMRWgIAAAAAAABIKISWAAAAAAAAABIKoSUAAAAAAACAhEJoCQAAAAAAACChEFoCAAAAAAAASCiElgAAAAAAAAASCqElAAAAAAAAgIRCaAkAAAAAAAAgoRBaAgAAAAAAAEgohJYAAAAAAAAAEgqhJQAAAAAAAICEQmgJAAAAAAAAIKEQWgIAAAAAAABIKISWAAAAAAAAABIKoSUAAAAAAACAhEJoCQAAAAAAACChEFoCAAAAAAAASCiElgAAAAAAAAASimHbth3vInoS27ZlWb33j8zlMhWJWPEuA70E/QSn0VNwEv0EJ9FPcBo9BSfRT3AS/YQTZZqGDMM46naElgAAAAAAAAASCpeHAwAAAAAAAEgohJYAAAAAAAAAEgqhJQAAAAAAAICEQmgJAAAAAAAAIKEQWgIAAAAAAABIKISWAAAAAAAAABIKoSUAAAAAAACAhEJoCQAAAAAAACChEFoCAAAAAAAASCiElgAAAAAAAAASCqElAAAAAAAAgIRCaAkAAAAAAAAgoRBaAgAAAAAAAEgo7ngXgO6xZcsW3Xvvvfroo4+Umpqqz3zmM7r55pvl9XqPuJ9t23rkkUf0l7/8RdXV1SopKdFtt92myZMnd0/hSEiLFi3Sv/71L61Zs0Z1dXUaMmSIrrzySl166aUyDOOw+5111lkqLy/vML5q1Sr5fL6uLBkJ7Pnnn9dtt93WYfzaa6/VLbfcctj9OD/hUK688kq9//77h3ztV7/6lS666KJDvsb5CZK0Y8cOPfroo/r444+1adMmDRs2TAsWLOiw3d///nfNnz9fu3btUnFxsb71rW/pzDPPPOrxKyoqdO+99+rtt9+Wx+PRueeeq9tuu01paWld8XGQAI7WUw0NDfrTn/6kJUuWaPv27fJ6vZo4caK+9a1vafTo0Uc89rJly/SlL32pw/iFF16oX//6145/FsRfZ85Rh/t7cOHChRo+fPgRj885qm85Wj+VlZXp7LPPPuS+Xq9Xq1evPuyxOT/BKYSWfUBtba2uuuoqDR06VA899JAqKip03333KRAI6M477zzivo888ogefPBB3XLLLRo9erSefvppffWrX9U///lPDRo0qJs+ARLN448/roEDB+rWW29Vdna23n33Xd1xxx3as2ePbrzxxiPue9555+mrX/1qu7GjhefoG+bPn6/09PTY84KCgiNuz/kJh3LXXXepoaGh3dgTTzyhV199VbNmzTrivpyfsGnTJi1ZskSTJk2SZVmybbvDNi+99JLuuOMOXX/99Zo5c6YWLlyoG2+8UU8//fQR/6dJKBTSNddcI0n65S9/qUAgoPvvv1/f+c539PDDD3fVR0KcHa2ndu3apWeeeUaXXnqpbr75ZjU3N+uxxx7TF77wBT333HNHDZkk6Wc/+5mGDRsWe56dne3450Bi6Mw5SpJOOukkff/73283VlRUdMRjc47qe47WT/n5+XrmmWfajdm2rWuuuUYzZ87s1HtwfsKJIrTsA/72t7+psbFRv/vd75SVlSVJikQiuvvuu3XdddcdNhhobm7Www8/rK9+9av68pe/LEmaOnWqzj//fD366KP60Y9+1D0fAAnnD3/4g3JycmLPZ82apZqaGv3pT3/S17/+dZnm4e88kZuby0w4HNK4cePa9dWRcH7C4YwYMaLD2He+8x2deuqpR+0vzk8466yzdM4550iSbr31Vn3yyScdtnnwwQd10UUX6eabb5YkzZw5Uxs3btTvf/97PfLII4c99iuvvKJNmzZp4cKFsf+Ay8jI0NVXX61Vq1Zp4sSJzn8gxN3ReqqoqEj//ve/lZycHBubOXOmzjrrLP3lL3/RHXfccdT3GDlypCZMmOBs4UhInTlHSdFzy7H+fcY5qu85Wj95vd4OfbRs2TI1NDRo7ty5nXoPzk84UdzTsg948803NWvWrFhgKUkXXHCBLMvSO++8c9j9PvzwQzU0NOiCCy6IjXm9Xp177rl68803u7JkJLhD/Yd/SUmJGhoa1NTUFIeK0NdwfkJnffjhhyorK9PFF18c71LQAxzpf7pJUmlpqbZv397u3CNFL3dbunSpgsHgYfd98803NXr06HYzTk499VRlZWVpyZIlJ1Y4EtbReiolJaVdYClJqampGjx4sPbu3duVpaEHOlo/nQjOUX3P8fTTggULlJaWprPOOqsLKgI6IrTsA7Zu3druLx8p+n/N8vLytHXr1iPuJ6nDvsOHD9euXbsUCAScLxY91ooVK1RQUHDUe968+OKLGj9+vKZMmaJrr71WGzZs6KYKkejmzp2rkpISnX322Xr44YcViUQOuy3nJ3TWggULlJKScth7MrXF+QlH03ruKS4ubjc+fPhwhUIhlZaWHnHfg89ZhmGouLj4iN/H0PfU1dXF7i/XGV/72tdUUlKi2bNn6/777+fvQOj999/X5MmTNWHCBH3xi1/UBx98cNR9OEfhaEKhkF599VWde+65nb7fN+cnnCguD+8D6urqlJGR0WE8MzNTtbW1R9zP6/V2OCFlZGTItm3V1tYqKSnJ8XrR8yxfvlwLFy7scO+cg5111lmaOHGiCgsLVVpaqv/3//6frrjiCr3wwgvcg7APy8vL00033aRJkybJMAz95z//0W9+8xtVVFQc9r67nJ/QGeFwWIsWLdJZZ52llJSUI27L+Qmd0fq96eDvVa3Pj/a9qu19e1sd7fsY+p6f//znMgxDl19++RG3S09P1zXXXKOTTz5ZPp9P7733nh577DFt3bqVexD2YSeffLI+85nPaOjQodq7d68effRRfeUrX9FTTz2lKVOmHHY/zlE4mjfffFM1NTWdujSc8xOcQmgJ4ITs2bNH3/rWtzRjxoxDrhDX1g9/+MPY42nTpunUU0/VBRdcwD0I+7jTTz9dp59+euz5aaedJp/PpyeeeELXX3+98vPz41gderJ33nlH1dXVnfpyzfkJQCJ47rnn9Oyzz+q+++5T//79j7jt2LFjNXbs2NjzWbNmKT8/Xz/+8Y+5B2Ef9o1vfKPd8zPOOENz587V//7v/x7xvrvA0bz44ovKzc096sKGEucnOIfLw/uAjIwM1dfXdxivra1VZmbmEfcLBoNqbm5uN15XVyfDMI64L/qGuro6XXvttcrKytJDDz10zPdFyc/P19SpU7VmzZouqhA91QUXXKBIJKJ169Yd8nXOT+iMBQsWKCsrS6eddtox78v5CYfSem45+HtVXV1du9cPJSMjo8PK9tLRv4+h71iyZInuvPNOff3rX9dnP/vZ4zpG6/1WD7dAC/qelJQUzZkz56h/n3GOwpE0NjZq8eLFuuCCC+RyuY7rGJyfcDwILfuAYcOGdbgPSX19vSorK494r5zW17Zt29ZufOvWrSosLOTSyz4uEAjouuuuU319vebPn3/Iy0mArsL5CUcTCAT02muv6fzzz5fH44l3OeglWs89B3+v2rp1qzwezxFvJXCo72O2bWvbtm2dvncheq+VK1fqm9/8pi655BJ985vfjHc56IM4R+FI/v3vfysQCLCwIbodoWUfMHv2bL377ruxWQCS9PLLL8s0TZ166qmH3e+kk05SWlqaFi1aFBtrvfnu7Nmzu7RmJLZwOKybb75ZW7du1fz581VQUHBcx6moqNCKFSs0YcIEhytET7dw4UK5XK52l5W0xfkJR/Of//xHTU1Nx/3lmvMTDmXQoEEaOnSoXn755XbjCxcu1KxZs+T1eg+77+zZs7V+/Xpt3749NrZ06VLV1NRozpw5XVUyeoDNmzfruuuu08yZM3X33Xef0LFeeuklSeLchZimpia98cYbR+0JzlE4kgULFmjw4MGaNGnScR+D8xOOB/e07AMuu+wyPfXUU7rhhht03XXXqaKiQg888IAuu+yydmHTVVddpV27dunf//63JMnn8+m6667TQw89pJycHI0aNUp//etfVVNTo6uvvjpeHwcJ4O6779bixYt16623qqGhQStXroy9NnbsWHm93g79tGDBAi1evFhz5sxRfn6+SktL9cc//lEul0tf+cpX4vRJkAiuvvpqzZgxQ6NHj5Ykvf7663r22Wf1pS99SXl5eZI4P+HYvfjiiyosLNTUqVM7vMb5CYfj9/u1ZMkSSVJ5ebkaGhpiAeX06dOVk5Ojm266SbfccosGDx6sGTNmaOHChVq1apX+/Oc/x45TXl6uc889V1//+td14403SpLOO+88Pfzww7rpppv07W9/W36/Xw888IDOOOMM7u3Vix2tp2zb1tVXXy2fz6errrqq3WWTaWlpGjFiRGzfg3vqlltu0ZAhQzR27NjYQhePP/64zjnnHEKBXupo/dQ6oeDcc8/VwIEDtXfvXv3pT39SZWWlfvvb38aOwzkKUuf+zpOk6upqLV26VNdee+0hj8P5CV2J0LIPyMzM1BNPPKF77rlHN9xwg1JTUzVv3jx961vfaredZVmKRCLtxq699lrZtq3HHntM1dXVKikp0aOPPspKqn3cO++8I0m67777Orz2+uuvq6ioqEM/FRUVae/evfrpT3+q+vp6paena+bMmfrGN75BP/VxxcXFeu6557Rnzx5ZlqWhQ4fq9ttv15VXXhnbhvMTjkVtba3eeustXXXVVTIMo8PrnJ9wOFVVVR0uzW19/uSTT2rGjBmaO3eu/H6/HnnkEf3xj39UcXGxfve737Vblde2bUUiEdm2HRvzeDyaP3++7r33Xn3729+W2+3Wueeeq9tvv717Phzi4mg9JUUXNZSkL3/5y+22mz59up566ilJh+6pkSNH6sUXX9Rjjz2mUCikgQMH6vrrr9fXvva1rvo4iLOj9VP//v0VCoX061//WjU1NUpOTtaUKVN09913twseOUdB6tzfeZK0aNEihcPhw169wvkJXcmw23YWAAAAAAAAAMQZ97QEAAAAAAAAkFAILQEAAAAAAAAkFEJLAAAAAAAAAAmF0BIAAAAAAABAQiG0BAAAAAAAAJBQCC0BAAAAAAAAJBRCSwAAAAAAAAAJhdASAAAAaPH8889r9OjRWr16dbxLAQAA6NPc8S4AAAAAfcvzzz+v22677bCvP/PMM5o8eXL3FQQAAICEQ2gJAACAuPjGN76hoqKiDuODBw+OQzUAAABIJISWAAAAiIvZs2drwoQJ8S4DAAAACYh7WgIAACDhlJWVafTo0Xr00Uf1+OOP68wzz9TEiRP1xS9+URs3buyw/dKlS3XFFVdo8uTJmjZtmv7nf/5HW7Zs6bBdRUWFbr/9dp122mkaP368zjrrLN11110KBoPttgsGg/rZz36mmTNnavLkybrhhhtUXV3dZZ8XAAAA7THTEgAAAHHR0NDQIQg0DEPZ2dmx5y+88IIaGxt1xRVXqLm5WU899ZSuuuoqvfjii8rNzZUkvfvuu7r22mtVVFSkG2+8UYFAQH/+8591+eWX6/nnn49dgl5RUaF58+apvr5en//85zVs2DBVVFTolVdeUSAQkNfrjb3vvffeq4yMDN14440qLy/XE088oR//+Mf6zW9+0/V/MAAAACC0BAAAQHx8+ctf7jDm9Xrbrdy9c+dOvfrqqyooKJAUvaT8v/7rv/TII4/EFvN54IEHlJmZqWeeeUZZWVmSpHPOOUef/exn9dBDD+n++++XJP3qV7/Svn379Oyzz7a7LP2b3/ymbNtuV0dWVpYee+wxGYYhSbIsS0899ZTq6+uVnp7u2J8BAAAADo3QEgAAAHFx5513qri4uN2Yaba/e9E555wTCywlaeLEiZo0aZKWLFmi2267TXv37tW6det0zTXXxAJLSRozZoxOOeUULVmyRFI0dHzttdd05plnHvI+mq3hZKvPf/7z7camTZumxx9/XOXl5RozZsxxf2YAAAB0DqElAAAA4mLixIlHXYhnyJAhHcaGDh2qRYsWSZJ27dolSR3CT0kaPny43n77bTU1NampqUkNDQ0aOXJkp2orLCxs9zwjI0OSVFdX16n9AQAAcGJYiAcAAAA4yMEzPlsdfBk5AAAAugYzLQEAAJCwduzY0WFs+/btGjhwoKQDMyK3bdvWYbutW7cqOztbKSkpSkpKUlpamjZt2tS1BQMAAMARzLQEAABAwnrttddUUVERe75q1Sp9/PHHmj17tiQpPz9fJSUleuGFF9pdur1x40a98847mjNnjqTozMlzzjlHixcvbrfQTytmUAIAACQWZloCAAAgLt58801t3bq1w/hJJ50UWwRn8ODBuvzyy3X55ZcrGAzqySefVFZWlq655prY9t/73vd07bXX6gtf+ILmzZunQCCgP//5z0pPT9eNN94Y2+7b3/623nnnHV155ZX6/Oc/r+HDh6uyslIvv/yy/vKXv8TuWwkAAID4I7QEAABAXDz44IOHHP/Zz36m6dOnS5IuueQSmaapJ554QlVVVZo4caLuuOMO5efnx7Y/5ZRTNH/+fD344IN68MEH5Xa7dfLJJ+u73/2uBg0aFNuuoKBAzz77rH7729/qxRdfVENDgwoKCjR79mwlJSV17YcFAADAMTFsroUBAABAgikrK9PZZ5+t733ve7r66qvjXQ4AAAC6Gfe0BAAAAAAAAJBQCC0BAAAAAAAAJBRCSwAAAAAAAAAJhXtaAgAAAAAAAEgozLQEAAAAAAAAkFAILQEAAAAAAAAkFEJLAAAAAAAAAAmF0BIAAAAAAABAQiG0BAAAAAAAAJBQCC0BAAAAAAAAJBRCSwAAAAAAAAAJhdASAAAAAAAAQEIhtAQAAAAAAACQUP4/rnHZVSrSIb8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fit(model, train_loader, valid_loader, optimizer, loss_fn, 20, 'Simple fc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQxkg0uBIT0f"
      },
      "source": [
        "## BatchNorm и Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "50vivUUNIT0f",
        "outputId": "4e39fc19-9398-40c7-8415-367eea627f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dropout(p=0.1, inplace=False)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "GkW4A_msIT0f",
        "outputId": "5b578d48-1507-4985-d772-1218f3098c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4692, 0.5289, 0.1251, 0.2366, 0.5250, 0.1004, 0.7477],\n",
              "        [0.5762, 0.5053, 0.4679, 0.9223, 0.9563, 0.7441, 0.7483],\n",
              "        [0.2576, 0.7044, 0.1618, 0.7161, 0.1450, 0.4973, 0.8624]])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "x = torch.rand(3, 7)\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Ae8rXE65IT0g",
        "outputId": "52ef31cc-16d4-46b6-864c-c36e7a1dee32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5213, 0.5877, 0.1389, 0.2628, 0.5834, 0.1115, 0.8307],\n",
              "        [0.6402, 0.5614, 0.5199, 1.0248, 1.0626, 0.8268, 0.8315],\n",
              "        [0.2862, 0.7827, 0.1798, 0.7957, 0.1611, 0.5525, 0.9582]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "x / 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "OIdpkCj-IT0g",
        "outputId": "d30e1524-4080-4fa3-b9df-fb45d0a55a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.5877, 0.1389, 0.2628, 0.0000, 0.1115, 0.8307],\n",
            "        [0.6402, 0.5614, 0.5199, 1.0248, 1.0626, 0.8268, 0.8315],\n",
            "        [0.2862, 0.7827, 0.1798, 0.7957, 0.1611, 0.5525, 0.9582]])\n",
            "tensor([[0.5213, 0.5877, 0.1389, 0.0000, 0.5834, 0.1115, 0.8307],\n",
            "        [0.6402, 0.5614, 0.5199, 1.0248, 1.0626, 0.8268, 0.8315],\n",
            "        [0.2862, 0.7827, 0.1798, 0.7957, 0.1611, 0.0000, 0.9582]])\n",
            "tensor([[0.5213, 0.5877, 0.1389, 0.2628, 0.5834, 0.1115, 0.8307],\n",
            "        [0.6402, 0.5614, 0.5199, 1.0248, 1.0626, 0.8268, 0.8315],\n",
            "        [0.2862, 0.7827, 0.1798, 0.7957, 0.1611, 0.5525, 0.0000]])\n"
          ]
        }
      ],
      "source": [
        "dropout.train()\n",
        "\n",
        "for _ in range(3):\n",
        "    print(dropout(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbTlnRBLXXyR",
        "outputId": "3941d263-37e9-48da-854a-6df498b19c7b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4692, 0.5289, 0.1251, 0.2366, 0.5250, 0.1004, 0.7477],\n",
              "        [0.5762, 0.5053, 0.4679, 0.9223, 0.9563, 0.7441, 0.7483],\n",
              "        [0.2576, 0.7044, 0.1618, 0.7161, 0.1450, 0.4973, 0.8624]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "o8WpezQnIT0g",
        "outputId": "2874b83a-a07c-4c68-e51f-6712b13ace97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4692, 0.5289, 0.1251, 0.2366, 0.5250, 0.1004, 0.7477],\n",
              "        [0.5762, 0.5053, 0.4679, 0.9223, 0.9563, 0.7441, 0.7483],\n",
              "        [0.2576, 0.7044, 0.1618, 0.7161, 0.1450, 0.4973, 0.8624]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "dropout.eval()\n",
        "\n",
        "dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "ADdqZ-GnIT0g",
        "outputId": "7f0b09e5-ef40-496c-e033-e65b7663becb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "batch_norm = nn.BatchNorm1d(num_features=7)\n",
        "\n",
        "batch_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "9Pk3q62PIT0h",
        "outputId": "b45f1fc2-587b-4028-cb5d-73d11afcd349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6941, 0.6341, 0.8651, 0.7624, 0.6475, 0.3255, 0.2580],\n",
              "        [0.3764, 0.7386, 0.2278, 0.6366, 0.9375, 0.9234, 0.1319],\n",
              "        [0.6425, 0.8269, 0.0458, 0.8196, 0.1885, 0.1385, 0.2881]])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "x = torch.rand(3, 7)\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "M6uyWBMvIT0h",
        "outputId": "c6ab6d21-2efd-40da-e314-ed04c384c902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8840, -1.2566,  1.3822,  0.2989,  0.1829, -0.4090,  0.4729],\n",
              "        [-1.3976,  0.0685, -0.4320, -1.3455,  1.1230,  1.3769, -1.3893],\n",
              "        [ 0.5136,  1.1881, -0.9501,  1.0465, -1.3058, -0.9678,  0.9163]],\n",
              "       grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "batch_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "eykRSgNvIT0h",
        "outputId": "9b7a340a-a0f3-43c6-fcae-21a8fe9df6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "batch_norm.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "uJWE-35QIT0h",
        "outputId": "c7035385-b2ff-4c39-842a-537e4260295f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "batch_norm.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "LbRRMVnwIT0i",
        "outputId": "30ae3a50-8870-4616-9f1b-70b420a1cb6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0571, 0.0733, 0.0380, 0.0740, 0.0591, 0.0462, 0.0226])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "batch_norm.running_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "44CVL3kVIT0i",
        "outputId": "b2c94fc6-a000-4fb0-87cd-882fbb3cb690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9029, 0.9009, 0.9185, 0.9009, 0.9143, 0.9168, 0.9007])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "batch_norm.running_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "K_SrMe85IT0i",
        "outputId": "f5fbf5b1-482f-40a0-9afa-0ca63abe147c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "batch_norm.num_batches_tracked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "CdYP5c26IT0i",
        "outputId": "8181d919-d2c6-4c05-edd6-e0cec7219289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "batch_norm(x)\n",
        "\n",
        "batch_norm.num_batches_tracked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "60uHib2bIT0j",
        "outputId": "80f4b34e-d140-4b29-f9e4-5dab0f85d592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6485,  0.5491,  0.8626,  0.6903,  0.5850,  0.2590,  0.2388],\n",
              "        [ 0.2966,  0.6652,  0.1694,  0.5506,  0.9018,  0.9106,  0.0987],\n",
              "        [ 0.5913,  0.7632, -0.0286,  0.7537,  0.0832,  0.0552,  0.2721]],\n",
              "       grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "batch_norm.eval()\n",
        "\n",
        "batch_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "UEI4onXBIT0j",
        "outputId": "1bec7fda-0ac7-4938-c573-4bab63fbd3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6941, 0.6341, 0.8651, 0.7624, 0.6475, 0.3255, 0.2580],\n",
              "        [0.3764, 0.7386, 0.2278, 0.6366, 0.9375, 0.9234, 0.1319],\n",
              "        [0.6425, 0.8269, 0.0458, 0.8196, 0.1885, 0.1385, 0.2881]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "rbp7VeIrIT0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d8d6eb-fc62-43b6-c16b-dad60f90b634"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6941, 0.6341, 0.8651, 0.7624, 0.6475, 0.3255, 0.2580],\n",
              "        [0.3764, 0.7386, 0.2278, 0.6366, 0.9374, 0.9234, 0.1319],\n",
              "        [0.6425, 0.8269, 0.0458, 0.8196, 0.1885, 0.1385, 0.2881]],\n",
              "       grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "batch_norm = nn.BatchNorm1d(num_features=7)\n",
        "\n",
        "batch_norm.eval()\n",
        "\n",
        "batch_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZYoKp07IT0j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}